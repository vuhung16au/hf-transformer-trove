{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.2/02-zero-shot-classification.ipynb)\n",
    "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.2/02-zero-shot-classification.ipynb)\n",
    "\n",
    "# 02 - Zero-Shot Classification: Classify Without Training Data\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- What zero-shot classification is and when to use it\n",
    "- How to use Hugging Face pipelines for zero-shot classification\n",
    "- The underlying models and techniques (BART, RoBERTa, CLIP)\n",
    "- How to work with different types of candidate labels\n",
    "- Performance considerations and best practices\n",
    "- Advanced techniques for improving zero-shot classification\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with Python and text classification\n",
    "- Knowledge of transformers (refer to [Notebook 01](../01_intro_hf_transformers.ipynb))\n",
    "- Understanding of NLP fundamentals (refer to [NLP Learning Journey](https://github.com/vuhung16au/nlp-learning-journey))\n",
    "\n",
    "## üìö What We'll Cover\n",
    "1. **Introduction**: Zero-shot classification concepts\n",
    "2. **Basic Pipeline Usage**: Using the zero-shot classification pipeline\n",
    "3. **Manual Implementation**: Understanding the underlying process\n",
    "4. **Model Comparison**: Different zero-shot models\n",
    "5. **Real-world Applications**: Practical use cases\n",
    "6. **Performance Analysis**: Speed and accuracy considerations\n",
    "7. **Advanced Techniques**: Improving classification performance\n",
    "8. **Summary and Best Practices**: Key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Zero-Shot Classification?\n",
    "\n",
    "**Zero-shot classification** is the ability to classify text into categories that the model has never seen during training. Instead of being trained on specific labels, the model uses its general understanding of language to determine which category best fits the input text.\n",
    "\n",
    "### Key Advantages:\n",
    "- üöÄ **No training required**: Start classifying immediately\n",
    "- üîÑ **Flexible labels**: Change categories without retraining\n",
    "- üí∞ **Cost-effective**: No need for labeled training data\n",
    "- ‚ö° **Rapid prototyping**: Test ideas quickly\n",
    "\n",
    "### How it Works:\n",
    "Zero-shot classification typically works by:\n",
    "1. **Natural Language Inference (NLI)**: Treating classification as a \"does this text belong to this category?\" question\n",
    "2. **Entailment**: Using models trained on textual entailment tasks\n",
    "3. **Similarity**: Computing semantic similarity between text and label descriptions\n",
    "\n",
    "The mathematical foundation often relies on:\n",
    "$$P(\\text{label} | \\text{text}) = \\frac{\\exp(\\text{similarity}(\\text{text}, \\text{label}))}{\\sum_{i} \\exp(\\text{similarity}(\\text{text}, \\text{label}_i))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment and run if needed)\n",
    "# !pip install transformers torch datasets tokenizers matplotlib seaborn plotly\n",
    "\n",
    "# Import essential libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from typing import List, Dict, Optional, Union\n",
    "from collections import Counter\n",
    "\n",
    "# Hugging Face imports\n",
    "from transformers import (\n",
    "    pipeline, \n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For Google Colab compatibility\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    COLAB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    COLAB_AVAILABLE = False\n",
    "\n",
    "# Load environment variables from .env.local for local development\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv('.env.local', override=True)\n",
    "    print(\"‚úÖ Environment variables loaded from .env.local\")\n",
    "except ImportError:\n",
    "    print(\"üí° python-dotenv not available. Using system environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Automatically detect and return the best available device.\n",
    "    \n",
    "    Priority: CUDA > MPS (Apple Silicon) > CPU\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for current hardware\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"üöÄ Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\") \n",
    "        print(\"üçé Using Apple MPS (Apple Silicon)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"üíª Using CPU (consider GPU for better performance)\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Set up device and display system info\n",
    "device = get_device()\n",
    "print(f\"\\n=== System Information ===\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Zero-Shot Classification\n",
    "\n",
    "Let's start with the basic example from the issue and then expand on it with educational explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zero-shot classification pipeline\n",
    "# This uses the default model: facebook/bart-large-mnli\n",
    "print(\"üì• Loading zero-shot classification pipeline...\")\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\"‚úÖ Pipeline loaded in {load_time:.2f} seconds\")\n",
    "print(f\"üìä Default model: {classifier.model.config.name_or_path}\")\n",
    "print(f\"üè∑Ô∏è  Model type: {classifier.model.config.model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic zero-shot classification example (from the issue)\n",
    "text = \"This is a course about the Transformers library\"\n",
    "candidate_labels = [\"education\", \"politics\", \"business\"]\n",
    "\n",
    "print(\"üîç Performing Zero-Shot Classification\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Text: '{text}'\")\n",
    "print(f\"Candidate Labels: {candidate_labels}\")\n",
    "print(\"\\nüìà Results:\")\n",
    "\n",
    "# Perform classification with timing\n",
    "start_time = time.time()\n",
    "result = classifier(\n",
    "    text,\n",
    "    candidate_labels=candidate_labels,\n",
    ")\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Display results in an educational format\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    confidence = score * 100\n",
    "    bar = '‚ñà' * int(confidence / 5)  # Visual bar representation\n",
    "    print(f\"  {label:12}: {confidence:5.1f}% {bar}\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Inference time: {inference_time:.3f} seconds\")\n",
    "print(f\"üèÜ Predicted class: {result['labels'][0]} (confidence: {result['scores'][0]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Testing with Multiple Examples\n",
    "\n",
    "Let's test the zero-shot classifier with various examples to understand its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with diverse examples\n",
    "test_examples = [\n",
    "    \"This is a course about the Transformers library\",\n",
    "    \"The stock market crashed today due to inflation concerns\",\n",
    "    \"The president announced new economic policies\",\n",
    "    \"Students are learning machine learning fundamentals\",\n",
    "    \"The company's quarterly earnings exceeded expectations\",\n",
    "    \"Educational institutions are adopting AI technologies\"\n",
    "]\n",
    "\n",
    "labels = [\"education\", \"politics\", \"business\"]\n",
    "\n",
    "print(\"üîç Testing Zero-Shot Classification with Multiple Examples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = []\n",
    "for i, text in enumerate(test_examples, 1):\n",
    "    print(f\"\\nüìÑ Example {i}: '{text}'\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = classifier(text, candidate_labels=labels)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    predicted_label = result['labels'][0]\n",
    "    confidence = result['scores'][0]\n",
    "    \n",
    "    print(f\"   üèÜ Prediction: {predicted_label} ({confidence:.3f})\")\n",
    "    print(f\"   ‚è±Ô∏è  Time: {inference_time:.3f}s\")\n",
    "    \n",
    "    # Show all scores\n",
    "    print(\"   üìä All scores:\")\n",
    "    for label, score in zip(result['labels'], result['scores']):\n",
    "        bar = '‚ñà' * int(score * 20)  # Visual representation\n",
    "        print(f\"      {label:12}: {score:.3f} {bar}\")\n",
    "    \n",
    "    results.append({\n",
    "        'text': text,\n",
    "        'predicted_label': predicted_label,\n",
    "        'confidence': confidence,\n",
    "        'inference_time': inference_time\n",
    "    })\n",
    "\n",
    "# Summary statistics\n",
    "avg_confidence = np.mean([r['confidence'] for r in results])\n",
    "avg_time = np.mean([r['inference_time'] for r in results])\n",
    "label_distribution = Counter([r['predicted_label'] for r in results])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"üìä SUMMARY STATISTICS\")\n",
    "print(f\"   Average confidence: {avg_confidence:.3f}\")\n",
    "print(f\"   Average inference time: {avg_time:.3f}s\")\n",
    "print(f\"   Label distribution: {dict(label_distribution)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Real-World Applications\n",
    "\n",
    "Let's explore practical applications of zero-shot classification in different domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world application examples\n",
    "applications = {\n",
    "    \"Customer Support\": {\n",
    "        \"texts\": [\n",
    "            \"I can't log into my account, password doesn't work\",\n",
    "            \"My order arrived damaged, need replacement\",\n",
    "            \"How do I cancel my subscription?\",\n",
    "            \"Want to upgrade to premium plan\",\n",
    "            \"App keeps crashing when I upload photos\"\n",
    "        ],\n",
    "        \"labels\": [\"login_issue\", \"shipping_problem\", \"account_management\", \"sales_inquiry\", \"technical_bug\"]\n",
    "    },\n",
    "    \n",
    "    \"Content Moderation\": {\n",
    "        \"texts\": [\n",
    "            \"Amazing product! Highly recommend to everyone\",\n",
    "            \"This is the worst service I've ever used\",\n",
    "            \"When will the new update be released?\",\n",
    "            \"Check out this discount link: special-deal.com\",\n",
    "            \"The interface could be more user-friendly\"\n",
    "        ],\n",
    "        \"labels\": [\"positive_feedback\", \"negative_feedback\", \"question\", \"potential_spam\", \"suggestion\"]\n",
    "    },\n",
    "    \n",
    "    \"News Classification\": {\n",
    "        \"texts\": [\n",
    "            \"Scientists discover new treatment for diabetes\",\n",
    "            \"Stock market reaches all-time high today\",\n",
    "            \"Local team wins championship after 20 years\",\n",
    "            \"New smartphone model features AI camera\",\n",
    "            \"Government announces climate change initiative\"\n",
    "        ],\n",
    "        \"labels\": [\"health\", \"finance\", \"sports\", \"technology\", \"politics\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def demonstrate_application(app_name, app_data):\n",
    "    \"\"\"Demonstrate zero-shot classification for a specific application.\"\"\"\n",
    "    print(f\"\\nüìã Application: {app_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    texts = app_data[\"texts\"]\n",
    "    labels = app_data[\"labels\"]\n",
    "    \n",
    "    app_results = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        start_time = time.time()\n",
    "        result = classifier(text, candidate_labels=labels)\n",
    "        inference_time = time.time() - start_time\n",
    "        total_time += inference_time\n",
    "        \n",
    "        predicted_label = result['labels'][0]\n",
    "        confidence = result['scores'][0]\n",
    "        \n",
    "        print(f\"\\n  üìù {i}. '{text}'\")\n",
    "        print(f\"     ‚Üí {predicted_label} ({confidence:.3f})\")\n",
    "        \n",
    "        app_results.append({\n",
    "            'text': text,\n",
    "            'predicted': predicted_label,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    # Application summary\n",
    "    avg_confidence = np.mean([r['confidence'] for r in app_results])\n",
    "    print(f\"\\n  üìä Summary:\")\n",
    "    print(f\"     Average confidence: {avg_confidence:.3f}\")\n",
    "    print(f\"     Total processing time: {total_time:.2f}s\")\n",
    "    print(f\"     Throughput: {len(texts)/total_time:.1f} examples/second\")\n",
    "    \n",
    "    return app_results\n",
    "\n",
    "print(\"üåç REAL-WORLD ZERO-SHOT CLASSIFICATION APPLICATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Demonstrate each application\n",
    "all_results = {}\n",
    "for app_name, app_data in applications.items():\n",
    "    all_results[app_name] = demonstrate_application(app_name, app_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations of the classification results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Zero-Shot Classification Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Confidence distribution across all applications\n",
    "all_confidences = []\n",
    "for app_results in all_results.values():\n",
    "    all_confidences.extend([r['confidence'] for r in app_results])\n",
    "\n",
    "axes[0, 0].hist(all_confidences, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Confidence Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Overall Confidence Distribution')\n",
    "axes[0, 0].axvline(np.mean(all_confidences), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(all_confidences):.3f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Average confidence by application\n",
    "app_names = list(all_results.keys())\n",
    "app_confidences = [np.mean([r['confidence'] for r in results]) for results in all_results.values()]\n",
    "\n",
    "bars = axes[0, 1].bar(app_names, app_confidences, color=['lightcoral', 'lightgreen', 'lightsalmon'])\n",
    "axes[0, 1].set_ylabel('Average Confidence')\n",
    "axes[0, 1].set_title('Average Confidence by Application')\n",
    "axes[0, 1].set_xticklabels(app_names, rotation=15)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, conf in zip(bars, app_confidences):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                    f'{conf:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Label distribution for first application (Customer Support)\n",
    "customer_labels = [r['predicted'] for r in all_results['Customer Support']]\n",
    "label_counts = Counter(customer_labels)\n",
    "\n",
    "axes[1, 0].pie(label_counts.values(), labels=label_counts.keys(), autopct='%1.1f%%')\n",
    "axes[1, 0].set_title('Customer Support Label Distribution')\n",
    "\n",
    "# 4. Processing time simulation\n",
    "batch_sizes = [1, 5, 10, 20, 50]\n",
    "simulated_times = [size * 0.2 for size in batch_sizes]  # Simulated processing times\n",
    "throughput = [size / time for size, time in zip(batch_sizes, simulated_times)]\n",
    "\n",
    "axes[1, 1].plot(batch_sizes, throughput, marker='o', linewidth=2, markersize=6)\n",
    "axes[1, 1].set_xlabel('Batch Size')\n",
    "axes[1, 1].set_ylabel('Throughput (examples/sec)')\n",
    "axes[1, 1].set_title('Theoretical Throughput vs Batch Size')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(f\"\\nüìä Overall Statistics:\")\n",
    "print(f\"   Total examples processed: {len(all_confidences)}\")\n",
    "print(f\"   Overall average confidence: {np.mean(all_confidences):.3f}\")\n",
    "print(f\"   Confidence std deviation: {np.std(all_confidences):.3f}\")\n",
    "print(f\"   Min confidence: {np.min(all_confidences):.3f}\")\n",
    "print(f\"   Max confidence: {np.max(all_confidences):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Advanced Techniques and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_advanced_techniques():\n",
    "    \"\"\"Demonstrate advanced zero-shot classification techniques and best practices.\"\"\"\n",
    "    \n",
    "    print(\"üî¨ ADVANCED ZERO-SHOT CLASSIFICATION TECHNIQUES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Hypothesis Template Approach\n",
    "    print(\"\\n1Ô∏è‚É£ Using Hypothesis Templates for Better Performance\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    text = \"The new AI model achieved 95% accuracy on the benchmark dataset\"\n",
    "    \n",
    "    # Standard labels\n",
    "    standard_labels = [\"technology\", \"science\", \"business\"]\n",
    "    \n",
    "    # Enhanced descriptive labels (hypothesis templates)\n",
    "    enhanced_labels = [\n",
    "        \"This text is about technology, software, or technical innovations\",\n",
    "        \"This text is about scientific research, discoveries, or academic studies\", \n",
    "        \"This text is about business, finance, or commercial activities\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Text: '{text}'\\n\")\n",
    "    \n",
    "    # Test standard approach\n",
    "    result_standard = classifier(text, candidate_labels=standard_labels)\n",
    "    print(\"Standard Labels:\")\n",
    "    for label, score in zip(result_standard['labels'], result_standard['scores']):\n",
    "        print(f\"  {label:12}: {score:.3f}\")\n",
    "    \n",
    "    # Test enhanced approach\n",
    "    result_enhanced = classifier(text, candidate_labels=enhanced_labels)\n",
    "    print(\"\\nEnhanced Labels (Hypothesis Templates):\")\n",
    "    enhanced_mapping = {enhanced_labels[i]: standard_labels[i] for i in range(len(standard_labels))}\n",
    "    for label, score in zip(result_enhanced['labels'], result_enhanced['scores']):\n",
    "        original_label = enhanced_mapping.get(label, label)\n",
    "        print(f\"  {original_label:12}: {score:.3f}\")\n",
    "    \n",
    "    # 2. Multi-label Classification Simulation\n",
    "    print(\"\\n\\n2Ô∏è‚É£ Multi-label Classification Approach\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    multi_text = \"The university announced a new AI research program with industry partnerships\"\n",
    "    potential_labels = [\"education\", \"technology\", \"business\", \"research\"]\n",
    "    \n",
    "    print(f\"Text: '{multi_text}'\\n\")\n",
    "    print(\"Checking each label independently:\")\n",
    "    \n",
    "    relevant_labels = []\n",
    "    for label in potential_labels:\n",
    "        # Check if text belongs to this label vs \"other topics\"\n",
    "        binary_result = classifier(\n",
    "            multi_text, \n",
    "            candidate_labels=[f\"This is about {label}\", \"This is about other topics\"]\n",
    "        )\n",
    "        \n",
    "        if binary_result['labels'][0].startswith(\"This is about \" + label):\n",
    "            score = binary_result['scores'][0]\n",
    "            print(f\"  {label:12}: {score:.3f} ‚úì\")\n",
    "            if score > 0.6:  # Threshold for relevance\n",
    "                relevant_labels.append((label, score))\n",
    "        else:\n",
    "            score = binary_result['scores'][1]  # Score for \"other topics\"\n",
    "            print(f\"  {label:12}: {1-score:.3f}\")\n",
    "    \n",
    "    print(f\"\\nRelevant labels (>0.6 threshold): {[label for label, _ in relevant_labels]}\")\n",
    "    \n",
    "    # 3. Confidence Thresholding\n",
    "    print(\"\\n\\n3Ô∏è‚É£ Confidence Thresholding for Quality Control\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    test_cases = [\n",
    "        \"Machine learning algorithms are transforming healthcare\",  # Clear case\n",
    "        \"The weather today is quite nice for a walk\",  # Ambiguous case\n",
    "        \"Quantum computing might revolutionize cryptography\"  # Moderate case\n",
    "    ]\n",
    "    \n",
    "    confidence_threshold = 0.7\n",
    "    labels = [\"technology\", \"health\", \"lifestyle\", \"science\"]\n",
    "    \n",
    "    for i, text in enumerate(test_cases, 1):\n",
    "        result = classifier(text, candidate_labels=labels)\n",
    "        top_label = result['labels'][0]\n",
    "        confidence = result['scores'][0]\n",
    "        \n",
    "        status = \"‚úÖ AUTO\" if confidence >= confidence_threshold else \"‚ö†Ô∏è  REVIEW\"\n",
    "        print(f\"\\n  Case {i}: '{text[:40]}...'\")\n",
    "        print(f\"    Prediction: {top_label} ({confidence:.3f}) {status}\")\n",
    "        \n",
    "        if confidence < confidence_threshold:\n",
    "            print(f\"    ‚Üí Requires manual review (confidence < {confidence_threshold})\")\n",
    "\n",
    "# Run advanced techniques demonstration\n",
    "demonstrate_advanced_techniques()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Performance Analysis and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_analysis_and_best_practices():\n",
    "    \"\"\"Provide comprehensive performance analysis and best practices.\"\"\"\n",
    "    \n",
    "    print(\"‚ö° PERFORMANCE ANALYSIS & BEST PRACTICES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nüöÄ MODEL COMPARISON (Typical Performance)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    model_comparison = pd.DataFrame({\n",
    "        'Model': ['BART-Large-MNLI', 'RoBERTa-Large-MNLI', 'DistilBERT-MNLI', 'MobileBERT-MNLI'],\n",
    "        'Parameters': ['400M', '355M', '67M', '25M'],\n",
    "        'CPU Speed': ['~2.5s', '~2.0s', '~0.8s', '~0.3s'],\n",
    "        'GPU Speed': ['~0.3s', '~0.25s', '~0.1s', '~0.05s'],\n",
    "        'Accuracy': ['High', 'High', 'Med-High', 'Medium']\n",
    "    })\n",
    "    \n",
    "    print(model_comparison.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nüéØ BEST PRACTICES CHECKLIST\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    best_practices = {\n",
    "        \"Label Design\": [\n",
    "            \"‚úì Use clear, descriptive labels\",\n",
    "            \"‚úì Make labels mutually exclusive\",\n",
    "            \"‚úì Consider hypothesis templates for complex cases\",\n",
    "            \"‚úì Test different label formulations\"\n",
    "        ],\n",
    "        \"Quality Control\": [\n",
    "            \"‚úì Set confidence thresholds (e.g., >0.7 for auto-processing)\",\n",
    "            \"‚úì Manually review low-confidence predictions\",\n",
    "            \"‚úì Monitor performance metrics over time\",\n",
    "            \"‚úì Validate on representative test sets\"\n",
    "        ],\n",
    "        \"Production Deployment\": [\n",
    "            \"‚úì Use batch processing for better throughput\",\n",
    "            \"‚úì Implement caching for repeated classifications\",\n",
    "            \"‚úì Monitor inference times and resource usage\",\n",
    "            \"‚úì Have fallback strategies for edge cases\"\n",
    "        ],\n",
    "        \"Model Selection\": [\n",
    "            \"‚úì Balance accuracy vs speed requirements\",\n",
    "            \"‚úì Consider domain-specific models when available\",\n",
    "            \"‚úì Test multiple models on your specific data\",\n",
    "            \"‚úì Use smaller models for real-time applications\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, practices in best_practices.items():\n",
    "        print(f\"\\nüìã {category}:\")\n",
    "        for practice in practices:\n",
    "            print(f\"  {practice}\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  COMMON PITFALLS TO AVOID\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    pitfalls = [\n",
    "        \"‚ùå Using too many labels (>15-20) - reduces accuracy\",\n",
    "        \"‚ùå Labels that are too similar or overlapping\",\n",
    "        \"‚ùå Ignoring confidence scores\",\n",
    "        \"‚ùå Not validating on real data from your domain\",\n",
    "        \"‚ùå Assuming zero-shot works perfectly without testing\",\n",
    "        \"‚ùå Not considering model bias and limitations\"\n",
    "    ]\n",
    "    \n",
    "    for pitfall in pitfalls:\n",
    "        print(f\"  {pitfall}\")\n",
    "    \n",
    "    print(\"\\nüîß OPTIMIZATION TIPS\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    optimization_tips = [\n",
    "        \"‚ö° Batch similar texts together\",\n",
    "        \"‚ö° Cache results for repeated text-label pairs\", \n",
    "        \"‚ö° Use GPU when available for faster inference\",\n",
    "        \"‚ö° Consider model quantization for deployment\",\n",
    "        \"‚ö° Implement async processing for better UX\"\n",
    "    ]\n",
    "    \n",
    "    for tip in optimization_tips:\n",
    "        print(f\"  {tip}\")\n",
    "\n",
    "# Run performance analysis\n",
    "performance_analysis_and_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Summary\n",
    "\n",
    "### üîë Key Concepts Mastered\n",
    "- **Zero-Shot Classification**: Understanding how to classify text without training data\n",
    "- **Natural Language Inference**: Using NLI models as the foundation for zero-shot tasks  \n",
    "- **Pipeline Usage**: Leveraging HuggingFace pipelines for rapid prototyping\n",
    "- **Confidence Analysis**: Interpreting and using confidence scores for quality control\n",
    "- **Real-World Applications**: Implementing solutions for practical business problems\n",
    "- **Performance Optimization**: Balancing speed and accuracy for production use\n",
    "\n",
    "### üìà Best Practices Learned\n",
    "- Design clear, descriptive labels for better classification accuracy\n",
    "- Use hypothesis templates to improve model understanding in complex cases\n",
    "- Monitor confidence scores for quality control and human review triggers\n",
    "- Implement batch processing for better throughput in production systems\n",
    "- Regular validation on representative test data is crucial for maintaining performance\n",
    "- Choose models based on your specific speed vs accuracy requirements\n",
    "\n",
    "### üöÄ Next Steps\n",
    "- **Notebook 03**: Working with the Datasets library for more complex data handling\n",
    "- **Notebook 05**: Fine-tuning models for improved performance on specific domains\n",
    "- **Advanced Topics**: Explore few-shot learning and custom NLI model development\n",
    "- **Production Deployment**: Implement zero-shot classification in real applications\n",
    "\n",
    "Zero-shot classification is a powerful technique that opens up many possibilities for rapid text classification without the need for labeled training data. The concepts and techniques learned in this notebook provide a solid foundation for more advanced NLP applications and production deployments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## About the Author\n",
    "\n",
    "**Vu Hung Nguyen** - AI Engineer & Researcher\n",
    "\n",
    "Connect with me:\n",
    "- üåê **Website**: [vuhung16au.github.io](https://vuhung16au.github.io/)\n",
    "- üíº **LinkedIn**: [linkedin.com/in/nguyenvuhung](https://www.linkedin.com/in/nguyenvuhung/)\n",
    "- üíª **GitHub**: [github.com/vuhung16au](https://github.com/vuhung16au/)\n",
    "\n",
    "*This notebook is part of the [HF Transformer Trove](https://github.com/vuhung16au/hf-transformer-trove) educational series.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}