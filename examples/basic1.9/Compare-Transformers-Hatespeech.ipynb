{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.9/Compare-Transformers-Hatespeech.ipynb)\n",
    "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.9/Compare-Transformers-Hatespeech.ipynb)\n",
    "\n",
    "# Comparison of Transformer Architectures for Hate Speech Detection\n",
    "\n",
    "## \ud83c\udfaf Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- How different transformer architectures perform on hate speech classification\n",
    "- Practical differences between encoder-only, decoder-only, and encoder-decoder models\n",
    "- When to choose each architecture for classification tasks\n",
    "- How to evaluate and compare model performance\n",
    "- Best practices for hate speech detection systems\n",
    "\n",
    "## \ud83d\udccb Prerequisites\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with Python and PyTorch\n",
    "- Knowledge of NLP fundamentals (refer to [NLP Learning Journey](https://github.com/vuhung16au/nlp-learning-journey))\n",
    "- Understanding of transformer architectures\n",
    "\n",
    "## \ud83d\udcda What We'll Cover\n",
    "1. **Setup**: Environment and dependencies\n",
    "2. **Test Data**: Creating a comprehensive test dataset\n",
    "3. **Encoder-Only**: BERT/RoBERTa for classification\n",
    "4. **Decoder-Only**: GPT-2 with prompting strategies\n",
    "5. **Encoder-Decoder**: T5 for text classification\n",
    "6. **Comparison**: Side-by-side performance analysis\n",
    "7. **Evaluation**: Metrics and best practices\n",
    "8. **Recommendations**: When to use each architecture\n",
    "9. **Summary**: Key takeaways\n",
    "\n",
    "## \ud83c\udfd7\ufe0f Architecture Overview\n",
    "\n",
    "We'll compare three fundamental transformer architectures:\n",
    "\n",
    "### \ud83d\udd0d Encoder-Only (BERT-like)\n",
    "- **Strengths**: Excellent for classification, bidirectional context\n",
    "- **Models**: BERT, RoBERTa, DistilBERT\n",
    "- **Use Case**: Traditional hate speech detection\n",
    "\n",
    "### \ud83c\udfad Decoder-Only (GPT-like)\n",
    "- **Strengths**: Flexible prompting, few-shot learning\n",
    "- **Models**: GPT-2, DistilGPT-2\n",
    "- **Use Case**: Zero/few-shot classification via prompting\n",
    "\n",
    "### \ud83d\udd04 Encoder-Decoder (T5-like)\n",
    "- **Strengths**: Text-to-text framework, flexible outputs\n",
    "- **Models**: T5, FLAN-T5, BART\n",
    "- **Use Case**: Classification as text generation task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install transformers torch datasets evaluate scikit-learn matplotlib seaborn pandas numpy tqdm\n",
    "\n",
    "# Core imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Hugging Face ecosystem\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    AutoModelForCausalLM, T5ForConditionalGeneration,\n",
    "    pipeline, set_seed\n",
    ")\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import evaluate\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "set_seed(42)\n",
    "\n",
    "print(\"\u2705 All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device detection with educational output\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Automatically detect and return the best available device.\n",
    "    \n",
    "    Priority: CUDA > MPS (Apple Silicon) > CPU\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for current hardware\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"\ud83d\ude80 Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "        print(f\"   Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"\ud83c\udf4e Using Apple MPS (Apple Silicon) for GPU acceleration\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"\ud83d\udcbb Using CPU - consider GPU for better performance\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Get optimal device\n",
    "device = get_device()\n",
    "print(f\"\ud83d\udcf1 Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Creation\n",
    "\n",
    "Let's create a comprehensive test dataset that includes various types of content, from clearly positive to potentially problematic, allowing us to evaluate how each architecture handles different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive test dataset for hate speech detection\n",
    "test_data = {\n",
    "    \"Clearly Positive\": [\n",
    "        \"I love Sydney\",\n",
    "        \"Melbourne has beautiful architecture\",\n",
    "        \"Brisbane is a wonderful city to visit\",\n",
    "        \"Perth has amazing beaches\",\n",
    "        \"Thank you for your help and support\"\n",
    "    ],\n",
    "    \n",
    "    \"Neutral/Informative\": [\n",
    "        \"The weather in Sydney today is cloudy\",\n",
    "        \"Melbourne's population is approximately 5 million\",\n",
    "        \"The conference will be held in Brisbane\",\n",
    "        \"Flight tickets to Perth are available online\",\n",
    "        \"The meeting is scheduled for tomorrow\"\n",
    "    ],\n",
    "    \n",
    "    \"Mild Criticism\": [\n",
    "        \"I hate Melbourne traffic during rush hour\", \n",
    "        \"Sydney's housing prices are too expensive\",\n",
    "        \"Brisbane's public transport could be improved\",\n",
    "        \"Perth feels too isolated from other cities\",\n",
    "        \"This policy decision seems poorly thought out\"\n",
    "    ],\n",
    "    \n",
    "    \"Strong Negative (Non-Toxic)\": [\n",
    "        \"I strongly disagree with this approach\",\n",
    "        \"This service was terrible and disappointing\",\n",
    "        \"The customer support was unhelpful\",\n",
    "        \"I hate waiting in long queues\",\n",
    "        \"This movie was boring and poorly made\"\n",
    "    ],\n",
    "    \n",
    "    \"Potentially Problematic\": [\n",
    "        \"People from that country are all the same\",\n",
    "        \"I can't stand people who think differently\",\n",
    "        \"Those protesters should be silenced\",\n",
    "        \"Nobody wants to hear your opinion\",\n",
    "        \"You people always complain about everything\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten the test data for processing\n",
    "all_texts = []\n",
    "categories = []\n",
    "expected_labels = []\n",
    "\n",
    "# Define expected toxicity levels (0=safe, 1=toxic)\n",
    "category_toxicity = {\n",
    "    \"Clearly Positive\": 0,\n",
    "    \"Neutral/Informative\": 0,\n",
    "    \"Mild Criticism\": 0,  # Criticism but not toxic\n",
    "    \"Strong Negative (Non-Toxic)\": 0,  # Strong but not hateful\n",
    "    \"Potentially Problematic\": 1  # Potentially toxic content\n",
    "}\n",
    "\n",
    "for category, texts in test_data.items():\n",
    "    for text in texts:\n",
    "        all_texts.append(text)\n",
    "        categories.append(category)\n",
    "        expected_labels.append(category_toxicity[category])\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "test_df = pd.DataFrame({\n",
    "    'text': all_texts,\n",
    "    'category': categories,\n",
    "    'expected_toxic': expected_labels\n",
    "})\n",
    "\n",
    "print(f\"\ud83d\udcca Test Dataset Summary:\")\n",
    "print(f\"   Total samples: {len(test_df)}\")\n",
    "print(f\"   Categories: {list(test_data.keys())}\")\n",
    "print(f\"   Expected toxic samples: {sum(expected_labels)}\")\n",
    "print(f\"   Expected safe samples: {len(expected_labels) - sum(expected_labels)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n\ud83d\udcdd Sample Test Data:\")\n",
    "for category, texts in test_data.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for i, text in enumerate(texts[:2], 1):  # Show first 2 examples\n",
    "        print(f\"  {i}. \\\"{text}\\\"\")\n",
    "    if len(texts) > 2:\n",
    "        print(f\"  ... and {len(texts)-2} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Encoder-Only Architecture: BERT for Hate Speech Detection\n",
    "\n",
    "Encoder-only models excel at classification tasks. We'll use a pre-trained model specifically fine-tuned for toxicity detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Only Implementation\n",
    "print(\"\ud83d\udce5 Loading Encoder-Only model for hate speech detection...\")\n",
    "\n",
    "try:\n",
    "    # Try to load a toxicity-specific model\n",
    "    encoder_model = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=\"unitary/toxic-bert\",\n",
    "        device=0 if device.type == \"cuda\" else -1,\n",
    "        return_all_scores=True\n",
    "    )\n",
    "    encoder_model_name = \"unitary/toxic-bert\"\n",
    "    print(\"\u2705 Loaded toxic-bert model successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Could not load toxic-bert, using fallback: {e}\")\n",
    "    # Fallback to a general sentiment model\n",
    "    encoder_model = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "        device=0 if device.type == \"cuda\" else -1,\n",
    "        return_all_scores=True\n",
    "    )\n",
    "    encoder_model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest (fallback)\"\n",
    "    print(\"\u2705 Loaded sentiment model as fallback\")\n",
    "\n",
    "print(f\"\ud83d\udcca Model: {encoder_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfad Decoder-Only Architecture: GPT-2 with Prompting\n",
    "\n",
    "For decoder-only models, we'll use prompting to perform classification. This demonstrates how modern LLMs handle classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder-Only Implementation\n",
    "print(\"\ud83d\udce5 Loading Decoder-Only model for prompted classification...\")\n",
    "\n",
    "try:\n",
    "    # Load a smaller GPT model for demonstration\n",
    "    decoder_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "    decoder_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "    \n",
    "    # Add pad token if not present\n",
    "    if decoder_tokenizer.pad_token is None:\n",
    "        decoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n",
    "    \n",
    "    decoder_model.to(device)\n",
    "    decoder_model.eval()\n",
    "    \n",
    "    decoder_model_name = \"distilgpt2\"\n",
    "    print(\"\u2705 Loaded DistilGPT-2 model successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Could not load decoder model: {e}\")\n",
    "    decoder_model = None\n",
    "    decoder_model_name = \"Not available\"\n",
    "\n",
    "def classify_with_prompting(text: str) -> dict:\n",
    "    \"\"\"Use GPT-2 with prompting for classification.\"\"\"\n",
    "    if decoder_model is None:\n",
    "        return {'toxic_score': 0.5, 'is_toxic': False, 'confidence': 0.0, 'error': 'Model not available'}\n",
    "    \n",
    "    # Create a classification prompt\n",
    "    prompt = f\"\"\"Text: \"{text}\"\n",
    "Question: Is this text toxic or safe?\n",
    "Answer: This text is\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Tokenize and generate\n",
    "        inputs = decoder_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=200).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = decoder_model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=inputs.input_ids.shape[1] + 10,\n",
    "                num_return_sequences=1,\n",
    "                temperature=0.3,\n",
    "                do_sample=True,\n",
    "                pad_token_id=decoder_tokenizer.eos_token_id,\n",
    "                attention_mask=inputs.attention_mask\n",
    "            )\n",
    "        \n",
    "        # Decode and analyze response\n",
    "        generated = decoder_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        completion = generated[len(prompt):].strip().lower()\n",
    "        \n",
    "        # Simple heuristic classification\n",
    "        toxic_indicators = ['toxic', 'harmful', 'bad', 'inappropriate', 'offensive']\n",
    "        safe_indicators = ['safe', 'fine', 'okay', 'normal', 'appropriate']\n",
    "        \n",
    "        if any(word in completion for word in toxic_indicators):\n",
    "            toxic_score = 0.8\n",
    "        elif any(word in completion for word in safe_indicators):\n",
    "            toxic_score = 0.2\n",
    "        else:\n",
    "            toxic_score = 0.5  # Neutral/uncertain\n",
    "        \n",
    "        return {\n",
    "            'toxic_score': toxic_score,\n",
    "            'is_toxic': toxic_score > 0.5,\n",
    "            'confidence': abs(toxic_score - 0.5) * 2,\n",
    "            'completion': completion[:100]  # Truncate for display\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'toxic_score': 0.5, 'is_toxic': False, 'confidence': 0.0, 'error': str(e)}\n",
    "\n",
    "print(f\"\ud83d\udcca Model: {decoder_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd04 Encoder-Decoder Architecture: T5 for Text Classification\n",
    "\n",
    "Encoder-decoder models like T5 treat classification as a text-to-text task, generating class labels as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Decoder Implementation\n",
    "print(\"\ud83d\udce5 Loading Encoder-Decoder model for text-to-text classification...\")\n",
    "\n",
    "try:\n",
    "    # Try to load FLAN-T5 which is instruction-tuned\n",
    "    encoder_decoder_model = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"google/flan-t5-small\",\n",
    "        device=0 if device.type == \"cuda\" else -1,\n",
    "        max_length=50\n",
    "    )\n",
    "    encoder_decoder_model_name = \"google/flan-t5-small\"\n",
    "    print(\"\u2705 Loaded FLAN-T5-small model successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Could not load FLAN-T5, trying T5-small: {e}\")\n",
    "    try:\n",
    "        encoder_decoder_model = pipeline(\n",
    "            \"text2text-generation\",\n",
    "            model=\"t5-small\",\n",
    "            device=0 if device.type == \"cuda\" else -1,\n",
    "            max_length=50\n",
    "        )\n",
    "        encoder_decoder_model_name = \"t5-small (fallback)\"\n",
    "        print(\"\u2705 Loaded T5-small as fallback\")\n",
    "    except Exception as e2:\n",
    "        print(f\"\u274c Could not load encoder-decoder model: {e2}\")\n",
    "        encoder_decoder_model = None\n",
    "        encoder_decoder_model_name = \"Not available\"\n",
    "\n",
    "def classify_with_text2text(text: str) -> dict:\n",
    "    \"\"\"Use T5 for text-to-text classification.\"\"\"\n",
    "    if encoder_decoder_model is None:\n",
    "        return {'toxic_score': 0.5, 'is_toxic': False, 'confidence': 0.0, 'error': 'Model not available'}\n",
    "    \n",
    "    # Create text-to-text prompt\n",
    "    prompt = f\"Classify this text as 'safe' or 'toxic': {text}\"\n",
    "    \n",
    "    try:\n",
    "        # Generate classification\n",
    "        result = encoder_decoder_model(prompt, max_length=10, num_return_sequences=1)\n",
    "        generated_text = result[0]['generated_text'].strip().lower()\n",
    "        \n",
    "        # Parse the result\n",
    "        if 'toxic' in generated_text:\n",
    "            toxic_score = 0.8\n",
    "        elif 'safe' in generated_text:\n",
    "            toxic_score = 0.2\n",
    "        else:\n",
    "            # Fallback analysis\n",
    "            negative_words = ['bad', 'negative', 'harmful', 'inappropriate']\n",
    "            if any(word in generated_text for word in negative_words):\n",
    "                toxic_score = 0.7\n",
    "            else:\n",
    "                toxic_score = 0.5\n",
    "        \n",
    "        return {\n",
    "            'toxic_score': toxic_score,\n",
    "            'is_toxic': toxic_score > 0.5,\n",
    "            'confidence': abs(toxic_score - 0.5) * 2,\n",
    "            'generated_text': generated_text\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'toxic_score': 0.5, 'is_toxic': False, 'confidence': 0.0, 'error': str(e)}\n",
    "\n",
    "print(f\"\ud83d\udcca Model: {encoder_decoder_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Running All Models and Comparison\n",
    "\n",
    "Now let's run all three architectures on our test dataset and create a comprehensive comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all models on test data and create comparison\n",
    "print(\"\ufffd\ufffd Running comprehensive comparison across all architectures...\\n\")\n",
    "\n",
    "# Initialize results storage\n",
    "results_comparison = []\n",
    "\n",
    "print(\"Processing texts with all models...\")\n",
    "for i, text in enumerate(tqdm(all_texts, desc=\"Processing\")):\n",
    "    row = {\n",
    "        'Text': text[:50] + '...' if len(text) > 50 else text,\n",
    "        'Full_Text': text,\n",
    "        'Category': categories[i],\n",
    "        'Expected_Toxic': bool(expected_labels[i])\n",
    "    }\n",
    "    \n",
    "    # Encoder-Only Results\n",
    "    try:\n",
    "        enc_result = encoder_model(text)\n",
    "        if 'toxic' in encoder_model_name.lower():\n",
    "            # Toxic-BERT model\n",
    "            toxic_score = next((p['score'] for p in enc_result if p['label'] == 'TOXIC'), 0)\n",
    "        else:\n",
    "            # Sentiment model fallback\n",
    "            negative_score = next((p['score'] for p in enc_result if p['label'] in ['NEGATIVE', 'LABEL_0']), 0)\n",
    "            toxic_score = negative_score\n",
    "        \n",
    "        row.update({\n",
    "            'Encoder_Toxic': toxic_score > 0.5,\n",
    "            'Encoder_Score': f\"{toxic_score:.3f}\",\n",
    "            'Encoder_Confidence': f\"{max(p['score'] for p in enc_result):.3f}\"\n",
    "        })\n",
    "    except Exception as e:\n",
    "        row.update({\n",
    "            'Encoder_Toxic': False,\n",
    "            'Encoder_Score': '0.500',\n",
    "            'Encoder_Confidence': '0.000'\n",
    "        })\n",
    "    \n",
    "    # Decoder-Only Results\n",
    "    dec_result = classify_with_prompting(text)\n",
    "    row.update({\n",
    "        'Decoder_Toxic': dec_result['is_toxic'],\n",
    "        'Decoder_Score': f\"{dec_result['toxic_score']:.3f}\",\n",
    "        'Decoder_Confidence': f\"{dec_result['confidence']:.3f}\"\n",
    "    })\n",
    "    \n",
    "    # Encoder-Decoder Results\n",
    "    ed_result = classify_with_text2text(text)\n",
    "    row.update({\n",
    "        'EncDec_Toxic': ed_result['is_toxic'],\n",
    "        'EncDec_Score': f\"{ed_result['toxic_score']:.3f}\",\n",
    "        'EncDec_Confidence': f\"{ed_result['confidence']:.3f}\"\n",
    "    })\n",
    "    \n",
    "    results_comparison.append(row)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results_comparison)\n",
    "\n",
    "print(\"\\n\u2705 All models completed! Results ready for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Results Table Comparison\n",
    "\n",
    "Here's the comprehensive comparison table showing how each architecture performed on our test cases, including **\"I love Sydney\"** and **\"I hate Melbourne traffic\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive results table\n",
    "print(\"\ud83d\udccb COMPREHENSIVE RESULTS COMPARISON TABLE\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Create a clean display DataFrame\n",
    "display_columns = ['Text', 'Category', 'Expected_Toxic', \n",
    "                  'Encoder_Toxic', 'Encoder_Score',\n",
    "                  'Decoder_Toxic', 'Decoder_Score', \n",
    "                  'EncDec_Toxic', 'EncDec_Score']\n",
    "\n",
    "display_df = results_df[display_columns].copy()\n",
    "print(display_df.to_string(index=False, max_colwidth=40))\n",
    "\n",
    "# Calculate accuracy for each model\n",
    "encoder_predictions = [bool(row['Encoder_Toxic']) for _, row in results_df.iterrows()]\n",
    "decoder_predictions = [bool(row['Decoder_Toxic']) for _, row in results_df.iterrows()]\n",
    "encdec_predictions = [bool(row['EncDec_Toxic']) for _, row in results_df.iterrows()]\n",
    "\n",
    "encoder_accuracy = accuracy_score(expected_labels, encoder_predictions)\n",
    "decoder_accuracy = accuracy_score(expected_labels, decoder_predictions)\n",
    "encdec_accuracy = accuracy_score(expected_labels, encdec_predictions)\n",
    "\n",
    "print(\"\\n\\n\ud83d\udcca OVERALL ACCURACY SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\ud83d\udd0d Encoder-Only ({encoder_model_name[:30]}...): {encoder_accuracy:.3f}\")\n",
    "print(f\"\ud83c\udfad Decoder-Only ({decoder_model_name}): {decoder_accuracy:.3f}\")\n",
    "print(f\"\ud83d\udd04 Encoder-Decoder ({encoder_decoder_model_name}): {encdec_accuracy:.3f}\")\n",
    "\n",
    "# Highlight specific examples\n",
    "print(\"\\n\\n\ud83c\udfaf SPECIFIC EXAMPLES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "key_examples = [\"I love Sydney\", \"I hate Melbourne traffic during rush hour\", \n",
    "               \"I strongly disagree with this approach\", \"People from that country are all the same\"]\n",
    "\n",
    "for example in key_examples:\n",
    "    matching_rows = results_df[results_df['Full_Text'] == example]\n",
    "    if not matching_rows.empty:\n",
    "        row = matching_rows.iloc[0]\n",
    "        print(f\"\\n\ud83d\udcdd \\\"{example}\\\"\")\n",
    "        print(f\"   Expected: {'Toxic' if row['Expected_Toxic'] else 'Safe'}\")\n",
    "        print(f\"   \ud83d\udd0d Encoder: {'Toxic' if row['Encoder_Toxic'] else 'Safe'} ({row['Encoder_Score']})\")\n",
    "        print(f\"   \ud83c\udfad Decoder: {'Toxic' if row['Decoder_Toxic'] else 'Safe'} ({row['Decoder_Score']})\")\n",
    "        print(f\"   \ud83d\udd04 Enc-Dec: {'Toxic' if row['EncDec_Toxic'] else 'Safe'} ({row['EncDec_Score']})\")\n",
    "        \n",
    "        # Check agreement\n",
    "        predictions = [row['Encoder_Toxic'], row['Decoder_Toxic'], row['EncDec_Toxic']]\n",
    "        if len(set(predictions)) == 1:\n",
    "            print(f\"   \u2705 All models agree!\")\n",
    "        else:\n",
    "            print(f\"   \u26a0\ufe0f Models disagree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Performance Analysis and Recommendations\n",
    "\n",
    "Let's analyze the results and provide recommendations for when to use each architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis and grading\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "def analyze_performance(predictions, expected, model_name):\n",
    "    \"\"\"Analyze model performance with comprehensive metrics.\"\"\"\n",
    "    accuracy = accuracy_score(expected, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(expected, predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(expected, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "    \n",
    "    # Grade the model\n",
    "    if accuracy >= 0.9 and f1 >= 0.85:\n",
    "        grade = \"\ud83d\udfe2 Excellent\"\n",
    "    elif accuracy >= 0.8 and f1 >= 0.75:\n",
    "        grade = \"\ud83d\udfe1 Good\"\n",
    "    elif accuracy >= 0.7 and f1 >= 0.6:\n",
    "        grade = \"\ud83d\udfe0 Fair\"\n",
    "    else:\n",
    "        grade = \"\ud83d\udd34 Needs Improvement\"\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'true_pos': tp,\n",
    "        'false_pos': fp,\n",
    "        'true_neg': tn,\n",
    "        'false_neg': fn,\n",
    "        'grade': grade\n",
    "    }\n",
    "\n",
    "# Analyze each model\n",
    "encoder_analysis = analyze_performance(encoder_predictions, expected_labels, \"Encoder-Only\")\n",
    "decoder_analysis = analyze_performance(decoder_predictions, expected_labels, \"Decoder-Only\")\n",
    "encdec_analysis = analyze_performance(encdec_predictions, expected_labels, \"Encoder-Decoder\")\n",
    "\n",
    "analyses = [encoder_analysis, decoder_analysis, encdec_analysis]\n",
    "\n",
    "print(\"\ud83d\udcca DETAILED PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create performance comparison table\n",
    "perf_data = []\n",
    "for analysis in analyses:\n",
    "    perf_data.append({\n",
    "        'Architecture': analysis['model'],\n",
    "        'Grade': analysis['grade'],\n",
    "        'Accuracy': f\"{analysis['accuracy']:.3f}\",\n",
    "        'Precision': f\"{analysis['precision']:.3f}\",\n",
    "        'Recall': f\"{analysis['recall']:.3f}\",\n",
    "        'F1-Score': f\"{analysis['f1_score']:.3f}\",\n",
    "        'True Pos': analysis['true_pos'],\n",
    "        'False Pos': analysis['false_pos']\n",
    "    })\n",
    "\n",
    "perf_df = pd.DataFrame(perf_data)\n",
    "print(perf_df.to_string(index=False))\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n\\n\ud83c\udfc6 ARCHITECTURE RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_model = max(analyses, key=lambda x: x['f1_score'])\n",
    "print(f\"\\n\ud83e\udd47 **Best Overall Performance**: {best_model['model']} ({best_model['grade']})\")\n",
    "print(f\"   F1-Score: {best_model['f1_score']:.3f} | Accuracy: {best_model['accuracy']:.3f}\")\n",
    "\n",
    "recommendations = {\n",
    "    \"\ud83d\udd0d Encoder-Only (BERT/RoBERTa)\": [\n",
    "        \"\u2705 Best for: Production hate speech detection systems\",\n",
    "        \"\u2705 Advantages: Fast, reliable, specifically designed for classification\",\n",
    "        \"\u26a0\ufe0f Limitations: Requires fine-tuning, less flexible for new tasks\",\n",
    "        \"\ud83d\udcca Use when: You have labeled data and need consistent performance\"\n",
    "    ],\n",
    "    \"\ud83c\udfad Decoder-Only (GPT-2/GPT)\": [\n",
    "        \"\u2705 Best for: Exploratory analysis, zero-shot classification\",\n",
    "        \"\u2705 Advantages: No fine-tuning needed, flexible prompting\",\n",
    "        \"\u26a0\ufe0f Limitations: Inconsistent, slower, requires prompt engineering\",\n",
    "        \"\ud83d\udcca Use when: You lack labeled data or need quick prototyping\"\n",
    "    ],\n",
    "    \"\ud83d\udd04 Encoder-Decoder (T5/BART)\": [\n",
    "        \"\u2705 Best for: Multi-task systems, classification with explanations\",\n",
    "        \"\u2705 Advantages: Text-to-text flexibility, can generate reasoning\",\n",
    "        \"\u26a0\ufe0f Limitations: Overkill for simple classification, slower inference\",\n",
    "        \"\ud83d\udcca Use when: You need both classification and explanation generation\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for arch, points in recommendations.items():\n",
    "    print(f\"\\n{arch}\")\n",
    "    for point in points:\n",
    "        print(f\"   {point}\")\n",
    "\n",
    "print(f\"\\n\\n\ud83d\udca1 **Key Takeaway**: The choice between architectures depends on your specific\")\n",
    "print(f\"    requirements: accuracy vs. flexibility vs. speed vs. explainability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udccb Summary\n",
    "\n",
    "### \ud83d\udd11 Key Concepts Mastered\n",
    "- **Architecture Comparison**: Practical differences between encoder-only, decoder-only, and encoder-decoder models for hate speech detection\n",
    "- **Evaluation Methodology**: Comprehensive approach to assess classification performance using multiple metrics\n",
    "- **Model Selection**: Understanding when to choose each architecture based on requirements and constraints\n",
    "- **Performance Analysis**: How to interpret metrics and make data-driven decisions about model deployment\n",
    "\n",
    "### \ud83d\udcc8 Best Practices Learned\n",
    "- **Comprehensive Testing**: Use diverse test cases including edge cases and different content types\n",
    "- **Multiple Metrics**: Don't rely on accuracy alone - consider precision, recall, and F1-score\n",
    "- **Context Matters**: Different architectures excel in different scenarios and use cases\n",
    "- **Production Readiness**: Evaluate not just accuracy but also speed, reliability, and maintainability\n",
    "\n",
    "### \ud83d\ude80 Next Steps\n",
    "- **Fine-tuning**: Explore fine-tuning techniques for encoder-only models on domain-specific data\n",
    "- **Prompt Engineering**: Improve decoder-only performance through better prompt design\n",
    "- **Ensemble Methods**: Combine multiple architectures for robust hate speech detection\n",
    "- **Production Deployment**: Consider scalability, monitoring, and continuous improvement strategies\n",
    "\n",
    "### \ud83d\udd17 Related Resources\n",
    "- **[Encoder-Decoder Guide](../../docs/encoder-decoder.md)**: Detailed technical documentation\n",
    "- **[HF NLP Models](../../docs/HF-NLP-models.md)**: Comprehensive model recommendations\n",
    "- **[Best Practices](../../docs/best-practices.md)**: Production deployment guidelines\n",
    "\n",
    "---\n",
    "\n",
    "## About the Author\n",
    "\n",
    "**Vu Hung Nguyen** - AI Engineer & Researcher\n",
    "\n",
    "Connect with me:\n",
    "- \ud83c\udf10 **Website**: [vuhung16au.github.io](https://vuhung16au.github.io/)\n",
    "- \ud83d\udcbc **LinkedIn**: [linkedin.com/in/nguyenvuhung](https://www.linkedin.com/in/nguyenvuhung/)\n",
    "- \ud83d\udcbb **GitHub**: [github.com/vuhung16au](https://github.com/vuhung16au/)\n",
    "\n",
    "*This notebook is part of the [HF Transformer Trove](https://github.com/vuhung16au/hf-transformer-trove) educational series.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}