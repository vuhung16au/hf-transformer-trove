{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.6/machine-translation.ipynb)\n",
    "[![Open with SageMaker](https://img.shields.io/badge/Open%20with-SageMaker-orange?logo=amazonaws)](https://studiolab.sagemaker.aws/import/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.6/machine-translation.ipynb)\n",
    "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.6/machine-translation.ipynb)\n",
    "\n",
    "# 🌐 Machine Translation: Converting Text Between Languages\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- What machine translation is and its practical applications\n",
    "- How to use Marian models for neural machine translation\n",
    "- How to use T5 models for text-to-text translation\n",
    "- Vietnamese to English translation using modern transformer models\n",
    "- Comparison between different translation model architectures\n",
    "\n",
    "## 📋 Prerequisites\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with Python and PyTorch\n",
    "- Knowledge of NLP fundamentals (refer to [NLP Learning Journey](https://github.com/vuhung16au/nlp-learning-journey))\n",
    "\n",
    "## 📚 What We'll Cover\n",
    "1. **Introduction**: Machine translation concepts\n",
    "2. **Environment Setup**: Device detection and model loading\n",
    "3. **Marian Models**: Using Helsinki-NLP Marian models\n",
    "4. **T5 Models**: Text-to-text translation with T5\n",
    "5. **Translation Examples**: Vietnamese to English examples\n",
    "6. **Model Comparison**: Performance and quality analysis\n",
    "7. **Summary**: Key takeaways and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to Machine Translation\n",
    "\n",
    "**Machine Translation (MT)** is the task of automatically translating text from one language to another using computational methods. Modern neural machine translation uses transformer architectures to achieve high-quality translations.\n",
    "\n",
    "### 🔍 Key Model Types:\n",
    "\n",
    "**Marian Models:**\n",
    "- Specialized encoder-decoder architecture for translation\n",
    "- Trained on large parallel corpora (OPUS dataset)\n",
    "- Fast inference and good quality for specific language pairs\n",
    "\n",
    "**T5 Models:**\n",
    "- Text-to-Text Transfer Transformer approach\n",
    "- Treats translation as a text generation task\n",
    "- More flexible but requires task-specific prefixes\n",
    "\n",
    "### 🇻🇳 Why Vietnamese to English?\n",
    "- Vietnamese is a tonal language with unique linguistic features\n",
    "- Demonstrates challenges in translating between different language families\n",
    "- Growing importance in Southeast Asian technology markets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "import time\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"📦 Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device detection for optimal performance\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Automatically detect and return the best available device.\n",
    "    \n",
    "    Priority: CUDA > MPS (Apple Silicon) > CPU\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for current hardware\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"🚀 Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"🍎 Using Apple MPS (Apple Silicon)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"💻 Using CPU (consider GPU for better performance)\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Get optimal device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Marian Models for Translation\n",
    "\n",
    "Marian models are optimized for machine translation tasks. Let's load a Vietnamese to English Marian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Marian model for Vietnamese to English translation\n",
    "print(\"🔄 Loading Marian model for Vietnamese → English translation...\")\n",
    "print(\"This may take a few minutes on first run (downloading model)\")\n",
    "\n",
    "try:\n",
    "    # Using Helsinki-NLP OPUS Marian model\n",
    "    marian_model_name = \"Helsinki-NLP/opus-mt-vi-en\"\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    marian_tokenizer = MarianTokenizer.from_pretrained(marian_model_name)\n",
    "    marian_model = MarianMTModel.from_pretrained(marian_model_name)\n",
    "    \n",
    "    # Move model to optimal device\n",
    "    marian_model.to(device)\n",
    "    \n",
    "    # Create translation pipeline\n",
    "    marian_translator = pipeline(\n",
    "        \"translation\",\n",
    "        model=marian_model,\n",
    "        tokenizer=marian_tokenizer,\n",
    "        device=0 if device.type == 'cuda' else -1\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Marian model loaded successfully: {marian_model_name}\")\n",
    "    print(f\"📊 Model size: ~{marian_model.num_parameters():,} parameters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading Marian model: {e}\")\n",
    "    print(\"💡 Continuing with alternative approach...\")\n",
    "    marian_translator = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: T5 Models for Translation\n",
    "\n",
    "T5 treats every NLP task as a text-to-text problem. We'll use a multilingual T5 model for translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load T5 model for Vietnamese to English translation\n",
    "print(\"🔄 Loading T5 model for Vietnamese → English translation...\")\n",
    "print(\"This may take a few minutes on first run (downloading model)\")\n",
    "\n",
    "try:\n",
    "    # Using multilingual T5 model\n",
    "    t5_model_name = \"google/mt5-small\"\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_name)\n",
    "    t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_model_name)\n",
    "    \n",
    "    # Move model to optimal device\n",
    "    t5_model.to(device)\n",
    "    \n",
    "    print(f\"✅ T5 model loaded successfully: {t5_model_name}\")\n",
    "    print(f\"📊 Model size: ~{t5_model.num_parameters():,} parameters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading T5 model: {e}\")\n",
    "    print(\"💡 Continuing without T5 model...\")\n",
    "    t5_model = None\n",
    "    t5_tokenizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Translation Examples\n",
    "\n",
    "Let's translate some Vietnamese texts to English using our loaded models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Vietnamese texts for translation\n",
    "vietnamese_texts = [\n",
    "    \"Xin chào! Hôm nay bạn có khỏe không?\",\n",
    "    \"Tôi đang học về trí tuệ nhân tạo và học máy tại Đại học Sydney.\",\n",
    "    \"Thời tiết ở Sydney hôm nay rất đẹp. Bạn có muốn đi dạo quanh cảng không?\",\n",
    "    \"Việt Nam là một đất nước xinh đẹp với văn hóa phong phú.\",\n",
    "    \"Công nghệ máy học đang phát triển rất nhanh trong những năm gần đây.\"\n",
    "]\n",
    "\n",
    "print(\"📝 Vietnamese Texts to Translate:\")\n",
    "print(\"=\" * 50)\n",
    "for i, text in enumerate(vietnamese_texts, 1):\n",
    "    print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate using Marian model\n",
    "def translate_with_marian(texts: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Translate Vietnamese texts to English using Marian model.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of Vietnamese texts to translate\n",
    "        \n",
    "    Returns:\n",
    "        List of English translations\n",
    "    \"\"\"\n",
    "    if marian_translator is None:\n",
    "        return [\"Marian model not available\"] * len(texts)\n",
    "    \n",
    "    print(\"🔄 Translating with Marian model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    translations = []\n",
    "    for text in texts:\n",
    "        try:\n",
    "            result = marian_translator(text, max_length=512)\n",
    "            translation = result[0]['translation_text'] if result else \"Translation failed\"\n",
    "            translations.append(translation)\n",
    "        except Exception as e:\n",
    "            translations.append(f\"Error: {str(e)[:50]}...\")\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"⏱️ Marian translation completed in {duration:.2f} seconds\")\n",
    "    \n",
    "    return translations\n",
    "\n",
    "# Translate using Marian model\n",
    "marian_translations = translate_with_marian(vietnamese_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate using T5 model (manual implementation)\n",
    "def translate_with_t5(texts: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Translate Vietnamese texts to English using T5 model.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of Vietnamese texts to translate\n",
    "        \n",
    "    Returns:\n",
    "        List of English translations\n",
    "    \"\"\"\n",
    "    if t5_model is None or t5_tokenizer is None:\n",
    "        return [\"T5 model not available\"] * len(texts)\n",
    "    \n",
    "    print(\"🔄 Translating with T5 model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    translations = []\n",
    "    for text in texts:\n",
    "        try:\n",
    "            # T5 requires task prefix for translation\n",
    "            input_text = f\"translate Vietnamese to English: {text}\"\n",
    "            \n",
    "            # Tokenize input\n",
    "            inputs = t5_tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Generate translation\n",
    "            with torch.no_grad():\n",
    "                outputs = t5_model.generate(\n",
    "                    **inputs,\n",
    "                    max_length=256,\n",
    "                    num_beams=4,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "            \n",
    "            # Decode translation\n",
    "            translation = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            translations.append(translation)\n",
    "            \n",
    "        except Exception as e:\n",
    "            translations.append(f\"Error: {str(e)[:50]}...\")\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"⏱️ T5 translation completed in {duration:.2f} seconds\")\n",
    "    \n",
    "    return translations\n",
    "\n",
    "# Translate using T5 model\n",
    "t5_translations = translate_with_t5(vietnamese_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Translation Results and Comparison\n",
    "\n",
    "Let's compare the translations from both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display translation results\n",
    "print(\"🔍 TRANSLATION RESULTS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (original, marian_trans, t5_trans) in enumerate(zip(vietnamese_texts, marian_translations, t5_translations), 1):\n",
    "    print(f\"\\n📝 Example {i}:\")\n",
    "    print(f\"Vietnamese:  {original}\")\n",
    "    print(f\"Marian:      {marian_trans}\")\n",
    "    print(f\"T5:          {t5_trans}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Model Analysis and Best Practices\n",
    "\n",
    "Let's analyze the performance and characteristics of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison analysis\n",
    "def analyze_models():\n",
    "    \"\"\"\n",
    "    Provide analysis of different translation models.\n",
    "    \"\"\"\n",
    "    print(\"📊 MODEL ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    models_info = {\n",
    "        \"🎯 Marian Models (Helsinki-NLP/opus-mt-vi-en)\": {\n",
    "            \"Strengths\": [\n",
    "                \"• Specialized for translation tasks\",\n",
    "                \"• Fast inference speed\",\n",
    "                \"• Trained on high-quality OPUS parallel corpora\",\n",
    "                \"• Good performance for specific language pairs\"\n",
    "            ],\n",
    "            \"Use Cases\": [\n",
    "                \"• Production translation systems\",\n",
    "                \"• Real-time translation applications\",\n",
    "                \"• When speed is more important than flexibility\"\n",
    "            ]\n",
    "        },\n",
    "        \"🔄 T5 Models (google/mt5-small)\": {\n",
    "            \"Strengths\": [\n",
    "                \"• Unified text-to-text framework\",\n",
    "                \"• Multilingual capabilities\",\n",
    "                \"• Can be fine-tuned for specific domains\",\n",
    "                \"• More flexible for various NLP tasks\"\n",
    "            ],\n",
    "            \"Use Cases\": [\n",
    "                \"• Research and experimentation\",\n",
    "                \"• Multi-task applications\",\n",
    "                \"• When fine-tuning is needed\",\n",
    "                \"• Custom domain translation\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for model_name, info in models_info.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(\"\\nStrengths:\")\n",
    "        for strength in info[\"Strengths\"]:\n",
    "            print(f\"  {strength}\")\n",
    "        print(\"\\nBest Use Cases:\")\n",
    "        for use_case in info[\"Use Cases\"]:\n",
    "            print(f\"  {use_case}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "analyze_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices for machine translation\n",
    "def display_best_practices():\n",
    "    \"\"\"\n",
    "    Display best practices for machine translation.\n",
    "    \"\"\"\n",
    "    print(\"💡 MACHINE TRANSLATION BEST PRACTICES\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    practices = [\n",
    "        {\n",
    "            \"title\": \"🎯 Model Selection\",\n",
    "            \"tips\": [\n",
    "                \"• Use Marian for fast, production-ready translations\",\n",
    "                \"• Use T5 for research and when fine-tuning is needed\",\n",
    "                \"• Consider model size vs. performance trade-offs\",\n",
    "                \"• Test multiple models for your specific use case\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"📝 Text Preprocessing\",\n",
    "            \"tips\": [\n",
    "                \"• Clean and normalize input text\",\n",
    "                \"• Handle special characters and punctuation carefully\",\n",
    "                \"• Consider sentence segmentation for long texts\",\n",
    "                \"• Maintain formatting when possible\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"⚡ Performance Optimization\",\n",
    "            \"tips\": [\n",
    "                \"• Use GPU acceleration when available\",\n",
    "                \"• Batch multiple translations together\",\n",
    "                \"• Adjust max_length based on typical text length\",\n",
    "                \"• Consider model quantization for deployment\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"🔍 Quality Assurance\",\n",
    "            \"tips\": [\n",
    "                \"• Test with diverse text types and domains\",\n",
    "                \"• Compare outputs from multiple models\",\n",
    "                \"• Consider human evaluation for critical applications\",\n",
    "                \"• Monitor translation quality over time\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for practice in practices:\n",
    "        print(f\"\\n{practice['title']}:\")\n",
    "        for tip in practice['tips']:\n",
    "            print(f\"  {tip}\")\n",
    "\n",
    "display_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📋 Summary\n",
    "\n",
    "### 🔑 Key Concepts Mastered\n",
    "- **Machine Translation Fundamentals**: Understanding how neural machine translation works\n",
    "- **Marian Models**: Using specialized encoder-decoder models for fast, high-quality translation\n",
    "- **T5 Models**: Leveraging text-to-text frameworks for flexible translation tasks\n",
    "- **Vietnamese-English Translation**: Practical examples of translating between different language families\n",
    "\n",
    "### 📈 Best Practices Learned\n",
    "- Choose the right model architecture based on your specific needs and constraints\n",
    "- Consider performance trade-offs between speed, quality, and resource requirements\n",
    "- Implement proper error handling and fallback mechanisms\n",
    "- Test translations with diverse text types to ensure robust performance\n",
    "\n",
    "### 🚀 Next Steps\n",
    "- **Advanced Models**: Explore larger multilingual models like NLLB-200\n",
    "- **Fine-tuning**: Learn to fine-tune models on domain-specific data\n",
    "- **Bidirectional Translation**: Implement both Vietnamese↔English translation\n",
    "- **Evaluation Metrics**: Study BLEU, METEOR, and other translation quality metrics\n",
    "- **Production Deployment**: Build scalable translation APIs and services\n",
    "\n",
    "---\n",
    "\n",
    "## About the Author\n",
    "\n",
    "**Vu Hung Nguyen** - AI Engineer & Researcher\n",
    "\n",
    "Connect with me:\n",
    "- 🌐 **Website**: [vuhung16au.github.io](https://vuhung16au.github.io/)\n",
    "- 💼 **LinkedIn**: [linkedin.com/in/nguyenvuhung](https://www.linkedin.com/in/nguyenvuhung/)\n",
    "- 💻 **GitHub**: [github.com/vuhung16au](https://github.com/vuhung16au/)\n",
    "\n",
    "*This notebook is part of the [HF Transformer Trove](https://github.com/vuhung16au/hf-transformer-trove) educational series.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}