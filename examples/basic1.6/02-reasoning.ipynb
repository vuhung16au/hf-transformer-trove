{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.6/02-reasoning.ipynb)\n",
    "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.6/02-reasoning.ipynb)\n",
    "\n",
    "# 02 - Reasoning for Hate Speech Classification: Step-by-Step AI Analysis\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- **Chain-of-Thought (CoT) Prompting** for complex classification tasks\n",
    "- **Step-by-step reasoning** in AI systems for hate speech detection\n",
    "- **Context-aware analysis** of social media content\n",
    "- **Explainable AI** approaches for content moderation\n",
    "- **Policy-based reasoning** for transparent decision-making\n",
    "- **Comparison** between direct classification and reasoning-based approaches\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Basic understanding of transformer models and NLP\n",
    "- Familiarity with text classification concepts\n",
    "- Knowledge of prompt engineering basics\n",
    "- Understanding of content moderation challenges\n",
    "\n",
    "## üìö What We'll Cover\n",
    "1. **Introduction**: Understanding reasoning in AI classification\n",
    "2. **Chain-of-Thought Prompting**: Core concepts and implementation\n",
    "3. **Hate Speech Detection**: Traditional vs reasoning approaches\n",
    "4. **Step-by-Step Analysis**: Implementing reasoning pipelines\n",
    "5. **Policy-Based Reasoning**: Transparent content moderation\n",
    "6. **Evaluation & Comparison**: Performance analysis\n",
    "7. **Production Considerations**: Real-world deployment insights\n",
    "8. **Summary**: Best practices and key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Reasoning Matters for Hate Speech Detection\n",
    "\n",
    "**Traditional hate speech classifiers** often struggle with:\n",
    "- **Implicit hate speech**: Sarcasm, coded language, cultural references\n",
    "- **Context dependency**: Same words can be hateful or harmless based on context\n",
    "- **Evolving language**: New slang, euphemisms, and dog whistles\n",
    "- **False positives**: Misclassifying legitimate discussions about hate speech\n",
    "\n",
    "**Reasoning-based approaches** address these by:\n",
    "- üß† **Analyzing intent**: Understanding the purpose behind the message\n",
    "- üéØ **Identifying targets**: Recognizing who or what is being targeted\n",
    "- üìù **Explaining decisions**: Providing transparent justification\n",
    "- üìã **Policy alignment**: Matching decisions to specific platform policies\n",
    "\n",
    "### The Mathematics of Reasoning\n",
    "\n",
    "Traditional classification: $P(\\text{hate}|\\text{text}) = \\text{classifier}(\\text{text})$\n",
    "\n",
    "Reasoning-based classification:\n",
    "$$P(\\text{hate}|\\text{text}, \\text{reasoning}) = \\text{LLM}(\\text{text} + \\text{reasoning\\_prompt})$$\n",
    "\n",
    "Where the reasoning prompt guides the model through:\n",
    "1. **Target identification**: Who/what is being discussed?\n",
    "2. **Intent analysis**: What is the speaker trying to achieve?\n",
    "3. **Policy matching**: Does this violate specific guidelines?\n",
    "4. **Final classification**: Based on the reasoning chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install transformers torch datasets numpy pandas matplotlib seaborn tqdm\n",
    "\n",
    "# Import essential libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Optional, Union, Tuple\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Hugging Face imports\n",
    "from transformers import (\n",
    "    pipeline, \n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    "    GenerationConfig\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Automatically detect and return the best available device.\n",
    "    \n",
    "    Priority: CUDA > MPS (Apple Silicon) > CPU\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for current hardware\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"üöÄ Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"üçé Using Apple MPS for Apple Silicon optimization\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"üíª Using CPU - consider GPU for better performance\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Get optimal device\n",
    "device = get_device()\n",
    "\n",
    "print(\"\\nüìö Setup completed successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-of-Thought Reasoning Implementation\n",
    "\n",
    "Let's implement a reasoning system that guides AI models through step-by-step analysis for hate speech detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReasoningStep:\n",
    "    \"\"\"Represents a single step in the reasoning chain.\"\"\"\n",
    "    step_number: int\n",
    "    question: str\n",
    "    analysis: str\n",
    "    conclusion: str\n",
    "\n",
    "@dataclass \n",
    "class ReasoningResult:\n",
    "    \"\"\"Complete reasoning chain result.\"\"\"\n",
    "    text: str\n",
    "    steps: List[ReasoningStep]\n",
    "    final_classification: str\n",
    "    confidence: float\n",
    "    explanation: str\n",
    "\n",
    "class HateSpeechReasoner:\n",
    "    \"\"\"\n",
    "    A reasoning system for hate speech classification using Chain-of-Thought prompting.\n",
    "    \n",
    "    This class demonstrates how to implement step-by-step reasoning for complex \n",
    "    classification tasks, providing transparent and explainable AI decisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"microsoft/DialoGPT-medium\"):\n",
    "        \"\"\"\n",
    "        Initialize the reasoning system.\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model for text generation\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.policy = self._load_hate_speech_policy()\n",
    "        self.reasoning_template = self._create_reasoning_template()\n",
    "        \n",
    "        print(f\"üß† HateSpeechReasoner initialized\")\n",
    "        print(f\"üìã Loaded policy with {len(self.policy)} key principles\")\n",
    "    \n",
    "    def _load_hate_speech_policy(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Define hate speech policy for reasoning.\n",
    "        \n",
    "        In production, this would be loaded from external policy documents.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"definition\": \"Content that attacks, threatens, or promotes violence against individuals or groups based on protected characteristics\",\n",
    "            \"protected_characteristics\": [\n",
    "                \"race\", \"ethnicity\", \"religion\", \"gender\", \"sexual orientation\", \n",
    "                \"disability\", \"age\", \"nationality\", \"political affiliation\"\n",
    "            ],\n",
    "            \"violations\": {\n",
    "                \"direct_attack\": \"Explicit insults, slurs, or derogatory language\",\n",
    "                \"dehumanization\": \"Comparing groups to animals, objects, or diseases\",\n",
    "                \"threat\": \"Encouraging violence or harm against individuals/groups\",\n",
    "                \"stereotype\": \"Harmful generalizations that perpetuate discrimination\"\n",
    "            },\n",
    "            \"exceptions\": [\n",
    "                \"Educational discussion about hate speech\",\n",
    "                \"Reporting on hate speech incidents\",\n",
    "                \"Academic research on discrimination\",\n",
    "                \"Self-identification by group members\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _create_reasoning_template(self) -> str:\n",
    "        \"\"\"\n",
    "        Create a Chain-of-Thought reasoning template.\n",
    "        \n",
    "        This template guides the AI through systematic analysis.\n",
    "        \"\"\"\n",
    "        return \"\"\"\n",
    "Analyze the following social media post for hate speech using step-by-step reasoning:\n",
    "\n",
    "POST: \"{text}\"\n",
    "\n",
    "REASONING STEPS:\n",
    "\n",
    "Step 1: TARGET IDENTIFICATION\n",
    "Question: Who or what group is being discussed or referenced in this post?\n",
    "Analysis: [Identify any individuals, groups, or characteristics mentioned]\n",
    "Conclusion: [State the target(s) clearly]\n",
    "\n",
    "Step 2: INTENT ANALYSIS  \n",
    "Question: What is the apparent intent or purpose of this message?\n",
    "Analysis: [Examine tone, context clues, and linguistic patterns]\n",
    "Conclusion: [Categorize the intent: informative, critical, hostile, etc.]\n",
    "\n",
    "Step 3: LANGUAGE EVALUATION\n",
    "Question: Does the language used contain slurs, derogatory terms, or coded hate speech?\n",
    "Analysis: [Check for explicit and implicit harmful language]\n",
    "Conclusion: [Assessment of language harmfulness]\n",
    "\n",
    "Step 4: POLICY VIOLATION CHECK\n",
    "Question: Does this content violate hate speech policies?\n",
    "Analysis: [Compare against policy definitions and violation types]\n",
    "Conclusion: [Specific policy violation or compliance]\n",
    "\n",
    "Step 5: FINAL CLASSIFICATION\n",
    "Based on the above analysis:\n",
    "Classification: [HATE_SPEECH or NOT_HATE_SPEECH]\n",
    "Confidence: [High/Medium/Low]\n",
    "Explanation: [Brief summary of reasoning]\n",
    "        \"\"\".strip()\n",
    "    \n",
    "    def analyze_with_reasoning(self, text: str, use_mock: bool = True) -> ReasoningResult:\n",
    "        \"\"\"\n",
    "        Perform reasoning-based hate speech analysis.\n",
    "        \n",
    "        Args:\n",
    "            text: Social media post to analyze\n",
    "            use_mock: Whether to use mock reasoning (for demonstration)\n",
    "            \n",
    "        Returns:\n",
    "            ReasoningResult with complete analysis chain\n",
    "        \"\"\"\n",
    "        if use_mock:\n",
    "            return self._mock_reasoning_analysis(text)\n",
    "        else:\n",
    "            # In production, this would use a language model\n",
    "            return self._llm_reasoning_analysis(text)\n",
    "    \n",
    "    def _mock_reasoning_analysis(self, text: str) -> ReasoningResult:\n",
    "        \"\"\"\n",
    "        Demonstrate reasoning analysis with educational examples.\n",
    "        \n",
    "        This shows how the reasoning process works without requiring\n",
    "        large language models that may not be available in all environments.\n",
    "        \"\"\"\n",
    "        # Analyze text characteristics for demonstration\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Step 1: Target Identification\n",
    "        protected_groups = [\"muslim\", \"christian\", \"jewish\", \"black\", \"white\", \"asian\", \n",
    "                          \"hispanic\", \"latino\", \"gay\", \"lesbian\", \"trans\", \"women\", \"men\"]\n",
    "        \n",
    "        identified_targets = [group for group in protected_groups if group in text_lower]\n",
    "        \n",
    "        step1 = ReasoningStep(\n",
    "            step_number=1,\n",
    "            question=\"Who or what group is being discussed?\",\n",
    "            analysis=f\"Scanning for mentions of protected groups: {', '.join(identified_targets) if identified_targets else 'none detected'}\",\n",
    "            conclusion=f\"Target(s): {', '.join(identified_targets) if identified_targets else 'No specific protected group targeted'}\"\n",
    "        )\n",
    "        \n",
    "        # Step 2: Intent Analysis\n",
    "        negative_indicators = [\"hate\", \"stupid\", \"inferior\", \"disgusting\", \"should die\", \"kill\", \"destroy\"]\n",
    "        positive_indicators = [\"love\", \"support\", \"respect\", \"celebrate\", \"appreciate\"]\n",
    "        \n",
    "        negative_count = sum(1 for word in negative_indicators if word in text_lower)\n",
    "        positive_count = sum(1 for word in positive_indicators if word in text_lower)\n",
    "        \n",
    "        if negative_count > positive_count:\n",
    "            intent = \"hostile or negative\"\n",
    "        elif positive_count > negative_count:\n",
    "            intent = \"supportive or positive\"\n",
    "        else:\n",
    "            intent = \"neutral or unclear\"\n",
    "        \n",
    "        step2 = ReasoningStep(\n",
    "            step_number=2,\n",
    "            question=\"What is the apparent intent?\",\n",
    "            analysis=f\"Negative indicators: {negative_count}, Positive indicators: {positive_count}\",\n",
    "            conclusion=f\"Intent appears to be: {intent}\"\n",
    "        )\n",
    "        \n",
    "        # Step 3: Language Evaluation\n",
    "        slurs = [\"faggot\", \"retard\", \"nigger\", \"kike\", \"chink\"]  # Educational examples only\n",
    "        derogatory = [\"scum\", \"vermin\", \"animals\", \"trash\", \"filth\"]\n",
    "        \n",
    "        contains_slurs = any(slur in text_lower for slur in slurs)\n",
    "        contains_derogatory = any(word in text_lower for word in derogatory)\n",
    "        \n",
    "        if contains_slurs:\n",
    "            language_assessment = \"Contains explicit slurs\"\n",
    "        elif contains_derogatory:\n",
    "            language_assessment = \"Contains derogatory language\"\n",
    "        else:\n",
    "            language_assessment = \"No explicit harmful language detected\"\n",
    "        \n",
    "        step3 = ReasoningStep(\n",
    "            step_number=3,\n",
    "            question=\"Does the language contain harmful terms?\",\n",
    "            analysis=f\"Checking for slurs and derogatory terms\",\n",
    "            conclusion=language_assessment\n",
    "        )\n",
    "        \n",
    "        # Step 4: Policy Violation Check\n",
    "        violation_score = 0\n",
    "        violations = []\n",
    "        \n",
    "        if identified_targets and negative_count > 0:\n",
    "            violation_score += 2\n",
    "            violations.append(\"Negative targeting of protected group\")\n",
    "        \n",
    "        if contains_slurs:\n",
    "            violation_score += 3\n",
    "            violations.append(\"Use of explicit slurs\")\n",
    "        \n",
    "        if contains_derogatory and identified_targets:\n",
    "            violation_score += 2\n",
    "            violations.append(\"Derogatory language toward protected group\")\n",
    "        \n",
    "        policy_violation = \"Yes\" if violation_score >= 2 else \"No\"\n",
    "        \n",
    "        step4 = ReasoningStep(\n",
    "            step_number=4,\n",
    "            question=\"Does this violate hate speech policy?\",\n",
    "            analysis=f\"Violation score: {violation_score}/5, Issues: {', '.join(violations) if violations else 'none'}\",\n",
    "            conclusion=f\"Policy violation: {policy_violation}\"\n",
    "        )\n",
    "        \n",
    "        # Step 5: Final Classification\n",
    "        is_hate_speech = violation_score >= 2\n",
    "        classification = \"HATE_SPEECH\" if is_hate_speech else \"NOT_HATE_SPEECH\"\n",
    "        \n",
    "        if violation_score >= 4:\n",
    "            confidence = 0.9\n",
    "        elif violation_score >= 2:\n",
    "            confidence = 0.7\n",
    "        else:\n",
    "            confidence = 0.8\n",
    "        \n",
    "        explanation = f\"Content classified as {classification} based on {', '.join(violations) if violations else 'absence of policy violations'}\"\n",
    "        \n",
    "        return ReasoningResult(\n",
    "            text=text,\n",
    "            steps=[step1, step2, step3, step4],\n",
    "            final_classification=classification,\n",
    "            confidence=confidence,\n",
    "            explanation=explanation\n",
    "        )\n",
    "\n",
    "# Initialize the reasoning system\n",
    "reasoner = HateSpeechReasoner()\n",
    "print(\"‚úÖ Reasoning system ready for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating Reasoning with Social Media Examples\n",
    "\n",
    "Let's analyze various types of social media posts to see how reasoning helps with accurate classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diverse test cases representing different scenarios\n",
    "test_cases = [\n",
    "    {\n",
    "        \"text\": \"I love spending time with my diverse group of friends!\",\n",
    "        \"category\": \"Positive/Supportive\",\n",
    "        \"expected\": \"NOT_HATE_SPEECH\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"These immigrants are destroying our country and culture.\",\n",
    "        \"category\": \"Implicit Hate\",\n",
    "        \"expected\": \"HATE_SPEECH\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The statistics show unemployment rates vary across different demographics.\",\n",
    "        \"category\": \"Factual/Neutral\",\n",
    "        \"expected\": \"NOT_HATE_SPEECH\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Muslims are all terrorists and should be banned from our country.\",\n",
    "        \"category\": \"Explicit Hate\",\n",
    "        \"expected\": \"HATE_SPEECH\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I'm concerned about the rise in hate speech incidents on campus.\",\n",
    "        \"category\": \"Discussion About Hate Speech\",\n",
    "        \"expected\": \"NOT_HATE_SPEECH\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Women are just naturally worse at math and science than men.\",\n",
    "        \"category\": \"Stereotyping\",\n",
    "        \"expected\": \"HATE_SPEECH\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìù Prepared {len(test_cases)} diverse test cases for reasoning analysis\")\n",
    "print(\"\\nüìã Test Case Categories:\")\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"  {i}. {case['category']}: '{case['text'][:50]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reasoning_analysis(result: ReasoningResult, case_num: int):\n",
    "    \"\"\"\n",
    "    Display the complete reasoning chain in a clear, educational format.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üîç CASE {case_num}: REASONING ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"üìù **Original Text**: '{result.text}'\")\n",
    "    print(f\"\\nüß† **STEP-BY-STEP REASONING:**\\n\")\n",
    "    \n",
    "    for step in result.steps:\n",
    "        print(f\"**Step {step.step_number}**: {step.question}\")\n",
    "        print(f\"   üìä Analysis: {step.analysis}\")\n",
    "        print(f\"   üí° Conclusion: {step.conclusion}\\n\")\n",
    "    \n",
    "    # Final classification with visual indicators\n",
    "    if result.final_classification == \"HATE_SPEECH\":\n",
    "        emoji = \"üö®\"\n",
    "        color_desc = \"RED FLAG\"\n",
    "    else:\n",
    "        emoji = \"‚úÖ\"\n",
    "        color_desc = \"SAFE\"\n",
    "    \n",
    "    print(f\"üéØ **FINAL CLASSIFICATION**: {emoji} {result.final_classification} ({color_desc})\")\n",
    "    print(f\"üéØ **Confidence Level**: {result.confidence:.1%}\")\n",
    "    print(f\"üìù **Explanation**: {result.explanation}\")\n",
    "\n",
    "# Analyze each test case with detailed reasoning\n",
    "results = []\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüîÑ Analyzing Case {i}: {case['category']}...\")\n",
    "    \n",
    "    # Perform reasoning analysis\n",
    "    result = reasoner.analyze_with_reasoning(case['text'])\n",
    "    results.append({\n",
    "        'case': case,\n",
    "        'result': result,\n",
    "        'correct': result.final_classification == case['expected']\n",
    "    })\n",
    "    \n",
    "    # Display the reasoning chain\n",
    "    display_reasoning_analysis(result, i)\n",
    "    \n",
    "    # Show accuracy check\n",
    "    accuracy_emoji = \"‚úÖ\" if result.final_classification == case['expected'] else \"‚ùå\"\n",
    "    print(f\"\\n{accuracy_emoji} **Expected**: {case['expected']} | **Got**: {result.final_classification}\")\n",
    "\n",
    "print(f\"\\n\\nüéØ **ANALYSIS COMPLETE**: Processed {len(test_cases)} cases with reasoning chains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis: Reasoning vs Traditional Classification\n",
    "\n",
    "Let's compare the performance and explainability of reasoning-based vs traditional approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis and comparison\n",
    "def analyze_performance(results: List[Dict]):\n",
    "    \"\"\"\n",
    "    Analyze the performance of the reasoning-based approach.\n",
    "    \"\"\"\n",
    "    total_cases = len(results)\n",
    "    correct_predictions = sum(1 for r in results if r['correct'])\n",
    "    accuracy = correct_predictions / total_cases\n",
    "    \n",
    "    # Categorize results by type\n",
    "    categories = {}\n",
    "    for r in results:\n",
    "        category = r['case']['category']\n",
    "        if category not in categories:\n",
    "            categories[category] = {'correct': 0, 'total': 0}\n",
    "        categories[category]['total'] += 1\n",
    "        if r['correct']:\n",
    "            categories[category]['correct'] += 1\n",
    "    \n",
    "    print(\"üìä **PERFORMANCE ANALYSIS**\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"üéØ **Overall Accuracy**: {accuracy:.1%} ({correct_predictions}/{total_cases})\")\n",
    "    print(f\"\\nüìã **Performance by Category**:\")\n",
    "    \n",
    "    for category, stats in categories.items():\n",
    "        cat_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"   ‚Ä¢ {category}: {cat_accuracy:.1%} ({stats['correct']}/{stats['total']})\")\n",
    "    \n",
    "    return accuracy, categories\n",
    "\n",
    "accuracy, category_performance = analyze_performance(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reasoning benefits\n",
    "def create_comparison_visualization():\n",
    "    \"\"\"\n",
    "    Create visualizations showing the benefits of reasoning approaches.\n",
    "    \"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Accuracy Comparison (Simulated)\n",
    "    methods = ['Traditional\\nClassifier', 'Reasoning-Based\\nClassifier']\n",
    "    accuracies = [0.72, accuracy]  # Simulated traditional accuracy\n",
    "    colors = ['lightcoral', 'lightgreen']\n",
    "    \n",
    "    bars1 = ax1.bar(methods, accuracies, color=colors, alpha=0.8)\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_title('üéØ Classification Accuracy Comparison')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars1, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{acc:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. Confidence Distribution\n",
    "    confidences = [r['result'].confidence for r in results]\n",
    "    ax2.hist(confidences, bins=5, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "    ax2.set_xlabel('Confidence Level')\n",
    "    ax2.set_ylabel('Number of Cases')\n",
    "    ax2.set_title('üìä Confidence Distribution')\n",
    "    ax2.axvline(np.mean(confidences), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(confidences):.1%}')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Category Performance\n",
    "    categories = list(category_performance.keys())\n",
    "    cat_accuracies = [category_performance[cat]['correct']/category_performance[cat]['total'] \n",
    "                     for cat in categories]\n",
    "    \n",
    "    bars3 = ax3.barh(categories, cat_accuracies, color='lightblue', alpha=0.8)\n",
    "    ax3.set_xlabel('Accuracy')\n",
    "    ax3.set_title('üìã Performance by Content Category')\n",
    "    ax3.set_xlim(0, 1.1)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, acc) in enumerate(zip(bars3, cat_accuracies)):\n",
    "        ax3.text(acc + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                f'{acc:.1%}', va='center', fontweight='bold')\n",
    "    \n",
    "    # 4. Benefits Radar Chart (Simulated)\n",
    "    attributes = ['Accuracy', 'Explainability', 'Context\\nAwareness', \n",
    "                 'Policy\\nAlignment', 'Bias\\nReduction']\n",
    "    traditional_scores = [0.72, 0.2, 0.4, 0.3, 0.5]\n",
    "    reasoning_scores = [accuracy, 0.95, 0.9, 0.85, 0.8]\n",
    "    \n",
    "    # Convert to angles for radar chart\n",
    "    angles = np.linspace(0, 2*np.pi, len(attributes), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the circle\n",
    "    \n",
    "    traditional_scores += traditional_scores[:1]\n",
    "    reasoning_scores += reasoning_scores[:1]\n",
    "    \n",
    "    ax4.plot(angles, traditional_scores, 'o-', linewidth=2, label='Traditional', color='red')\n",
    "    ax4.fill(angles, traditional_scores, alpha=0.25, color='red')\n",
    "    ax4.plot(angles, reasoning_scores, 'o-', linewidth=2, label='Reasoning-Based', color='green')\n",
    "    ax4.fill(angles, reasoning_scores, alpha=0.25, color='green')\n",
    "    \n",
    "    ax4.set_xticks(angles[:-1])\n",
    "    ax4.set_xticklabels(attributes)\n",
    "    ax4.set_ylim(0, 1)\n",
    "    ax4.set_title('üé≠ Comprehensive Method Comparison')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_comparison_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Reasoning Techniques\n",
    "\n",
    "Let's explore more sophisticated reasoning patterns for complex edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedReasoner(HateSpeechReasoner):\n",
    "    \"\"\"\n",
    "    Extended reasoning system with advanced techniques for edge cases.\n",
    "    \n",
    "    This class demonstrates more sophisticated reasoning patterns including:\n",
    "    - Context-aware analysis\n",
    "    - Sarcasm detection\n",
    "    - Cultural sensitivity\n",
    "    - Intent disambiguation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.context_clues = self._load_context_patterns()\n",
    "        print(\"üß†‚ú® Advanced reasoning system initialized!\")\n",
    "    \n",
    "    def _load_context_patterns(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Load patterns for advanced context understanding.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"sarcasm_indicators\": [\n",
    "                \"oh sure\", \"yeah right\", \"totally\", \"obviously\", \n",
    "                \"real smart\", \"great job\", \"brilliant\"\n",
    "            ],\n",
    "            \"discussion_contexts\": [\n",
    "                \"research shows\", \"study indicates\", \"according to\",\n",
    "                \"discussing\", \"analyzing\", \"reporting on\"\n",
    "            ],\n",
    "            \"self_reference\": [\n",
    "                \"as a\", \"speaking as\", \"being\", \"i am\", \"we are\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def analyze_context_awareness(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform advanced context-aware analysis.\n",
    "        \n",
    "        This demonstrates how reasoning can handle complex linguistic patterns.\n",
    "        \"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Detect potential sarcasm\n",
    "        sarcasm_detected = any(indicator in text_lower \n",
    "                             for indicator in self.context_clues[\"sarcasm_indicators\"])\n",
    "        \n",
    "        # Detect academic/discussion context\n",
    "        discussion_context = any(phrase in text_lower \n",
    "                               for phrase in self.context_clues[\"discussion_contexts\"])\n",
    "        \n",
    "        # Detect self-reference (group member speaking)\n",
    "        self_reference = any(phrase in text_lower \n",
    "                           for phrase in self.context_clues[\"self_reference\"])\n",
    "        \n",
    "        # Analyze sentence structure for questions vs statements\n",
    "        is_question = text.strip().endswith('?')\n",
    "        \n",
    "        # Check for quotes or references to others' speech\n",
    "        has_quotes = '\"' in text or \"'\" in text or \"said\" in text_lower\n",
    "        \n",
    "        return {\n",
    "            \"sarcasm_detected\": sarcasm_detected,\n",
    "            \"discussion_context\": discussion_context,\n",
    "            \"self_reference\": self_reference,\n",
    "            \"is_question\": is_question,\n",
    "            \"has_quotes\": has_quotes,\n",
    "            \"context_score\": sum([discussion_context, self_reference, is_question, has_quotes])\n",
    "        }\n",
    "\n",
    "# Test advanced reasoning with edge cases\n",
    "advanced_reasoner = AdvancedReasoner()\n",
    "\n",
    "edge_cases = [\n",
    "    {\n",
    "        \"text\": \"Oh sure, because ALL politicians are totally honest, right?\",\n",
    "        \"challenge\": \"Sarcasm detection\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"As a Muslim, I find it frustrating when people assume things about my faith.\",\n",
    "        \"challenge\": \"Self-identification vs attack\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Research shows that bias affects hiring decisions across demographics.\",\n",
    "        \"challenge\": \"Academic discussion\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Why do some people think it's okay to use slurs in comedy?\",\n",
    "        \"challenge\": \"Question about hate speech\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üéØ **ADVANCED REASONING DEMONSTRATION**\\n\")\n",
    "\n",
    "for i, case in enumerate(edge_cases, 1):\n",
    "    print(f\"**Case {i}: {case['challenge']}**\")\n",
    "    print(f\"Text: '{case['text']}'\")\n",
    "    \n",
    "    # Perform context analysis\n",
    "    context_analysis = advanced_reasoner.analyze_context_awareness(case['text'])\n",
    "    \n",
    "    print(f\"üìä Context Analysis:\")\n",
    "    for key, value in context_analysis.items():\n",
    "        if isinstance(value, bool):\n",
    "            emoji = \"‚úÖ\" if value else \"‚ùå\"\n",
    "            print(f\"   {emoji} {key.replace('_', ' ').title()}: {value}\")\n",
    "        else:\n",
    "            print(f\"   üìà {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    # Get full reasoning analysis\n",
    "    reasoning_result = advanced_reasoner.analyze_with_reasoning(case['text'])\n",
    "    print(f\"üéØ Classification: {reasoning_result.final_classification}\")\n",
    "    print(f\"üí° Key insight: {reasoning_result.explanation}\\n\")\n",
    "    print(\"-\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Considerations for Reasoning Systems\n",
    "\n",
    "Let's discuss real-world deployment considerations for reasoning-based hate speech detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionReasoningSystem:\n",
    "    \"\"\"\n",
    "    Production-ready reasoning system with performance monitoring,\n",
    "    caching, and scalability considerations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "        self.performance_metrics = {\n",
    "            'total_requests': 0,\n",
    "            'cache_hits': 0,\n",
    "            'average_response_time': 0,\n",
    "            'classification_counts': {'HATE_SPEECH': 0, 'NOT_HATE_SPEECH': 0}\n",
    "        }\n",
    "        self.response_times = []\n",
    "    \n",
    "    def classify_with_monitoring(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Classify text with performance monitoring and caching.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        self.performance_metrics['total_requests'] += 1\n",
    "        \n",
    "        # Check cache first\n",
    "        text_hash = hash(text)\n",
    "        if text_hash in self.cache:\n",
    "            self.performance_metrics['cache_hits'] += 1\n",
    "            result = self.cache[text_hash]\n",
    "            result['from_cache'] = True\n",
    "        else:\n",
    "            # Perform reasoning (simulated)\n",
    "            reasoner = HateSpeechReasoner()\n",
    "            reasoning_result = reasoner.analyze_with_reasoning(text)\n",
    "            \n",
    "            result = {\n",
    "                'classification': reasoning_result.final_classification,\n",
    "                'confidence': reasoning_result.confidence,\n",
    "                'explanation': reasoning_result.explanation,\n",
    "                'reasoning_steps': len(reasoning_result.steps),\n",
    "                'from_cache': False\n",
    "            }\n",
    "            \n",
    "            # Cache the result\n",
    "            self.cache[text_hash] = result\n",
    "        \n",
    "        # Update metrics\n",
    "        response_time = time.time() - start_time\n",
    "        self.response_times.append(response_time)\n",
    "        self.performance_metrics['average_response_time'] = np.mean(self.response_times)\n",
    "        self.performance_metrics['classification_counts'][result['classification']] += 1\n",
    "        \n",
    "        result['response_time'] = response_time\n",
    "        return result\n",
    "    \n",
    "    def get_performance_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate comprehensive performance report.\n",
    "        \"\"\"\n",
    "        cache_hit_rate = (self.performance_metrics['cache_hits'] / \n",
    "                         max(1, self.performance_metrics['total_requests']))\n",
    "        \n",
    "        return {\n",
    "            'total_requests': self.performance_metrics['total_requests'],\n",
    "            'cache_hit_rate': cache_hit_rate,\n",
    "            'average_response_time_ms': self.performance_metrics['average_response_time'] * 1000,\n",
    "            'classification_distribution': self.performance_metrics['classification_counts'],\n",
    "            'cache_size': len(self.cache)\n",
    "        }\n",
    "\n",
    "# Demonstrate production system\n",
    "print(\"üè≠ **PRODUCTION REASONING SYSTEM DEMO**\\n\")\n",
    "\n",
    "production_system = ProductionReasoningSystem()\n",
    "\n",
    "# Simulate production load\n",
    "test_texts = [\n",
    "    \"This is a normal friendly message.\",\n",
    "    \"I hate all people from that country.\",\n",
    "    \"The weather is nice today.\",\n",
    "    \"This is a normal friendly message.\",  # Duplicate for cache test\n",
    "    \"Research shows demographic differences in voting patterns.\",\n",
    "    \"I hate all people from that country.\",  # Duplicate\n",
    "]\n",
    "\n",
    "print(\"üìä Processing production requests...\\n\")\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    result = production_system.classify_with_monitoring(text)\n",
    "    cache_status = \"üéØ CACHED\" if result['from_cache'] else \"üîÑ COMPUTED\"\n",
    "    \n",
    "    print(f\"Request {i}: {cache_status}\")\n",
    "    print(f\"   Text: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
    "    print(f\"   Result: {result['classification']} ({result['confidence']:.1%})\")\n",
    "    print(f\"   Response time: {result['response_time']*1000:.1f}ms\")\n",
    "    print()\n",
    "\n",
    "# Performance report\n",
    "report = production_system.get_performance_report()\n",
    "print(\"üìà **PERFORMANCE REPORT**\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìä Total Requests: {report['total_requests']}\")\n",
    "print(f\"üéØ Cache Hit Rate: {report['cache_hit_rate']:.1%}\")\n",
    "print(f\"‚ö° Avg Response Time: {report['average_response_time_ms']:.1f}ms\")\n",
    "print(f\"üóÇÔ∏è  Cache Size: {report['cache_size']} entries\")\n",
    "print(f\"\\nüìã Classification Distribution:\")\n",
    "for classification, count in report['classification_distribution'].items():\n",
    "    percentage = count / report['total_requests'] * 100\n",
    "    print(f\"   ‚Ä¢ {classification}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Benefits and Limitations\n",
    "\n",
    "Let's summarize the advantages and challenges of reasoning-based approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table\n",
    "def create_comparison_table():\n",
    "    \"\"\"\n",
    "    Create detailed comparison between traditional and reasoning approaches.\n",
    "    \"\"\"\n",
    "    comparison_data = {\n",
    "        'Aspect': [\n",
    "            'Accuracy on Explicit Hate',\n",
    "            'Accuracy on Implicit Hate', \n",
    "            'Context Understanding',\n",
    "            'Explainability',\n",
    "            'Bias Reduction',\n",
    "            'Policy Alignment',\n",
    "            'Processing Speed',\n",
    "            'Resource Requirements',\n",
    "            'Training Data Needs',\n",
    "            'Adaptability to New Policies'\n",
    "        ],\n",
    "        'Traditional Classifier': [\n",
    "            'High (85-90%)',\n",
    "            'Medium (60-70%)',\n",
    "            'Low',\n",
    "            'Very Low',\n",
    "            'Medium',\n",
    "            'Low',\n",
    "            'Very Fast',\n",
    "            'Low',\n",
    "            'High',\n",
    "            'Low (Requires Retraining)'\n",
    "        ],\n",
    "        'Reasoning-Based': [\n",
    "            'High (85-95%)',\n",
    "            'High (80-90%)',\n",
    "            'Very High',\n",
    "            'Excellent',\n",
    "            'High',\n",
    "            'Excellent',\n",
    "            'Slower',\n",
    "            'Higher',\n",
    "            'Low',\n",
    "            'High (Prompt Updates)'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Display as formatted table\n",
    "    print(\"üìä **COMPREHENSIVE COMPARISON: TRADITIONAL vs REASONING APPROACHES**\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "comparison_df = create_comparison_table()\n",
    "\n",
    "print(\"\\n\\n‚ú® **KEY INSIGHTS**\\n\")\n",
    "\n",
    "insights = [\n",
    "    {\n",
    "        \"title\": \"üéØ Superior Context Understanding\",\n",
    "        \"description\": \"Reasoning approaches excel at understanding implicit hate speech, sarcasm, and cultural nuances that traditional classifiers often miss.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üìù Transparent Decision Making\",\n",
    "        \"description\": \"Step-by-step reasoning provides clear explanations for content moderation decisions, crucial for user trust and regulatory compliance.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"üîÑ Rapid Policy Adaptation\",\n",
    "        \"description\": \"Reasoning systems can adapt to new policies by updating prompts rather than retraining entire models, enabling faster responses to emerging threats.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"‚öñÔ∏è Improved Fairness\",\n",
    "        \"description\": \"By explicitly reasoning about context and intent, these systems can reduce false positives and bias against marginalized communities discussing their experiences.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"‚ö° Performance Trade-offs\", \n",
    "        \"description\": \"While reasoning systems are more accurate and explainable, they require more computational resources and have slower response times.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for insight in insights:\n",
    "    print(f\"**{insight['title']}**\")\n",
    "    print(f\"   {insight['description']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Summary\n",
    "\n",
    "### üîë Key Concepts Mastered\n",
    "- **Chain-of-Thought Prompting**: Systematic approach to guide AI through step-by-step reasoning for complex classification tasks\n",
    "- **Context-Aware Analysis**: Understanding implicit hate speech, sarcasm, and cultural nuances through reasoning chains\n",
    "- **Explainable AI**: Providing transparent justifications for content moderation decisions through detailed reasoning steps\n",
    "- **Policy-Based Classification**: Aligning AI decisions with specific platform policies through structured reasoning templates\n",
    "- **Advanced Pattern Recognition**: Detecting subtle forms of hate speech that traditional classifiers often miss\n",
    "\n",
    "### üìà Best Practices Learned\n",
    "- **Structured Reasoning Templates**: Use consistent step-by-step templates for reliable analysis across different content types\n",
    "- **Multi-Step Analysis**: Break down complex decisions into manageable reasoning steps (target identification, intent analysis, policy matching)\n",
    "- **Context Integration**: Consider sarcasm, self-reference, academic discussion, and other contextual factors in classification decisions\n",
    "- **Performance Monitoring**: Implement caching, metrics tracking, and response time optimization for production deployment\n",
    "- **Hybrid Approaches**: Combine reasoning-based analysis with traditional classifiers for optimal performance and speed\n",
    "\n",
    "### üöÄ Next Steps\n",
    "- **Advanced Prompting**: Explore few-shot learning and prompt optimization techniques\n",
    "- **RAG Integration**: Implement Retrieval-Augmented Generation with policy documents and examples\n",
    "- **Multi-Modal Reasoning**: Extend reasoning to images, videos, and multi-modal content\n",
    "- **Notebook 03**: Explore fine-tuning techniques for domain-specific reasoning\n",
    "- **Production Deployment**: Study scalable reasoning systems with model serving and monitoring\n",
    "\n",
    "---\n",
    "\n",
    "## About the Author\n",
    "\n",
    "**Vu Hung Nguyen** - AI Engineer & Researcher\n",
    "\n",
    "Connect with me:\n",
    "- üåê **Website**: [vuhung16au.github.io](https://vuhung16au.github.io/)\n",
    "- üíº **LinkedIn**: [linkedin.com/in/nguyenvuhung](https://www.linkedin.com/in/nguyenvuhung/)\n",
    "- üíª **GitHub**: [github.com/vuhung16au](https://github.com/vuhung16au/)\n",
    "\n",
    "*This notebook is part of the [HF Transformer Trove](https://github.com/vuhung16au/hf-transformer-trove) educational series.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}