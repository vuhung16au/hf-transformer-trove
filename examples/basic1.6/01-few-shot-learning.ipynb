{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.6/01-few-shot-learning.ipynb)\n",
    "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/hf-transformer-trove/blob/main/examples/basic1.6/01-few-shot-learning.ipynb)\n",
    "\n",
    "# 01 - Few-Shot Learning: Learning from Examples in Context\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- What few-shot learning is and how it differs from zero-shot learning\n",
    "- How to use few-shot learning for hate speech classification\n",
    "- The concept of in-context learning popularized by GPT-3\n",
    "- How to structure prompts with 2-3 examples for optimal performance\n",
    "- Performance comparison between zero-shot and few-shot approaches\n",
    "- Best practices for selecting representative examples\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with Python and text classification\n",
    "- Knowledge of transformers (refer to [Notebook 01](../01_intro_hf_transformers.ipynb))\n",
    "- Understanding of zero-shot classification (refer to [Zero-Shot Classification](../basic1.2/02-zero-shot-classification.ipynb))\n",
    "- Understanding of NLP fundamentals (refer to [NLP Learning Journey](https://github.com/vuhung16au/nlp-learning-journey))\n",
    "\n",
    "## üìö What We'll Cover\n",
    "1. **Introduction**: Few-shot learning concepts and motivation\n",
    "2. **Setup and Imports**: Environment preparation and model loading\n",
    "3. **Understanding Few-Shot Learning**: GPT-3 style in-context learning\n",
    "4. **Hate Speech Classification**: Practical implementation with 2-3 examples\n",
    "5. **Prompt Engineering**: Crafting effective few-shot prompts\n",
    "6. **Performance Analysis**: Zero-shot vs Few-shot comparison\n",
    "7. **Advanced Techniques**: Example selection and optimization\n",
    "8. **Summary and Best Practices**: Key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Few-Shot Learning?\n",
    "\n",
    "**Few-shot learning** is a machine learning approach where models learn to perform tasks from just a few examples. In the context of large language models like GPT-3/4, this is achieved through **in-context learning** - providing 2-3 examples directly in the prompt without updating model parameters.\n",
    "\n",
    "### Key Concepts:\n",
    "- üß† **In-context Learning**: Learning from examples in the input prompt\n",
    "- üéØ **No Parameter Updates**: Model weights remain unchanged during inference\n",
    "- üìö **Example-Driven**: Performance improves with well-chosen examples\n",
    "- üöÄ **Immediate Application**: No training or fine-tuning required\n",
    "\n",
    "### Few-Shot vs Zero-Shot vs Fine-Tuning:\n",
    "\n",
    "| Approach | Examples Needed | Training Required | Performance | Speed |\n",
    "|----------|-----------------|-------------------|-------------|-------|\n",
    "| **Zero-shot** | 0 | No | Good | Fast |\n",
    "| **Few-shot** | 2-5 | No | Better | Fast |\n",
    "| **Fine-tuning** | 100s-1000s | Yes | Best | Slow setup |\n",
    "\n",
    "### When to Use Few-Shot Learning:\n",
    "- üîÑ When zero-shot performance isn't sufficient\n",
    "- ‚ö° When you need quick improvements without training\n",
    "- üìù When you have a few high-quality examples\n",
    "- üéØ For specialized tasks that benefit from demonstration\n",
    "- üí∞ When compute resources for fine-tuning are limited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment and run if needed)\n",
    "# !pip install transformers torch datasets tokenizers matplotlib seaborn plotly\n",
    "\n",
    "# Import essential libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from typing import List, Dict, Optional, Union\n",
    "from collections import Counter\n",
    "\n",
    "# Hugging Face imports\n",
    "from transformers import (\n",
    "    pipeline, \n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(f\"üêç Python version: {torch.__version__}\")\n",
    "print(f\"ü§ó Transformers version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the best available device for PyTorch operations.\n",
    "    \n",
    "    Priority order: CUDA > MPS (Apple Silicon) > CPU\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for current hardware\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"üöÄ Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"üçé Using Apple MPS for Apple Silicon optimization\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"üíª Using CPU - consider GPU for better performance\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Initialize device\n",
    "device = get_device()\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Few-Shot Learning with Text Generation Models\n",
    "\n",
    "Few-shot learning with language models works by providing examples in the prompt itself. The model learns the pattern from these examples and applies it to new inputs. Let's start by understanding the basic concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_few_shot_concept():\n",
    "    \"\"\"\n",
    "    Demonstrate the basic concept of few-shot learning with prompt structure.\n",
    "    This shows the pattern without actual model inference.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üß† FEW-SHOT LEARNING CONCEPT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Few-shot prompt structure for hate speech classification\n",
    "    few_shot_prompt = \"\"\"\n",
    "Classify the following social media posts as either \"hate speech\" or \"normal speech\":\n",
    "\n",
    "Post: \"Great job on the presentation! Really well done.\"\n",
    "Classification: normal speech\n",
    "\n",
    "Post: \"This movie was terrible, waste of time.\"\n",
    "Classification: normal speech\n",
    "\n",
    "Post: \"All people from that country are criminals and should be deported.\"\n",
    "Classification: hate speech\n",
    "\n",
    "Post: \"I love spending time with my diverse group of friends.\"\n",
    "Classification: normal speech\n",
    "\n",
    "Now classify this new post:\n",
    "Post: \"The new policy will benefit everyone in our community.\"\n",
    "Classification: \"\"\"\n",
    "    \n",
    "    print(\"üìù Few-Shot Prompt Structure:\")\n",
    "    print(few_shot_prompt)\n",
    "    print(\"\\nüéØ Expected Output: normal speech\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä Key Elements of Effective Few-Shot Prompts:\")\n",
    "    print(\"1. Clear task description\")\n",
    "    print(\"2. Consistent format for examples\")\n",
    "    print(\"3. Diverse, representative examples\")\n",
    "    print(\"4. Clear input-output mapping\")\n",
    "    print(\"5. Explicit prompt for new classification\")\n",
    "\n",
    "demonstrate_few_shot_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Loading Models for Few-Shot Learning\n",
    "\n",
    "For few-shot learning, we typically use generative models (decoder-only) like GPT-2, GPT-3, or similar architectures that can generate text based on prompts. Let's load and set up our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_few_shot_model(model_name: str = \"gpt2\"):\n",
    "    \"\"\"\n",
    "    Load a generative model suitable for few-shot learning.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model to load (default: gpt2)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (tokenizer, model)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üì• Loading model: {model_name}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load tokenizer and model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        \n",
    "        # Add pad token if not present (common for GPT models)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        # Move model to optimal device\n",
    "        model = model.to(device)\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Model loaded successfully in {load_time:.2f} seconds\")\n",
    "        print(f\"üìä Model size: {model.num_parameters():,} parameters\")\n",
    "        print(f\"üè∑Ô∏è  Model type: {model.config.model_type}\")\n",
    "        \n",
    "        return tokenizer, model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model {model_name}: {e}\")\n",
    "        print(\"üí° Try checking model name or network connection\")\n",
    "        raise\n",
    "\n",
    "# Load GPT-2 for few-shot learning (lightweight and fast)\n",
    "print(\"ü§ñ Loading GPT-2 for few-shot learning...\")\n",
    "tokenizer, model = load_few_shot_model(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also load a zero-shot classifier for comparison\n",
    "print(\"üì• Loading zero-shot classification pipeline for comparison...\")\n",
    "zero_shot_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    device=0 if device.type == 'cuda' else -1  # Use GPU if available\n",
    ")\n",
    "print(f\"‚úÖ Zero-shot classifier ready: {zero_shot_classifier.model.config.name_or_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implementing Few-Shot Hate Speech Classification\n",
    "\n",
    "Now let's implement the core functionality for few-shot hate speech classification. We'll create a system that can classify social media posts using just a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotHateSpeechClassifier:\n",
    "    \"\"\"\n",
    "    A few-shot learning classifier for hate speech detection.\n",
    "    \n",
    "    This class demonstrates how to use generative models for classification\n",
    "    tasks through few-shot prompting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer, model, device):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        \n",
    "        # Pre-defined examples for few-shot learning\n",
    "        self.examples = [\n",
    "            {\n",
    "                \"post\": \"Great job on your presentation! Really impressive work.\",\n",
    "                \"label\": \"normal speech\"\n",
    "            },\n",
    "            {\n",
    "                \"post\": \"I disagree with this policy, but I respect your opinion.\",\n",
    "                \"label\": \"normal speech\"\n",
    "            },\n",
    "            {\n",
    "                \"post\": \"All immigrants are criminals and should be sent back where they came from.\",\n",
    "                \"label\": \"hate speech\"\n",
    "            },\n",
    "            {\n",
    "                \"post\": \"Women are too emotional to be leaders in any field.\",\n",
    "                \"label\": \"hate speech\"\n",
    "            },\n",
    "            {\n",
    "                \"post\": \"Looking forward to working with the new diverse team members.\",\n",
    "                \"label\": \"normal speech\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def create_few_shot_prompt(self, text_to_classify: str, num_examples: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Create a few-shot learning prompt for hate speech classification.\n",
    "        \n",
    "        Args:\n",
    "            text_to_classify: The text to classify\n",
    "            num_examples: Number of examples to include (2-5 recommended)\n",
    "            \n",
    "        Returns:\n",
    "            Formatted prompt string\n",
    "        \"\"\"\n",
    "        prompt = \"Classify the following social media posts as either 'hate speech' or 'normal speech':\\n\\n\"\n",
    "        \n",
    "        # Add few-shot examples\n",
    "        for i, example in enumerate(self.examples[:num_examples]):\n",
    "            prompt += f\"Post: \\\"{example['post']}\\\"\\n\"\n",
    "            prompt += f\"Classification: {example['label']}\\n\\n\"\n",
    "        \n",
    "        # Add the text to classify\n",
    "        prompt += f\"Post: \\\"{text_to_classify}\\\"\\n\"\n",
    "        prompt += \"Classification:\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def classify(self, text: str, num_examples: int = 3, max_length: int = 10) -> Dict:\n",
    "        \"\"\"\n",
    "        Classify text using few-shot learning.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to classify\n",
    "            num_examples: Number of examples to use\n",
    "            max_length: Maximum length of generated response\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with classification results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create prompt\n",
    "            prompt = self.create_few_shot_prompt(text, num_examples)\n",
    "            \n",
    "            # Tokenize input\n",
    "            inputs = self.tokenizer(\n",
    "                prompt, \n",
    "                return_tensors=\"pt\", \n",
    "                truncation=True, \n",
    "                max_length=1024\n",
    "            ).to(self.device)\n",
    "            \n",
    "            # Generate response\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs.input_ids,\n",
    "                    max_length=inputs.input_ids.shape[1] + max_length,\n",
    "                    num_return_sequences=1,\n",
    "                    temperature=0.3,  # Low temperature for more consistent outputs\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            # Decode the generated text\n",
    "            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Extract only the classification part (after the last \"Classification:\")\n",
    "            classification = full_response.split(\"Classification:\")[-1].strip()\n",
    "            \n",
    "            # Clean and determine the prediction\n",
    "            classification = classification.lower().strip()\n",
    "            \n",
    "            if \"hate speech\" in classification:\n",
    "                prediction = \"hate speech\"\n",
    "                confidence = 0.8  # Approximate confidence\n",
    "            elif \"normal speech\" in classification:\n",
    "                prediction = \"normal speech\"\n",
    "                confidence = 0.8\n",
    "            else:\n",
    "                prediction = \"unclear\"\n",
    "                confidence = 0.3\n",
    "            \n",
    "            return {\n",
    "                \"text\": text,\n",
    "                \"prediction\": prediction,\n",
    "                \"confidence\": confidence,\n",
    "                \"raw_response\": classification,\n",
    "                \"prompt_used\": prompt,\n",
    "                \"num_examples\": num_examples\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during classification: {e}\")\n",
    "            return {\n",
    "                \"text\": text,\n",
    "                \"prediction\": \"error\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "# Initialize the few-shot classifier\n",
    "few_shot_classifier = FewShotHateSpeechClassifier(tokenizer, model, device)\n",
    "print(\"‚úÖ Few-shot hate speech classifier initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Testing Few-Shot Classification\n",
    "\n",
    "Let's test our few-shot classifier with various examples and see how it performs on hate speech detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases for hate speech classification\n",
    "test_posts = [\n",
    "    # Normal speech examples\n",
    "    \"I really enjoyed the new restaurant downtown. Great food and service!\",\n",
    "    \"Looking forward to collaborating with colleagues from different backgrounds.\",\n",
    "    \"The weather today is perfect for a walk in the park.\",\n",
    "    \"I disagree with this decision, but I understand the reasoning behind it.\",\n",
    "    \n",
    "    # Potential hate speech examples (educational purposes)\n",
    "    \"People from that religion are all terrorists and dangerous.\",\n",
    "    \"Women shouldn't be allowed in leadership positions.\",\n",
    "    \"All refugees are just looking for free handouts.\",\n",
    "    \n",
    "    # Borderline/ambiguous cases\n",
    "    \"This movie was absolutely terrible, complete waste of time.\",\n",
    "    \"The government's new policy is completely wrong and stupid.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ TESTING FEW-SHOT HATE SPEECH CLASSIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "for i, post in enumerate(test_posts, 1):\n",
    "    print(f\"\\nüìù Test {i}: \\\"{post}\\\"\")\n",
    "    \n",
    "    # Classify with few-shot learning (3 examples)\n",
    "    result = few_shot_classifier.classify(post, num_examples=3)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"   üéØ Prediction: {result['prediction']}\")\n",
    "    print(f\"   üìä Confidence: {result['confidence']:.2f}\")\n",
    "    if 'raw_response' in result:\n",
    "        print(f\"   üîç Raw response: '{result['raw_response']}'\")\n",
    "\n",
    "print(\"\\n‚úÖ Few-shot classification testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Comparing Zero-Shot vs Few-Shot Performance\n",
    "\n",
    "Let's compare how zero-shot and few-shot approaches perform on the same texts to understand the benefits of providing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_zero_shot_vs_few_shot(test_texts: List[str]):\n",
    "    \"\"\"\n",
    "    Compare zero-shot and few-shot classification performance.\n",
    "    \n",
    "    Args:\n",
    "        test_texts: List of texts to classify\n",
    "    \"\"\"\n",
    "    print(\"‚öñÔ∏è ZERO-SHOT vs FEW-SHOT COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    for i, text in enumerate(test_texts, 1):\n",
    "        print(f\"\\nüìù Text {i}: \\\"{text[:60]}{'...' if len(text) > 60 else ''}\\\"\")\n",
    "        \n",
    "        # Zero-shot classification\n",
    "        zero_shot_start = time.time()\n",
    "        try:\n",
    "            zero_shot_result = zero_shot_classifier(\n",
    "                text, \n",
    "                candidate_labels=[\"hate speech\", \"normal speech\"]\n",
    "            )\n",
    "            zero_shot_time = time.time() - zero_shot_start\n",
    "            zero_shot_pred = zero_shot_result['labels'][0]\n",
    "            zero_shot_conf = zero_shot_result['scores'][0]\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Zero-shot error: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Few-shot classification\n",
    "        few_shot_start = time.time()\n",
    "        few_shot_result = few_shot_classifier.classify(text, num_examples=3)\n",
    "        few_shot_time = time.time() - few_shot_start\n",
    "        \n",
    "        # Store results\n",
    "        comparison_results.append({\n",
    "            'text': text,\n",
    "            'zero_shot_pred': zero_shot_pred,\n",
    "            'zero_shot_conf': zero_shot_conf,\n",
    "            'zero_shot_time': zero_shot_time,\n",
    "            'few_shot_pred': few_shot_result['prediction'],\n",
    "            'few_shot_conf': few_shot_result['confidence'],\n",
    "            'few_shot_time': few_shot_time\n",
    "        })\n",
    "        \n",
    "        print(f\"   üîµ Zero-shot: {zero_shot_pred} (conf: {zero_shot_conf:.3f}, time: {zero_shot_time:.2f}s)\")\n",
    "        print(f\"   üü° Few-shot:  {few_shot_result['prediction']} (conf: {few_shot_result['confidence']:.3f}, time: {few_shot_time:.2f}s)\")\n",
    "        \n",
    "        # Highlight agreement/disagreement\n",
    "        if zero_shot_pred == few_shot_result['prediction']:\n",
    "            print(f\"   ‚úÖ Agreement: Both methods agree\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Disagreement: Methods differ\")\n",
    "    \n",
    "    return comparison_results\n",
    "\n",
    "# Run comparison on a subset of test posts\n",
    "comparison_data = compare_zero_shot_vs_few_shot(test_posts[:6])  # Use first 6 for detailed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of the comparison\n",
    "if comparison_data:\n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Plot performance comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Confidence comparison\n",
    "    axes[0].scatter(df_comparison['zero_shot_conf'], df_comparison['few_shot_conf'], \n",
    "                   alpha=0.7, s=100, c='blue')\n",
    "    axes[0].plot([0, 1], [0, 1], 'r--', alpha=0.5, label='Perfect correlation')\n",
    "    axes[0].set_xlabel('Zero-Shot Confidence')\n",
    "    axes[0].set_ylabel('Few-Shot Confidence')\n",
    "    axes[0].set_title('Confidence Comparison')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Time comparison\n",
    "    methods = ['Zero-Shot', 'Few-Shot']\n",
    "    avg_times = [df_comparison['zero_shot_time'].mean(), df_comparison['few_shot_time'].mean()]\n",
    "    \n",
    "    bars = axes[1].bar(methods, avg_times, color=['lightblue', 'orange'], alpha=0.7)\n",
    "    axes[1].set_ylabel('Average Time (seconds)')\n",
    "    axes[1].set_title('Average Classification Time')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, time_val in zip(bars, avg_times):\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{time_val:.2f}s', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate agreement rate\n",
    "    agreements = sum(1 for row in comparison_data \n",
    "                    if row['zero_shot_pred'] == row['few_shot_pred'])\n",
    "    agreement_rate = agreements / len(comparison_data) * 100\n",
    "    \n",
    "    print(f\"\\nüìä COMPARISON SUMMARY:\")\n",
    "    print(f\"   Agreement Rate: {agreement_rate:.1f}% ({agreements}/{len(comparison_data)})\")\n",
    "    print(f\"   Average Zero-Shot Time: {df_comparison['zero_shot_time'].mean():.2f}s\")\n",
    "    print(f\"   Average Few-Shot Time: {df_comparison['few_shot_time'].mean():.2f}s\")\n",
    "    print(f\"   Average Zero-Shot Confidence: {df_comparison['zero_shot_conf'].mean():.3f}\")\n",
    "    print(f\"   Average Few-Shot Confidence: {df_comparison['few_shot_conf'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Prompt Engineering for Better Few-Shot Performance\n",
    "\n",
    "The quality and selection of examples in few-shot learning significantly impacts performance. Let's explore different prompt engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_with_different_prompts(text_to_classify: str):\n",
    "    \"\"\"\n",
    "    Experiment with different prompt structures and example counts.\n",
    "    \n",
    "    Args:\n",
    "        text_to_classify: Text to classify with different approaches\n",
    "    \"\"\"\n",
    "    print(f\"üî¨ PROMPT ENGINEERING EXPERIMENTS\")\n",
    "    print(f\"Text to classify: \\\"{text_to_classify}\\\"\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Experiment 1: Different numbers of examples\n",
    "    print(\"\\nüìä Experiment 1: Effect of Example Count\")\n",
    "    for num_examples in [2, 3, 4, 5]:\n",
    "        result = few_shot_classifier.classify(text_to_classify, num_examples=num_examples)\n",
    "        print(f\"   {num_examples} examples: {result['prediction']} (conf: {result['confidence']:.2f})\")\n",
    "    \n",
    "    # Experiment 2: Different prompt styles\n",
    "    print(\"\\nüìù Experiment 2: Different Prompt Styles\")\n",
    "    \n",
    "    # Style 1: More detailed instructions\n",
    "    detailed_prompt = f\"\"\"\n",
    "You are an expert content moderator. Classify social media posts as \"hate speech\" or \"normal speech\".\n",
    "\n",
    "Hate speech includes content that attacks or demeans people based on protected characteristics like race, religion, gender, etc.\n",
    "Normal speech includes opinions, criticism, and regular communication that doesn't target protected groups.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Post: \"Great job on your presentation! Really impressive work.\"\n",
    "Classification: normal speech\n",
    "\n",
    "Post: \"All immigrants are criminals and should be sent back where they came from.\"\n",
    "Classification: hate speech\n",
    "\n",
    "Post: \"I disagree with this policy, but I respect your opinion.\"\n",
    "Classification: normal speech\n",
    "\n",
    "Now classify:\n",
    "Post: \"{text_to_classify}\"\n",
    "Classification:\"\"\"\n",
    "    \n",
    "    # Test detailed prompt (simplified version using our classifier)\n",
    "    result_detailed = few_shot_classifier.classify(text_to_classify, num_examples=3)\n",
    "    print(f\"   Standard prompt: {result_detailed['prediction']} (conf: {result_detailed['confidence']:.2f})\")\n",
    "    \n",
    "    print(\"\\nüí° Key Insights:\")\n",
    "    print(\"   - More examples generally improve consistency\")\n",
    "    print(\"   - Diverse examples help with edge cases\")\n",
    "    print(\"   - Clear instructions reduce ambiguity\")\n",
    "    print(\"   - Balanced examples prevent bias toward one class\")\n",
    "\n",
    "# Test with an ambiguous example\n",
    "experiment_with_different_prompts(\n",
    "    \"The government's new immigration policy is completely misguided and harmful.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Best Practices for Few-Shot Learning\n",
    "\n",
    "Based on our experiments, let's summarize the best practices for effective few-shot learning in hate speech classification and other text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_best_practices():\n",
    "    \"\"\"\n",
    "    Demonstrate best practices for few-shot learning.\n",
    "    \"\"\"\n",
    "    print(\"‚úÖ FEW-SHOT LEARNING BEST PRACTICES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    practices = {\n",
    "        \"üìä Example Selection\": [\n",
    "            \"Use 2-5 examples (diminishing returns beyond 5)\",\n",
    "            \"Include diverse, representative cases\",\n",
    "            \"Balance positive and negative examples\",\n",
    "            \"Choose clear, unambiguous examples\",\n",
    "            \"Include edge cases if relevant to your domain\"\n",
    "        ],\n",
    "        \n",
    "        \"üìù Prompt Structure\": [\n",
    "            \"Start with clear task description\",\n",
    "            \"Use consistent format for all examples\",\n",
    "            \"Provide explicit input-output mapping\",\n",
    "            \"End with clear prompt for new classification\",\n",
    "            \"Use natural, readable language\"\n",
    "        ],\n",
    "        \n",
    "        \"üéØ Model Configuration\": [\n",
    "            \"Use low temperature (0.1-0.3) for consistency\",\n",
    "            \"Limit max generation length to prevent rambling\",\n",
    "            \"Consider using stop tokens for cleaner output\",\n",
    "            \"Monitor for repetition and adjust sampling\",\n",
    "            \"Handle edge cases and parsing errors\"\n",
    "        ],\n",
    "        \n",
    "        \"‚öñÔ∏è Evaluation Strategies\": [\n",
    "            \"Compare against zero-shot baselines\",\n",
    "            \"Test on held-out examples\",\n",
    "            \"Monitor consistency across similar inputs\",\n",
    "            \"Check for bias in example selection\",\n",
    "            \"Validate on edge cases and ambiguous examples\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, tips in practices.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for tip in tips:\n",
    "            print(f\"  ‚Ä¢ {tip}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üö® Common Pitfalls to Avoid:\")\n",
    "    pitfalls = [\n",
    "        \"Using biased or non-representative examples\",\n",
    "        \"Inconsistent formatting between examples\",\n",
    "        \"Too many examples (leads to context overflow)\",\n",
    "        \"Ambiguous or controversial examples\",\n",
    "        \"Not handling model generation errors\",\n",
    "        \"Ignoring computational cost vs. zero-shot alternatives\"\n",
    "    ]\n",
    "    \n",
    "    for pitfall in pitfalls:\n",
    "        print(f\"  ‚ùå {pitfall}\")\n",
    "\n",
    "demonstrate_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Real-World Applications and Limitations\n",
    "\n",
    "Let's explore when few-shot learning is most effective and understand its limitations in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_real_world_applications():\n",
    "    \"\"\"\n",
    "    Analyze real-world applications and limitations of few-shot learning.\n",
    "    \"\"\"\n",
    "    print(\"üåç REAL-WORLD APPLICATIONS & LIMITATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    applications = {\n",
    "        \"üéØ Ideal Use Cases\": [\n",
    "            \"Content moderation for new platforms\",\n",
    "            \"Customer service ticket classification\",\n",
    "            \"Social media monitoring and brand safety\",\n",
    "            \"Legal document categorization\",\n",
    "            \"Medical text classification (with domain examples)\",\n",
    "            \"Sentiment analysis for specific domains\"\n",
    "        ],\n",
    "        \n",
    "        \"‚ö†Ô∏è Limitations\": [\n",
    "            \"Computational cost higher than zero-shot\",\n",
    "            \"Sensitive to example quality and selection\",\n",
    "            \"May not scale to very large taxonomies\",\n",
    "            \"Context length limits number of examples\",\n",
    "            \"Consistency can vary between similar inputs\",\n",
    "            \"Difficult to version control and A/B test\"\n",
    "        ],\n",
    "        \n",
    "        \"üìà When to Choose Few-Shot over Alternatives\": [\n",
    "            \"Zero-shot performance insufficient\",\n",
    "            \"Limited labeled data available\",\n",
    "            \"Need rapid deployment\",\n",
    "            \"Domain-specific terminology important\",\n",
    "            \"Classifications require nuanced understanding\",\n",
    "            \"Cost/time prohibits fine-tuning\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, items in applications.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  ‚Ä¢ {item}\")\n",
    "    \n",
    "    # Performance characteristics table\n",
    "    print(\"\\nüìä PERFORMANCE CHARACTERISTICS COMPARISON:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    comparison_table = pd.DataFrame({\n",
    "        'Approach': ['Zero-Shot', 'Few-Shot', 'Fine-Tuning'],\n",
    "        'Setup Time': ['Instant', 'Minutes', 'Hours/Days'],\n",
    "        'Data Needed': ['0 examples', '2-5 examples', '100s-1000s examples'],\n",
    "        'Compute Cost': ['Low', 'Medium', 'High'],\n",
    "        'Accuracy': ['Good', 'Better', 'Best'],\n",
    "        'Consistency': ['High', 'Medium', 'High'],\n",
    "        'Flexibility': ['High', 'High', 'Low']\n",
    "    })\n",
    "    \n",
    "    print(comparison_table.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nüí° Decision Framework:\")\n",
    "    print(\"   1. Try zero-shot first (fastest, cheapest)\")\n",
    "    print(\"   2. Add few-shot if zero-shot insufficient\")\n",
    "    print(\"   3. Consider fine-tuning for production at scale\")\n",
    "    print(\"   4. Measure and compare all approaches on your data\")\n",
    "\n",
    "analyze_real_world_applications()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Summary\n",
    "\n",
    "### üîë Key Concepts Mastered\n",
    "- **Few-Shot Learning**: Learning from 2-5 examples provided in the prompt without parameter updates\n",
    "- **In-Context Learning**: GPT-3 style learning where examples teach the model the task format\n",
    "- **Prompt Engineering**: Crafting effective prompts with representative examples for optimal performance\n",
    "- **Hate Speech Classification**: Practical application of few-shot learning for content moderation\n",
    "- **Performance Trade-offs**: Understanding when few-shot outperforms zero-shot approaches\n",
    "\n",
    "### üìà Best Practices Learned\n",
    "- Use 2-5 diverse, representative examples for optimal balance of performance and efficiency\n",
    "- Maintain consistent formatting and clear task descriptions in prompts\n",
    "- Configure models with low temperature (0.1-0.3) for more consistent outputs\n",
    "- Compare against zero-shot baselines to validate the added complexity is worthwhile\n",
    "- Handle edge cases and parsing errors gracefully in production systems\n",
    "- Balance example diversity with clarity to avoid confusing the model\n",
    "\n",
    "### üöÄ Next Steps\n",
    "- **Advanced Prompting**: Explore chain-of-thought and instruction following techniques\n",
    "- **Fine-Tuning**: Learn when and how to fine-tune models for better performance ([Notebook 05](../05_fine_tuning_trainer.ipynb))\n",
    "- **Evaluation Metrics**: Implement comprehensive evaluation frameworks for classification tasks\n",
    "- **Production Deployment**: Scale few-shot learning systems for real-world applications\n",
    "- **Multimodal Learning**: Extend few-shot learning to image and text combinations\n",
    "\n",
    "### üéØ Key Takeaway\n",
    "Few-shot learning provides a powerful middle ground between zero-shot and fine-tuning approaches. By carefully selecting 2-5 representative examples and engineering effective prompts, you can significantly improve classification performance without the time and resource investment required for fine-tuning. This makes few-shot learning particularly valuable for rapid prototyping, domain-specific applications, and scenarios where labeled data is scarce but some examples are available.\n",
    "\n",
    "---\n",
    "\n",
    "## About the Author\n",
    "\n",
    "**Vu Hung Nguyen** - AI Engineer & Researcher\n",
    "\n",
    "Connect with me:\n",
    "- üåê **Website**: [vuhung16au.github.io](https://vuhung16au.github.io/)\n",
    "- üíº **LinkedIn**: [linkedin.com/in/nguyenvuhung](https://www.linkedin.com/in/nguyenvuhung/)\n",
    "- üíª **GitHub**: [github.com/vuhung16au](https://github.com/vuhung16au/)\n",
    "\n",
    "*This notebook is part of the [HF Transformer Trove](https://github.com/vuhung16au/hf-transformer-trove) educational series.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}