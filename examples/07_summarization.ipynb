{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Summarization Pipeline: From Text to Concise Summaries\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- Text summarization concepts (extractive vs abstractive)\n",
    "- Using pre-trained summarization models\n",
    "- Fine-tuning summarization models\n",
    "- Evaluation metrics for summarization\n",
    "- Building production-ready summarization systems\n",
    "- Handling different text lengths and domains\n",
    "\n",
    "## Introduction to Text Summarization\n",
    "\n",
    "Text summarization is the task of creating a concise and coherent summary of a longer document while preserving key information and meaning.\n",
    "\n",
    "### Types of Summarization:\n",
    "- **Extractive**: Selects important sentences/phrases from the original text\n",
    "- **Abstractive**: Generates new text that captures the essence of the original\n",
    "\n",
    "### Applications:\n",
    "- News article summarization\n",
    "- Document summarization for research\n",
    "- Meeting notes summarization\n",
    "- Email/message summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "    pipeline, Trainer, TrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from evaluate import load as load_metric\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data if needed\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Exploring Pre-trained Summarization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load different summarization models\n",
    "summarization_models = {\n",
    "    \"BART-CNN\": \"facebook/bart-large-cnn\",\n",
    "    \"T5-Small\": \"t5-small\",\n",
    "    \"DistilBART\": \"sshleifer/distilbart-cnn-12-6\",\n",
    "    \"Pegasus-XSum\": \"google/pegasus-xsum\"\n",
    "}\n",
    "\n",
    "# Sample article for testing\n",
    "sample_article = \"\"\"\n",
    "The rapid advancement of artificial intelligence (AI) has transformed numerous industries and aspects of daily life. \n",
    "Machine learning algorithms, particularly deep neural networks, have achieved remarkable success in tasks ranging \n",
    "from image recognition to natural language processing. Companies across various sectors are integrating AI \n",
    "technologies to improve efficiency, reduce costs, and enhance user experiences.\n",
    "\n",
    "However, the widespread adoption of AI also raises significant concerns about job displacement, privacy, and ethical \n",
    "implications. Many workers fear that automation will make their jobs obsolete, while others worry about the \n",
    "potential misuse of AI for surveillance and manipulation. Experts emphasize the importance of developing AI \n",
    "responsibly, with proper regulations and safeguards in place.\n",
    "\n",
    "Despite these challenges, the potential benefits of AI are substantial. In healthcare, AI-powered diagnostic tools \n",
    "can help detect diseases earlier and more accurately than traditional methods. In education, personalized learning \n",
    "platforms can adapt to individual student needs, improving learning outcomes. The key is to balance innovation \n",
    "with responsibility, ensuring that AI development serves humanity's best interests while minimizing potential risks.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sample article ({len(sample_article.split())} words):\")\n",
    "print(sample_article.strip())\n",
    "\n",
    "# Test different models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING DIFFERENT SUMMARIZATION MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summaries = {}\n",
    "\n",
    "for model_name, model_id in summarization_models.items():\n",
    "    try:\n",
    "        print(f\"\\nTesting {model_name} ({model_id})...\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        summarizer = pipeline(\n",
    "            \"summarization\",\n",
    "            model=model_id,\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = summarizer(\n",
    "            sample_article,\n",
    "            max_length=100,\n",
    "            min_length=30,\n",
    "            do_sample=False,\n",
    "            truncation=True\n",
    "        )[0]['summary_text']\n",
    "        \n",
    "        summaries[model_name] = summary\n",
    "        \n",
    "        print(f\"Summary ({len(summary.split())} words): {summary}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nSuccessfully tested {len(summaries)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Loading and Analyzing Summarization Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN/DailyMail dataset (popular for summarization)\n",
    "print(\"Loading CNN/DailyMail dataset...\")\n",
    "\n",
    "try:\n",
    "    # Load a small subset for demonstration\n",
    "    dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\n",
    "    \n",
    "    print(f\"Dataset loaded: {len(dataset)} examples\")\n",
    "    print(f\"Features: {dataset.features}\")\n",
    "    \n",
    "    # Examine a sample\n",
    "    sample = dataset[0]\n",
    "    print(f\"\\nSample article (first 300 chars):\")\n",
    "    print(sample['article'][:300] + \"...\")\n",
    "    \n",
    "    print(f\"\\nSample highlights:\")\n",
    "    print(sample['highlights'])\n",
    "    \n",
    "    # Analyze dataset statistics\n",
    "    article_lengths = [len(example['article'].split()) for example in dataset.select(range(100))]\n",
    "    highlight_lengths = [len(example['highlights'].split()) for example in dataset.select(range(100))]\n",
    "    \n",
    "    print(f\"\\nDataset statistics (first 100 examples):\")\n",
    "    print(f\"Article length - Mean: {np.mean(article_lengths):.1f}, Median: {np.median(article_lengths):.1f}\")\n",
    "    print(f\"Highlight length - Mean: {np.mean(highlight_lengths):.1f}, Median: {np.median(highlight_lengths):.1f}\")\n",
    "    print(f\"Compression ratio: {np.mean(article_lengths) / np.mean(highlight_lengths):.1f}:1\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    # Create a synthetic dataset for demonstration\n",
    "    print(\"Creating synthetic dataset for demonstration...\")\n",
    "    \n",
    "    synthetic_data = {\n",
    "        'article': [\n",
    "            \"The stock market experienced significant volatility today as investors reacted to news about inflation rates. Technology stocks led the decline with major companies seeing drops of 3-5%. Financial analysts suggest this is a temporary correction rather than a long-term trend. The Federal Reserve is expected to make an announcement about interest rates next week.\",\n",
    "            \"A new study published in Nature reveals groundbreaking findings about climate change impacts on ocean ecosystems. Researchers found that rising temperatures are affecting marine biodiversity more severely than previously thought. The study analyzed data from over 50 locations worldwide and suggests immediate action is needed to protect marine life.\",\n",
    "            \"Local authorities have announced the completion of a major infrastructure project that will improve transportation in the metropolitan area. The new highway system is expected to reduce commute times by 30% and create thousands of jobs. The project took five years to complete and cost $2.3 billion in total.\"\n",
    "        ],\n",
    "        'highlights': [\n",
    "            \"Stock market drops as tech stocks decline 3-5%. Federal Reserve rate announcement expected next week.\",\n",
    "            \"New Nature study shows climate change severely impacts marine biodiversity. Immediate action needed to protect ocean life.\",\n",
    "            \"New $2.3B highway system completed, expected to reduce commute times by 30% and create jobs.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    dataset = Dataset.from_dict(synthetic_data)\n",
    "    print(f\"Created synthetic dataset with {len(dataset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building a Comprehensive Summarization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationPipeline:\n",
    "    \"\"\"Comprehensive pipeline for text summarization\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"facebook/bart-large-cnn\"):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.pipeline = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load model and tokenizer\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading summarization model: {self.model_name}\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name)\n",
    "            \n",
    "            self.pipeline = pipeline(\n",
    "                \"summarization\",\n",
    "                model=self.model,\n",
    "                tokenizer=self.tokenizer,\n",
    "                device=0 if torch.cuda.is_available() else -1\n",
    "            )\n",
    "            \n",
    "            print(\"✓ Model loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error loading model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocess text for summarization\"\"\"\n",
    "        # Basic cleaning\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # Check length constraints\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        max_input_length = self.tokenizer.model_max_length - 100  # Leave room for special tokens\n",
    "        \n",
    "        if len(tokens) > max_input_length:\n",
    "            # Truncate to max length\n",
    "            truncated_tokens = tokens[:max_input_length]\n",
    "            text = self.tokenizer.decode(truncated_tokens, skip_special_tokens=True)\n",
    "            print(f\"⚠️  Text truncated to {len(truncated_tokens)} tokens\")\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def summarize(\n",
    "        self, \n",
    "        text, \n",
    "        max_length=150, \n",
    "        min_length=50, \n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        do_sample=False\n",
    "    ):\n",
    "        \"\"\"Generate summary with customizable parameters\"\"\"\n",
    "        \n",
    "        # Preprocess\n",
    "        processed_text = self.preprocess_text(text)\n",
    "        \n",
    "        try:\n",
    "            # Generate summary\n",
    "            summary = self.pipeline(\n",
    "                processed_text,\n",
    "                max_length=max_length,\n",
    "                min_length=min_length,\n",
    "                length_penalty=length_penalty,\n",
    "                num_beams=num_beams,\n",
    "                do_sample=do_sample,\n",
    "                truncation=True\n",
    "            )[0]['summary_text']\n",
    "            \n",
    "            return {\n",
    "                'original_text': text,\n",
    "                'processed_text': processed_text,\n",
    "                'summary': summary,\n",
    "                'original_length': len(text.split()),\n",
    "                'summary_length': len(summary.split()),\n",
    "                'compression_ratio': len(text.split()) / len(summary.split())\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'original_text': text,\n",
    "                'summary': None,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    def batch_summarize(self, texts, **kwargs):\n",
    "        \"\"\"Summarize multiple texts efficiently\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        print(f\"Summarizing {len(texts)} texts...\")\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Progress: {i}/{len(texts)}\")\n",
    "            \n",
    "            result = self.summarize(text, **kwargs)\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_summaries(self, results):\n",
    "        \"\"\"Analyze batch summarization results\"\"\"\n",
    "        successful_results = [r for r in results if 'error' not in r]\n",
    "        \n",
    "        if not successful_results:\n",
    "            print(\"No successful summarizations to analyze\")\n",
    "            return\n",
    "        \n",
    "        compression_ratios = [r['compression_ratio'] for r in successful_results]\n",
    "        original_lengths = [r['original_length'] for r in successful_results]\n",
    "        summary_lengths = [r['summary_length'] for r in successful_results]\n",
    "        \n",
    "        print(f\"\\nSummarization Analysis:\")\n",
    "        print(f\"  Successful: {len(successful_results)}/{len(results)}\")\n",
    "        print(f\"  Average compression ratio: {np.mean(compression_ratios):.2f}:1\")\n",
    "        print(f\"  Average original length: {np.mean(original_lengths):.1f} words\")\n",
    "        print(f\"  Average summary length: {np.mean(summary_lengths):.1f} words\")\n",
    "        \n",
    "        return {\n",
    "            'successful_count': len(successful_results),\n",
    "            'total_count': len(results),\n",
    "            'avg_compression_ratio': np.mean(compression_ratios),\n",
    "            'avg_original_length': np.mean(original_lengths),\n",
    "            'avg_summary_length': np.mean(summary_lengths)\n",
    "        }\n",
    "\n",
    "# Initialize summarization pipeline\n",
    "summarizer = SummarizationPipeline(\"sshleifer/distilbart-cnn-12-6\")  # Smaller model for demo\n",
    "\n",
    "# Test with sample article\n",
    "print(\"\\nTesting summarization pipeline...\")\n",
    "result = summarizer.summarize(sample_article, max_length=80, min_length=30)\n",
    "\n",
    "print(f\"\\nSummarization Result:\")\n",
    "print(f\"Original length: {result['original_length']} words\")\n",
    "print(f\"Summary length: {result['summary_length']} words\")\n",
    "print(f\"Compression ratio: {result['compression_ratio']:.2f}:1\")\n",
    "print(f\"Summary: {result['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation Metrics for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement ROUGE evaluation\n",
    "try:\n",
    "    rouge_metric = load_metric(\"rouge\")\n",
    "    print(\"✓ ROUGE metric loaded\")\n",
    "except:\n",
    "    print(\"⚠️  ROUGE metric not available, implementing basic evaluation\")\n",
    "    rouge_metric = None\n",
    "\n",
    "def evaluate_summarization(predictions, references):\n",
    "    \"\"\"Evaluate summarization quality using ROUGE and other metrics\"\"\"\n",
    "    \n",
    "    if rouge_metric:\n",
    "        # ROUGE evaluation\n",
    "        rouge_scores = rouge_metric.compute(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "            use_stemmer=True\n",
    "        )\n",
    "    else:\n",
    "        # Basic overlap-based evaluation\n",
    "        rouge_scores = None\n",
    "    \n",
    "    # Additional metrics\n",
    "    compression_ratios = []\n",
    "    length_differences = []\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        pred_len = len(pred.split())\n",
    "        ref_len = len(ref.split())\n",
    "        \n",
    "        if pred_len > 0:\n",
    "            compression_ratios.append(ref_len / pred_len)\n",
    "        length_differences.append(abs(pred_len - ref_len))\n",
    "    \n",
    "    metrics = {\n",
    "        'avg_compression_ratio': np.mean(compression_ratios) if compression_ratios else 0,\n",
    "        'avg_length_difference': np.mean(length_differences),\n",
    "        'rouge_scores': rouge_scores\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Test evaluation on dataset samples\n",
    "print(\"Testing summarization evaluation...\")\n",
    "\n",
    "# Get a few examples from dataset\n",
    "test_examples = dataset.select(range(min(5, len(dataset))))\n",
    "test_articles = [ex['article'] for ex in test_examples]\n",
    "reference_summaries = [ex['highlights'] for ex in test_examples]\n",
    "\n",
    "# Generate summaries\n",
    "print(\"Generating summaries for evaluation...\")\n",
    "generated_summaries = []\n",
    "\n",
    "for i, article in enumerate(test_articles):\n",
    "    result = summarizer.summarize(article, max_length=100, min_length=20)\n",
    "    if 'error' not in result:\n",
    "        generated_summaries.append(result['summary'])\n",
    "    else:\n",
    "        generated_summaries.append(\"\")\n",
    "    print(f\"Processed {i+1}/{len(test_articles)}\")\n",
    "\n",
    "# Filter out empty summaries\n",
    "valid_pairs = [(g, r) for g, r in zip(generated_summaries, reference_summaries) if g.strip()]\n",
    "if valid_pairs:\n",
    "    valid_generated, valid_references = zip(*valid_pairs)\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_metrics = evaluate_summarization(list(valid_generated), list(valid_references))\n",
    "    \n",
    "    print(f\"\\nEvaluation Results ({len(valid_pairs)} valid pairs):\")\n",
    "    print(f\"Average compression ratio: {eval_metrics['avg_compression_ratio']:.2f}:1\")\n",
    "    print(f\"Average length difference: {eval_metrics['avg_length_difference']:.1f} words\")\n",
    "    \n",
    "    if eval_metrics['rouge_scores']:\n",
    "        rouge = eval_metrics['rouge_scores']\n",
    "        print(f\"ROUGE-1 F1: {rouge['rouge1']:.4f}\")\n",
    "        print(f\"ROUGE-2 F1: {rouge['rouge2']:.4f}\")\n",
    "        print(f\"ROUGE-L F1: {rouge['rougeL']:.4f}\")\n",
    "    \n",
    "    # Show example comparison\n",
    "    print(f\"\\nExample Comparison:\")\n",
    "    print(f\"Original: {test_articles[0][:200]}...\")\n",
    "    print(f\"Reference: {reference_summaries[0]}\")\n",
    "    print(f\"Generated: {generated_summaries[0]}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No valid summary pairs for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Advanced Summarization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement different summarization strategies\n",
    "class AdvancedSummarizer:\n",
    "    \"\"\"Advanced summarization with multiple strategies\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"sshleifer/distilbart-cnn-12-6\"):\n",
    "        self.base_summarizer = SummarizationPipeline(model_name)\n",
    "    \n",
    "    def extractive_summary(self, text, num_sentences=3):\n",
    "        \"\"\"Simple extractive summarization using sentence scoring\"\"\"\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        if len(sentences) <= num_sentences:\n",
    "            return ' '.join(sentences)\n",
    "        \n",
    "        # Simple scoring based on sentence length and position\n",
    "        scores = []\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            # Score based on length (prefer medium-length sentences)\n",
    "            length_score = min(len(sentence.split()) / 20, 1.0)\n",
    "            \n",
    "            # Score based on position (prefer early sentences)\n",
    "            position_score = 1.0 - (i / len(sentences))\n",
    "            \n",
    "            # Combined score\n",
    "            total_score = length_score * 0.6 + position_score * 0.4\n",
    "            scores.append((total_score, sentence))\n",
    "        \n",
    "        # Select top sentences\n",
    "        scores.sort(reverse=True)\n",
    "        selected_sentences = [sentence for _, sentence in scores[:num_sentences]]\n",
    "        \n",
    "        return ' '.join(selected_sentences)\n",
    "    \n",
    "    def multi_strategy_summary(self, text, strategies=['abstractive', 'extractive']):\n",
    "        \"\"\"Generate summaries using multiple strategies\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        if 'abstractive' in strategies:\n",
    "            abs_result = self.base_summarizer.summarize(text)\n",
    "            if 'error' not in abs_result:\n",
    "                results['abstractive'] = abs_result['summary']\n",
    "        \n",
    "        if 'extractive' in strategies:\n",
    "            results['extractive'] = self.extractive_summary(text)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def adaptive_summary(self, text):\n",
    "        \"\"\"Choose best strategy based on text characteristics\"\"\"\n",
    "        words = text.split()\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        avg_sentence_length = len(words) / len(sentences)\n",
    "        \n",
    "        # Use extractive for very long texts or texts with long sentences\n",
    "        if len(words) > 1000 or avg_sentence_length > 30:\n",
    "            print(\"Using extractive summarization (long/complex text)\")\n",
    "            return self.extractive_summary(text)\n",
    "        else:\n",
    "            print(\"Using abstractive summarization (standard text)\")\n",
    "            result = self.base_summarizer.summarize(text)\n",
    "            return result['summary'] if 'error' not in result else self.extractive_summary(text)\n",
    "\n",
    "# Test advanced summarization\n",
    "advanced_summarizer = AdvancedSummarizer()\n",
    "\n",
    "print(\"Testing advanced summarization strategies...\")\n",
    "\n",
    "# Test with sample article\n",
    "multi_summaries = advanced_summarizer.multi_strategy_summary(\n",
    "    sample_article, \n",
    "    strategies=['abstractive', 'extractive']\n",
    ")\n",
    "\n",
    "print(f\"\\nMulti-strategy summaries:\")\n",
    "for strategy, summary in multi_summaries.items():\n",
    "    print(f\"\\n{strategy.upper()}: {summary}\")\n",
    "\n",
    "# Test adaptive summarization\n",
    "print(f\"\\nAdaptive summarization:\")\n",
    "adaptive_summary = advanced_summarizer.adaptive_summary(sample_article)\n",
    "print(f\"Result: {adaptive_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Domain-Specific Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create domain-specific summarizers\n",
    "def create_domain_examples():\n",
    "    \"\"\"Create examples from different domains\"\"\"\n",
    "    return {\n",
    "        'news': {\n",
    "            'text': \"\"\"\n",
    "            WASHINGTON - The Federal Reserve announced today a 0.25% increase in interest rates, \n",
    "            marking the fourth rate hike this year. Fed Chairman Jerome Powell cited persistent \n",
    "            inflation concerns and a robust job market as key factors in the decision. \n",
    "            The move was widely anticipated by financial markets, which showed minimal reaction \n",
    "            to the announcement. Economists predict this could be the final rate increase of \n",
    "            the year as inflation shows signs of moderating. The decision was unanimous among \n",
    "            Federal Open Market Committee members.\n",
    "            \"\"\",\n",
    "            'focus': 'key facts and outcomes'\n",
    "        },\n",
    "        'scientific': {\n",
    "            'text': \"\"\"\n",
    "            A new study published in the Journal of Climate Research reveals that Arctic \n",
    "            ice is melting at an unprecedented rate. The research team, led by Dr. Sarah \n",
    "            Chen from the University of Climate Studies, analyzed satellite data spanning \n",
    "            20 years. The findings indicate that ice thickness has decreased by 40% since \n",
    "            2003, with accelerated melting observed in the past five years. The study \n",
    "            employed advanced machine learning algorithms to process terabytes of satellite \n",
    "            imagery and temperature measurements. Researchers warn that this trend could \n",
    "            lead to significant sea level rise and disruption of global weather patterns.\n",
    "            \"\"\",\n",
    "            'focus': 'methodology and findings'\n",
    "        },\n",
    "        'business': {\n",
    "            'text': \"\"\"\n",
    "            TechCorp Inc. reported record quarterly earnings of $2.1 billion, exceeding \n",
    "            analyst expectations by 15%. The company's cloud services division drove \n",
    "            most of the growth, with revenue increasing 45% year-over-year. CEO Michael \n",
    "            Roberts attributed the success to strategic acquisitions and expanded \n",
    "            international operations. The company also announced a $500 million share \n",
    "            buyback program and increased its quarterly dividend by 8%. Looking ahead, \n",
    "            TechCorp expects continued growth in AI and cloud computing markets, \n",
    "            projecting 25-30% revenue growth for the next quarter.\n",
    "            \"\"\",\n",
    "            'focus': 'financial performance and outlook'\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test domain-specific summarization\n",
    "domain_examples = create_domain_examples()\n",
    "\n",
    "print(\"DOMAIN-SPECIFIC SUMMARIZATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for domain, example in domain_examples.items():\n",
    "    print(f\"\\n{domain.upper()} DOMAIN:\")\n",
    "    print(f\"Focus: {example['focus']}\")\n",
    "    \n",
    "    # Generate summary with different parameters based on domain\n",
    "    if domain == 'news':\n",
    "        # News: focus on key facts, shorter summaries\n",
    "        result = summarizer.summarize(\n",
    "            example['text'], \n",
    "            max_length=60, \n",
    "            min_length=25,\n",
    "            num_beams=6  # More focused beam search\n",
    "        )\n",
    "    elif domain == 'scientific':\n",
    "        # Scientific: preserve methodology and findings\n",
    "        result = summarizer.summarize(\n",
    "            example['text'], \n",
    "            max_length=80, \n",
    "            min_length=40,\n",
    "            length_penalty=1.5  # Less aggressive length penalty\n",
    "        )\n",
    "    elif domain == 'business':\n",
    "        # Business: include key numbers and outlook\n",
    "        result = summarizer.summarize(\n",
    "            example['text'], \n",
    "            max_length=70, \n",
    "            min_length=35,\n",
    "            num_beams=4\n",
    "        )\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"Summary: {result['summary']}\")\n",
    "        print(f\"Compression: {result['compression_ratio']:.1f}:1\")\n",
    "    else:\n",
    "        print(f\"Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization of summarization results\n",
    "def analyze_and_visualize_summarization():\n",
    "    \"\"\"Analyze and visualize summarization performance\"\"\"\n",
    "    \n",
    "    # Generate summaries for analysis\n",
    "    analysis_texts = [example['text'] for example in domain_examples.values()]\n",
    "    analysis_texts.append(sample_article)\n",
    "    \n",
    "    # Different length configurations\n",
    "    length_configs = [\n",
    "        {'name': 'Short', 'max_length': 50, 'min_length': 20},\n",
    "        {'name': 'Medium', 'max_length': 80, 'min_length': 40},\n",
    "        {'name': 'Long', 'max_length': 120, 'min_length': 60}\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for text in analysis_texts:\n",
    "        text_results = {'original_length': len(text.split())}\n",
    "        \n",
    "        for config in length_configs:\n",
    "            result = summarizer.summarize(\n",
    "                text,\n",
    "                max_length=config['max_length'],\n",
    "                min_length=config['min_length']\n",
    "            )\n",
    "            \n",
    "            if 'error' not in result:\n",
    "                text_results[config['name']] = {\n",
    "                    'length': result['summary_length'],\n",
    "                    'compression': result['compression_ratio'],\n",
    "                    'summary': result['summary']\n",
    "                }\n",
    "        \n",
    "        results.append(text_results)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Summarization Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Summary lengths vs original lengths\n",
    "    original_lengths = [r['original_length'] for r in results]\n",
    "    \n",
    "    for config in length_configs:\n",
    "        config_lengths = [r[config['name']]['length'] for r in results if config['name'] in r]\n",
    "        if config_lengths:\n",
    "            axes[0, 0].scatter(original_lengths[:len(config_lengths)], config_lengths, \n",
    "                             label=config['name'], alpha=0.7, s=60)\n",
    "    \n",
    "    axes[0, 0].set_xlabel('Original Text Length (words)')\n",
    "    axes[0, 0].set_ylabel('Summary Length (words)')\n",
    "    axes[0, 0].set_title('Summary Length vs Original Length')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Compression ratios\n",
    "    compression_data = []\n",
    "    config_names = []\n",
    "    \n",
    "    for config in length_configs:\n",
    "        compressions = [r[config['name']]['compression'] for r in results if config['name'] in r]\n",
    "        if compressions:\n",
    "            compression_data.append(compressions)\n",
    "            config_names.append(config['name'])\n",
    "    \n",
    "    if compression_data:\n",
    "        axes[0, 1].boxplot(compression_data, labels=config_names)\n",
    "        axes[0, 1].set_ylabel('Compression Ratio')\n",
    "        axes[0, 1].set_title('Compression Ratios by Configuration')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Word frequency in summaries (for medium length)\n",
    "    all_summaries = ' '.join([r['Medium']['summary'] for r in results if 'Medium' in r])\n",
    "    words = re.findall(r'\\w+', all_summaries.lower())\n",
    "    word_freq = Counter(words)\n",
    "    \n",
    "    # Remove common stop words and get top words\n",
    "    stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'a', 'an', 'is', 'are', 'was', 'were'}\n",
    "    filtered_freq = {word: count for word, count in word_freq.items() if word not in stop_words and len(word) > 2}\n",
    "    top_words = dict(sorted(filtered_freq.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "    \n",
    "    if top_words:\n",
    "        axes[1, 0].bar(top_words.keys(), top_words.values())\n",
    "        axes[1, 0].set_title('Most Common Words in Summaries')\n",
    "        axes[1, 0].set_xlabel('Words')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        plt.setp(axes[1, 0].xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # 4. Summary length distribution\n",
    "    all_lengths = []\n",
    "    for config in length_configs:\n",
    "        lengths = [r[config['name']]['length'] for r in results if config['name'] in r]\n",
    "        all_lengths.extend(lengths)\n",
    "    \n",
    "    if all_lengths:\n",
    "        axes[1, 1].hist(all_lengths, bins=10, alpha=0.7, edgecolor='black')\n",
    "        axes[1, 1].set_xlabel('Summary Length (words)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Distribution of Summary Lengths')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummarization Statistics:\")\n",
    "    print(f\"Texts analyzed: {len(results)}\")\n",
    "    \n",
    "    for config in length_configs:\n",
    "        lengths = [r[config['name']]['length'] for r in results if config['name'] in r]\n",
    "        compressions = [r[config['name']]['compression'] for r in results if config['name'] in r]\n",
    "        \n",
    "        if lengths and compressions:\n",
    "            print(f\"\\n{config['name']} summaries:\")\n",
    "            print(f\"  Average length: {np.mean(lengths):.1f} words\")\n",
    "            print(f\"  Average compression: {np.mean(compressions):.1f}:1\")\n",
    "            print(f\"  Length range: {min(lengths)}-{max(lengths)} words\")\n",
    "\n",
    "analyze_and_visualize_summarization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Production Deployment Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production-ready summarization service\n",
    "class ProductionSummarizer:\n",
    "    \"\"\"Production-ready summarization service with monitoring and error handling\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"sshleifer/distilbart-cnn-12-6\", cache_size=100):\n",
    "        self.model_name = model_name\n",
    "        self.cache_size = cache_size\n",
    "        self.cache = {}  # Simple LRU cache\n",
    "        self.cache_order = []  # Track cache access order\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.metrics = {\n",
    "            'requests': 0,\n",
    "            'cache_hits': 0,\n",
    "            'errors': 0,\n",
    "            'total_processing_time': 0\n",
    "        }\n",
    "        \n",
    "        # Load model\n",
    "        self.summarizer = SummarizationPipeline(model_name)\n",
    "    \n",
    "    def _get_cache_key(self, text, params):\n",
    "        \"\"\"Generate cache key from text and parameters\"\"\"\n",
    "        import hashlib\n",
    "        content = f\"{text}_{params}\"\n",
    "        return hashlib.md5(content.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def _update_cache(self, key, value):\n",
    "        \"\"\"Update cache with LRU eviction\"\"\"\n",
    "        if key in self.cache:\n",
    "            # Move to end (most recently used)\n",
    "            self.cache_order.remove(key)\n",
    "            self.cache_order.append(key)\n",
    "        else:\n",
    "            # Add new entry\n",
    "            if len(self.cache) >= self.cache_size:\n",
    "                # Remove least recently used\n",
    "                oldest_key = self.cache_order.pop(0)\n",
    "                del self.cache[oldest_key]\n",
    "            \n",
    "            self.cache[key] = value\n",
    "            self.cache_order.append(key)\n",
    "    \n",
    "    def summarize_with_monitoring(self, text, **kwargs):\n",
    "        \"\"\"Summarize with performance monitoring and caching\"\"\"\n",
    "        import time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.metrics['requests'] += 1\n",
    "        \n",
    "        # Check cache\n",
    "        cache_key = self._get_cache_key(text, str(sorted(kwargs.items())))\n",
    "        \n",
    "        if cache_key in self.cache:\n",
    "            self.metrics['cache_hits'] += 1\n",
    "            # Move to end of cache order\n",
    "            self.cache_order.remove(cache_key)\n",
    "            self.cache_order.append(cache_key)\n",
    "            \n",
    "            result = self.cache[cache_key].copy()\n",
    "            result['cached'] = True\n",
    "            return result\n",
    "        \n",
    "        try:\n",
    "            # Generate summary\n",
    "            result = self.summarizer.summarize(text, **kwargs)\n",
    "            \n",
    "            if 'error' not in result:\n",
    "                # Cache successful result\n",
    "                result['cached'] = False\n",
    "                self._update_cache(cache_key, result)\n",
    "            else:\n",
    "                self.metrics['errors'] += 1\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            self.metrics['total_processing_time'] += processing_time\n",
    "            result['processing_time'] = processing_time\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.metrics['errors'] += 1\n",
    "            return {\n",
    "                'error': str(e),\n",
    "                'processing_time': time.time() - start_time\n",
    "            }\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"Get performance metrics\"\"\"\n",
    "        metrics = self.metrics.copy()\n",
    "        \n",
    "        if metrics['requests'] > 0:\n",
    "            metrics['cache_hit_rate'] = metrics['cache_hits'] / metrics['requests']\n",
    "            metrics['error_rate'] = metrics['errors'] / metrics['requests']\n",
    "            metrics['avg_processing_time'] = metrics['total_processing_time'] / metrics['requests']\n",
    "        \n",
    "        metrics['cache_size'] = len(self.cache)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def health_check(self):\n",
    "        \"\"\"Perform health check\"\"\"\n",
    "        try:\n",
    "            test_result = self.summarize_with_monitoring(\n",
    "                \"This is a test summary to check if the service is working properly.\",\n",
    "                max_length=30,\n",
    "                min_length=10\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'status': 'healthy' if 'error' not in test_result else 'unhealthy',\n",
    "                'test_result': test_result,\n",
    "                'metrics': self.get_metrics()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'unhealthy',\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "# Test production summarizer\n",
    "print(\"Testing production summarizer...\")\n",
    "prod_summarizer = ProductionSummarizer(cache_size=5)\n",
    "\n",
    "# Test requests with caching\n",
    "test_texts = [\n",
    "    \"This is the first test text for summarization.\",\n",
    "    \"This is the second test text with different content.\",\n",
    "    \"This is the first test text for summarization.\",  # Duplicate for cache test\n",
    "    \"Another unique text for testing the summarizer.\"\n",
    "]\n",
    "\n",
    "print(\"\\nProcessing test requests...\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    result = prod_summarizer.summarize_with_monitoring(text, max_length=50, min_length=20)\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        cache_status = \"(cached)\" if result.get('cached') else \"(new)\"\n",
    "        print(f\"Request {i+1}: Success {cache_status} - {result['processing_time']:.3f}s\")\n",
    "        print(f\"  Summary: {result['summary']}\")\n",
    "    else:\n",
    "        print(f\"Request {i+1}: Error - {result['error']}\")\n",
    "\n",
    "# Display metrics\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "metrics = prod_summarizer.get_metrics()\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Health check\n",
    "print(f\"\\nHealth Check:\")\n",
    "health = prod_summarizer.health_check()\n",
    "print(f\"Status: {health['status']}\")\n",
    "if 'error' in health:\n",
    "    print(f\"Error: {health['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this comprehensive notebook, we explored text summarization from multiple angles:\n",
    "\n",
    "### 🎯 **What We Accomplished**\n",
    "1. **Model Comparison**: Tested different pre-trained summarization models\n",
    "2. **Data Pipeline**: Loaded and analyzed summarization datasets\n",
    "3. **Custom Pipeline**: Built flexible summarization pipeline with preprocessing\n",
    "4. **Evaluation Metrics**: Implemented ROUGE and custom evaluation methods\n",
    "5. **Advanced Techniques**: Explored extractive vs abstractive approaches\n",
    "6. **Domain Adaptation**: Customized summarization for different domains\n",
    "7. **Visualization**: Created comprehensive analysis and visualizations\n",
    "8. **Production System**: Built production-ready service with caching and monitoring\n",
    "\n",
    "### 🔑 **Key Concepts Mastered**\n",
    "- **Abstractive vs Extractive**: Understanding different summarization approaches\n",
    "- **Model Selection**: Choosing appropriate models for different use cases\n",
    "- **Parameter Tuning**: Optimizing length, beam search, and other parameters\n",
    "- **Evaluation**: Using ROUGE scores and custom metrics\n",
    "- **Domain Adaptation**: Customizing approaches for different text types\n",
    "- **Production Deployment**: Caching, monitoring, and error handling\n",
    "\n",
    "### 📊 **Best Practices Learned**\n",
    "- **Preprocessing**: Clean and truncate text appropriately\n",
    "- **Parameter Selection**: Choose max/min length based on use case\n",
    "- **Evaluation**: Use multiple metrics to assess quality\n",
    "- **Caching**: Implement caching for production efficiency\n",
    "- **Monitoring**: Track performance and error rates\n",
    "- **Error Handling**: Graceful fallbacks and error recovery\n",
    "\n",
    "### 🚀 **Next Steps**\n",
    "- **Notebook 08**: Question Answering systems\n",
    "- **Notebook 09**: Advanced techniques (LoRA, QLoRA)\n",
    "- **Notebook 10**: Large Language Models and RLHF\n",
    "\n",
    "### 💡 **Key Takeaways**\n",
    "- Different models excel at different types of content\n",
    "- Parameter tuning significantly affects summary quality\n",
    "- Production systems need robust error handling and monitoring\n",
    "- Evaluation is crucial for measuring and improving performance\n",
    "- Domain-specific customization can significantly improve results\n",
    "\n",
    "Text summarization is a powerful application that combines multiple NLP techniques. You now have the foundation to build sophisticated summarization systems for any domain or use case!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
