{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/hf-transformer-trove/blob/main/examples/08_question_answering.ipynb)\n",
    "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/hf-transformer-trove/blob/main/examples/08_question_answering.ipynb)\n",
    "\n",
    "# 08 - Question Answering Model: From Context to Answers\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- Question answering concepts and architectures\n",
    "- Extractive vs generative QA approaches\n",
    "- Using pre-trained QA models with HuggingFace\n",
    "- Fine-tuning QA models on custom datasets\n",
    "- Evaluation metrics for QA systems\n",
    "- Building production-ready QA applications\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with Python and PyTorch\n",
    "- Knowledge of transformers (refer to [Notebook 01](01_intro_hf_transformers.ipynb))\n",
    "- Understanding of tokenization (refer to [Notebook 02](02_tokenizers.ipynb))\n",
    "\n",
    "## üìö What We'll Cover\n",
    "1. **Introduction**: QA concepts and model architectures\n",
    "2. **Pipeline Usage**: High-level QA with pipelines\n",
    "3. **Manual Implementation**: Low-level QA model usage\n",
    "4. **Dataset Processing**: Working with SQuAD and custom QA data\n",
    "5. **Model Comparison**: Different QA architectures\n",
    "6. **Fine-tuning**: Custom QA model training\n",
    "7. **Evaluation**: QA metrics and benchmarking\n",
    "8. **Production System**: Building robust QA applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Question Answering\n",
    "\n",
    "Question Answering (QA) is the task of automatically answering questions posed in natural language. Given a context (passage of text) and a question, the model extracts or generates an appropriate answer.\n",
    "\n",
    "### Types of Question Answering:\n",
    "- **Extractive QA**: Extracts answer spans directly from the given context\n",
    "- **Generative QA**: Generates answers that may not appear verbatim in the context\n",
    "- **Open-domain QA**: Answers questions without a specific context\n",
    "- **Closed-domain QA**: Answers questions within a specific domain or context\n",
    "\n",
    "### Popular QA Datasets:\n",
    "- **SQuAD (Stanford Question Answering Dataset)**: Reading comprehension dataset\n",
    "- **Natural Questions**: Real questions from Google search\n",
    "- **MS MARCO**: Large-scale reading comprehension dataset\n",
    "- **QuAC**: Question Answering in Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForQuestionAnswering,\n",
    "    pipeline, Trainer, TrainingArguments,\n",
    "    DefaultDataCollator\n",
    ")\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device detection with educational output\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Automatically detect and return the best available device.\n",
    "    \n",
    "    Priority: CUDA > MPS (Apple Silicon) > CPU\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for current hardware\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"üöÄ Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\") \n",
    "        print(\"üçé Using Apple MPS (Apple Silicon)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"üíª Using CPU (consider GPU for better performance)\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Set up device\n",
    "device = get_device()\n",
    "\n",
    "print(\"\\nüìö Libraries loaded successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Question Answering with Pipelines\n",
    "\n",
    "Let's start with the simplest approach: using HuggingFace pipelines for question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a question-answering pipeline\n",
    "print(\"üîß Loading question-answering pipeline...\")\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"distilbert-base-cased-distilled-squad\",  # Efficient model fine-tuned on SQuAD\n",
    "    device=0 if device.type == \"cuda\" else -1  # Use GPU if available\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pipeline loaded successfully!\")\n",
    "\n",
    "# Example context about machine learning\n",
    "context = \"\"\"\n",
    "Machine learning is a method of data analysis that automates analytical model building. \n",
    "It is a branch of artificial intelligence (AI) based on the idea that systems can learn \n",
    "from data, identify patterns and make decisions with minimal human intervention. \n",
    "The process typically involves training algorithms on large datasets to create models \n",
    "that can make predictions or decisions on new, unseen data. Popular machine learning \n",
    "techniques include supervised learning, unsupervised learning, and reinforcement learning.\n",
    "\"\"\"\n",
    "\n",
    "# Test questions\n",
    "questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"What does ML automate?\",\n",
    "    \"What are three types of machine learning?\",\n",
    "    \"How do systems learn in machine learning?\",\n",
    "    \"What is machine learning based on?\"\n",
    "]\n",
    "\n",
    "print(\"\\nüéØ Testing Question Answering:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\n‚ùì Question {i}: {question}\")\n",
    "    \n",
    "    # Get answer from pipeline\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    \n",
    "    print(f\"üí° Answer: {result['answer']}\")\n",
    "    print(f\"üéØ Confidence: {result['score']:.4f}\")\n",
    "    print(f\"üìç Position: {result['start']}-{result['end']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this comprehensive notebook, we explored question answering from multiple perspectives:\n",
    "\n",
    "### üéØ **What We Accomplished**\n",
    "1. **QA Fundamentals**: Understanding extractive vs generative approaches\n",
    "2. **Pipeline Usage**: High-level QA with HuggingFace pipelines\n",
    "3. **Manual Implementation**: Low-level model usage and tokenization\n",
    "4. **Dataset Integration**: Working with SQuAD and custom QA data\n",
    "5. **Advanced Techniques**: Confidence thresholding and multi-context QA\n",
    "6. **Evaluation Metrics**: Implementing EM and F1 scores\n",
    "7. **Production System**: Building robust, scalable QA applications\n",
    "\n",
    "### üîë **Key Concepts Mastered**\n",
    "- **Extractive QA**: Models find answer spans within given context\n",
    "- **Confidence Scoring**: Using start/end logits to assess answer quality\n",
    "- **Context Processing**: Preprocessing techniques for better performance\n",
    "- **Evaluation**: Standard metrics (Exact Match, F1) for QA assessment\n",
    "- **Production Considerations**: Error handling, statistics, batch processing\n",
    "\n",
    "### üìà **Best Practices Learned**\n",
    "- **Model Selection**: Choose appropriate models for your use case (speed vs accuracy)\n",
    "- **Confidence Thresholding**: Reject low-confidence answers to maintain quality\n",
    "- **Input Preprocessing**: Clean and normalize text for consistent results\n",
    "- **Comprehensive Evaluation**: Use multiple metrics to assess performance\n",
    "- **Error Handling**: Graceful failure handling in production systems\n",
    "- **Monitoring**: Track system performance and usage statistics\n",
    "\n",
    "### üöÄ **Next Steps**\n",
    "- **Notebook 09**: Advanced fine-tuning with LoRA and QLoRA\n",
    "- **Notebook 10**: LLMs and Reinforcement Learning from Human Feedback\n",
    "- **Documentation**: [Question Answering Best Practices](../docs/qa-best-practices.md)\n",
    "- **External Resources**: [HuggingFace QA Guide](https://huggingface.co/transformers/task_summary.html#question-answering)\n",
    "\n",
    "Question answering is a fundamental NLP task that demonstrates the power of transformer models for understanding and extracting information from text. The techniques learned here form the foundation for many real-world applications!\n",
    "\n",
    "---\n",
    "\n",
    "*Ready to continue? Head to **Notebook 09: PEFT LoRA QLoRA** to learn advanced fine-tuning techniques!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## About the Author\n",
    "\n",
    "**Vu Hung Nguyen** - AI Engineer & Researcher\n",
    "\n",
    "Connect with me:\n",
    "- üåê **Website**: [vuhung16au.github.io](https://vuhung16au.github.io/)\n",
    "- üíº **LinkedIn**: [linkedin.com/in/nguyenvuhung](https://www.linkedin.com/in/nguyenvuhung/)\n",
    "- üíª **GitHub**: [github.com/vuhung16au](https://github.com/vuhung16au/)\n",
    "\n",
    "*This notebook is part of the [HF Transformer Trove](https://github.com/vuhung16au/hf-transformer-trove) educational series.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}