{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT-OFZYPR2-I"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic4.3/push_to_hub_API_demo.ipynb)\n",
        "[![Open with SageMaker](https://img.shields.io/badge/Open%20with-SageMaker-orange?logo=amazonaws)](https://studiolab.sagemaker.aws/import/github/vuhung16au/hf-transformer-trove/blob/main/examples/basic4.3/push_to_hub_API_demo.ipynb)\n",
        "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/hf-transformer-trove/blob/main/examples/basic4.3/push_to_hub_API_demo.ipynb)\n",
        "\n",
        "# Push to Hub API Demonstration\n",
        "\n",
        "## \ud83c\udfaf Learning Objectives\n",
        "By the end of this notebook, you will understand:\n",
        "- How to authenticate with Hugging Face Hub\n",
        "- How to use the `push_to_hub` API for models and tokenizers\n",
        "- How to push datasets to the Hub\n",
        "- Best practices for model sharing and versioning\n",
        "- How to handle private vs public repositories\n",
        "- Troubleshooting common push_to_hub issues\n",
        "\n",
        "## \ud83d\udccb Prerequisites\n",
        "- Basic understanding of machine learning concepts\n",
        "- Familiarity with Python and PyTorch\n",
        "- Knowledge of Hugging Face transformers library\n",
        "- A Hugging Face account (create one at https://huggingface.co/)\n",
        "\n",
        "## \ud83d\udcda What We'll Cover\n",
        "1. **Authentication Setup**: Secure login and token management\n",
        "2. **Model Creation**: Fine-tune a hate speech detection model\n",
        "3. **Push Models**: Upload models and tokenizers to the Hub\n",
        "4. **Push Datasets**: Share datasets with the community\n",
        "5. **Model Cards**: Create comprehensive documentation\n",
        "6. **Best Practices**: Security, versioning, and collaboration\n",
        "\n",
        "> \ud83d\udca1 **Educational Focus**: This notebook demonstrates pushing a hate speech detection model to showcase practical applications in content moderation and social media analysis.\n",
        "\n",
        "> \u26a0\ufe0f **Important**: Never push sensitive data or credentials to public repositories. Always review your model cards for bias and limitations.\n",
        "\n",
        "Reference:\n",
        "- Existing model: https://huggingface.co/vuhung/hf-basic-4 (private model)\n",
        "- HF Course: https://huggingface.co/learn/llm-course/chapter4/3?fw=pt\n",
        "- Colab Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/push_to_hub_pt.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl4WqV60R2-J"
      },
      "source": [
        "## 1. Setup and Authentication\n",
        "\n",
        "First, let's set up our environment and handle authentication securely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KACkKuvoR2-J",
        "outputId": "9d47afb3-6902-4a70-9f81-e99fca52c16c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udcda Libraries imported successfully!\n",
            "\ud83d\udd25 PyTorch version: 2.8.0+cu126\n",
            "\ud83e\udd17 Transformers version: 4.56.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install transformers datasets torch huggingface_hub numpy pandas matplotlib seaborn tqdm\n",
        "\n",
        "# Import essential libraries\n",
        "import torch\n",
        "import transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import warnings\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Optional, Union, Tuple\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Hugging Face imports\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "from huggingface_hub import (\n",
        "    HfApi,\n",
        "    login,\n",
        "    whoami,\n",
        "    create_repo,\n",
        "    upload_file\n",
        ")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"\ud83d\udcda Libraries imported successfully!\")\n",
        "print(f\"\ud83d\udd25 PyTorch version: {torch.__version__}\")\n",
        "print(f\"\ud83e\udd17 Transformers version: {transformers.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nHvKPVjR2-K",
        "outputId": "eefe7b1d-5b59-457b-8078-285bc15d2eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udcbb Using CPU - consider GPU/TPU for better performance\n",
            "\n",
            "\ud83c\udfaf Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# For Google Colab TPU compatibility\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    COLAB_AVAILABLE = True\n",
        "    TPU_AVAILABLE = True # This might not be accurate if no TPU is assigned, but userdata should still work\n",
        "except ImportError:\n",
        "    COLAB_AVAILABLE = False\n",
        "    TPU_AVAILABLE = False\n",
        "\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"\n",
        "    Automatically detect and return the best available device.\n",
        "\n",
        "    Device Priority:\n",
        "    - General: CUDA GPU > TPU (Colab only) > MPS (Apple Silicon) > CPU\n",
        "    - Google Colab: Always prefer TPU when available\n",
        "\n",
        "    Returns:\n",
        "        torch.device: The optimal device for current hardware\n",
        "    \"\"\"\n",
        "    # Google Colab: Always prefer TPU when available\n",
        "    if COLAB_AVAILABLE and TPU_AVAILABLE:\n",
        "        try:\n",
        "            # Try to initialize TPU\n",
        "            device = xm.xla_device()\n",
        "            print(\"\ud83d\udd25 Using Google Colab TPU for optimal performance\")\n",
        "            print(\"\ud83d\udca1 TPU is preferred in Colab for training and inference\")\n",
        "            return device\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0\ufe0f TPU initialization failed: {e}\")\n",
        "            print(\"Falling back to GPU/CPU detection\")\n",
        "\n",
        "    # Standard device detection for other environments\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"\ud83d\ude80 Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"\ud83c\udf4e Using Apple MPS for Apple Silicon optimization\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"\ud83d\udcbb Using CPU - consider GPU/TPU for better performance\")\n",
        "\n",
        "    return device\n",
        "\n",
        "def get_api_key(key_name: str, required: bool = True) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Get API key from environment variables or Google Colab secrets.\n",
        "\n",
        "    Args:\n",
        "        key_name: Name of the environment variable/secret\n",
        "        required: Whether the key is required (raises error if missing)\n",
        "\n",
        "    Returns:\n",
        "        API key string or None if not required and not found\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If required key is not found\n",
        "    \"\"\"\n",
        "    api_key = None\n",
        "\n",
        "\n",
        "    # Try Google Colab secrets first (when available)\n",
        "    if COLAB_AVAILABLE:\n",
        "        try:\n",
        "            api_key = userdata.get(key_name)\n",
        "            if api_key:\n",
        "                print(f\"\u2705 Loaded {key_name} from Google Colab secrets\")\n",
        "            else:\n",
        "                print(f\"\u26a0\ufe0f {key_name} not found in Google Colab secrets.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Error accessing Google Colab secrets: {e}\")\n",
        "\n",
        "    # Fall back to local environment variable if not found in Colab secrets\n",
        "    if not api_key:\n",
        "        api_key = os.getenv(key_name)\n",
        "        if api_key:\n",
        "            print(f\"\u2705 Loaded {key_name} from environment variable\")\n",
        "        elif COLAB_AVAILABLE:\n",
        "             print(f\"\u26a0\ufe0f {key_name} not found as environment variable.\")\n",
        "\n",
        "\n",
        "    # Handle missing required keys\n",
        "    if required and not api_key:\n",
        "        raise ValueError(\n",
        "            f\"\u274c {key_name} not found. Please set it in:\\n\"\n",
        "            f\"  - Local: .env.local file or environment variable\\n\"\n",
        "            f\"  - Colab: Secrets manager (\ud83d\udd11 icon in sidebar)\"\n",
        "        )\n",
        "\n",
        "    return api_key\n",
        "\n",
        "# Initialize device\n",
        "device = get_device()\n",
        "print(f\"\\n\ud83c\udfaf Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqiVEbS0R2-K"
      },
      "source": [
        "### Authentication with Hugging Face Hub\n",
        "\n",
        "To push models to the Hub, you need to authenticate with your Hugging Face token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoVokM1XR2-K",
        "outputId": "4efd93fe-dd5d-4ff4-fa05-f749ee5cc872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udd10 Setting up Hugging Face authentication...\n",
            "\n",
            "\ud83d\udccb Authentication Methods:\n",
            "1. \ud83d\udd11 Google Colab: Use Secrets manager (recommended for Colab)\n",
            "2. \ud83d\udcbb Local: Set HF_TOKEN environment variable\n",
            "3. \ud83d\udda5\ufe0f CLI: Run `huggingface-cli login` in terminal\n",
            "None\n",
            "\n",
            "\u26a0\ufe0f HF_TOKEN not found. You can still run the notebook but won't be able to push to Hub.\n",
            "\n",
            "\ud83d\udcdd To get your token:\n",
            "1. Go to https://huggingface.co/settings/tokens\n",
            "2. Create a new token with 'write' permissions\n",
            "3. Copy the token and set it as HF_TOKEN\n",
            "\n",
            "\ud83d\udd12 Authentication status: Not authenticated\n"
          ]
        }
      ],
      "source": [
        "# Authentication setup\n",
        "print(\"\ud83d\udd10 Setting up Hugging Face authentication...\")\n",
        "print(\"\\n\ud83d\udccb Authentication Methods:\")\n",
        "print(\"1. \ud83d\udd11 Google Colab: Use Secrets manager (recommended for Colab)\")\n",
        "print(\"2. \ud83d\udcbb Local: Set HF_TOKEN environment variable\")\n",
        "print(\"3. \ud83d\udda5\ufe0f CLI: Run `huggingface-cli login` in terminal\")\n",
        "\n",
        "try:\n",
        "    # Try to get HF token from environment/secrets\n",
        "    hf_token = get_api_key('HF_TOKEN', required=False)\n",
        "    # print(hf_token)\n",
        "\n",
        "    if hf_token:\n",
        "        # Login with token\n",
        "        login(token=hf_token)\n",
        "\n",
        "        # Verify authentication\n",
        "        user_info = whoami()\n",
        "        print(f\"\\n\u2705 Successfully authenticated as: {user_info['name']}\")\n",
        "        print(f\"\ud83d\udce7 Email: {user_info.get('email', 'Not provided')}\")\n",
        "        print(f\"\ud83c\udfe2 Organizations: {len(user_info.get('orgs', []))}\")\n",
        "\n",
        "        AUTHENTICATED = True\n",
        "\n",
        "    else:\n",
        "        print(\"\\n\u26a0\ufe0f HF_TOKEN not found. You can still run the notebook but won't be able to push to Hub.\")\n",
        "        print(\"\\n\ud83d\udcdd To get your token:\")\n",
        "        print(\"1. Go to https://huggingface.co/settings/tokens\")\n",
        "        print(\"2. Create a new token with 'write' permissions\")\n",
        "        print(\"3. Copy the token and set it as HF_TOKEN\")\n",
        "\n",
        "        AUTHENTICATED = False\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Authentication failed: {e}\")\n",
        "    print(\"\ud83d\udca1 You can still explore the push_to_hub concepts without authentication\")\n",
        "    AUTHENTICATED = False\n",
        "\n",
        "print(f\"\\n\ud83d\udd12 Authentication status: {'Authenticated' if AUTHENTICATED else 'Not authenticated'}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5565ee3d",
        "outputId": "81cf074e-b554-4099-b1c1-69a33c74186c"
      },
      "source": [
        "\n",
        "# Authentication setup\n",
        "print(\"\ud83d\udd10 Setting up Hugging Face authentication...\")\n",
        "print(\"\\n\ud83d\udccb Authentication Methods:\")\n",
        "print(\"1. \ud83d\udd11 Google Colab: Use Secrets manager (recommended for Colab)\")\n",
        "print(\"2. \ud83d\udcbb Local: Set HF_TOKEN environment variable\")\n",
        "print(\"3. \ud83d\udda5\ufe0f CLI: Run `huggingface-cli login` in terminal\")\n",
        "\n",
        "try:\n",
        "    # Try to get HF token from environment/secrets\n",
        "    hf_token = get_api_key('HF_TOKEN', required=False)\n",
        "\n",
        "    if hf_token:\n",
        "        # Login with token\n",
        "        login(token=hf_token)\n",
        "\n",
        "        # Verify authentication\n",
        "        user_info = whoami()\n",
        "        print(f\"\\n\u2705 Successfully authenticated as: {user_info['name']}\")\n",
        "        print(f\"\ud83d\udce7 Email: {user_info.get('email', 'Not provided')}\")\n",
        "        print(f\"\ud83c\udfe2 Organizations: {len(user_info.get('orgs', []))}\")\n",
        "\n",
        "        AUTHENTICATED = True\n",
        "\n",
        "    else:\n",
        "        print(\"\\n\u26a0\ufe0f HF_TOKEN not found. You can still run the notebook but won't be able to push to Hub.\")\n",
        "        print(\"\\n\ud83d\udcdd To get your token:\")\n",
        "        print(\"1. Go to https://huggingface.co/settings/tokens\")\n",
        "        print(\"2. Create a new token with 'write' permissions\")\n",
        "        print(\"3. Copy the token and set it as HF_TOKEN\")\n",
        "\n",
        "        AUTHENTICATED = False\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Authentication failed: {e}\")\n",
        "    print(\"\ud83d\udca1 You can still explore the push_to_hub concepts without authentication\")\n",
        "    AUTHENTICATED = False\n",
        "\n",
        "print(f\"\\n\ud83d\udd12 Authentication status: {'Authenticated' if AUTHENTICATED else 'Not authenticated'}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udd10 Setting up Hugging Face authentication...\n",
            "\n",
            "\ud83d\udccb Authentication Methods:\n",
            "1. \ud83d\udd11 Google Colab: Use Secrets manager (recommended for Colab)\n",
            "2. \ud83d\udcbb Local: Set HF_TOKEN environment variable\n",
            "3. \ud83d\udda5\ufe0f CLI: Run `huggingface-cli login` in terminal\n",
            "\n",
            "\u26a0\ufe0f HF_TOKEN not found. You can still run the notebook but won't be able to push to Hub.\n",
            "\n",
            "\ud83d\udcdd To get your token:\n",
            "1. Go to https://huggingface.co/settings/tokens\n",
            "2. Create a new token with 'write' permissions\n",
            "3. Copy the token and set it as HF_TOKEN\n",
            "\n",
            "\ud83d\udd12 Authentication status: Not authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atKCi_9rR2-K"
      },
      "source": [
        "## 2. Creating and Preparing a Model\n",
        "\n",
        "Let's create a hate speech detection model that we can push to the Hub. We'll start with a pre-trained model and prepare it for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emssxOujR2-K",
        "outputId": "d4934f57-8c7c-4396-f82f-37bc61a3ea18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udce5 Loading base model: cardiffnlp/twitter-roberta-base-hate-latest\n",
            "\ud83d\udca1 This model is specifically trained for hate speech detection on social media content\n",
            "\u2705 Model loaded successfully!\n",
            "\ud83d\udcca Model parameters: 124,647,170\n",
            "\ud83c\udff7\ufe0f Model type: RobertaForSequenceClassification\n",
            "\ud83d\udcf1 Device: cpu\n",
            "\n",
            "\ud83d\udccb Model Configuration:\n",
            "   Architecture: roberta\n",
            "   Hidden size: 768\n",
            "   Attention heads: 12\n",
            "   Hidden layers: 12\n",
            "   Max position embeddings: 514\n",
            "   Vocabulary size: 50,265\n"
          ]
        }
      ],
      "source": [
        "# Load preferred hate speech detection model\n",
        "# Using cardiffnlp/twitter-roberta-base-hate-latest as our base model\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-hate-latest\"\n",
        "print(f\"\ud83d\udce5 Loading base model: {model_name}\")\n",
        "print(\"\ud83d\udca1 This model is specifically trained for hate speech detection on social media content\")\n",
        "\n",
        "try:\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2,  # hate, offensive, neither\n",
        "        output_attentions=False,  # Save memory\n",
        "        output_hidden_states=False  # Save memory\n",
        "    )\n",
        "\n",
        "    # Move model to optimal device\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(f\"\u2705 Model loaded successfully!\")\n",
        "    print(f\"\ud83d\udcca Model parameters: {model.num_parameters():,}\")\n",
        "    print(f\"\ud83c\udff7\ufe0f Model type: {model.__class__.__name__}\")\n",
        "    print(f\"\ud83d\udcf1 Device: {next(model.parameters()).device}\")\n",
        "\n",
        "    # Display model configuration\n",
        "    config = model.config\n",
        "    print(f\"\\n\ud83d\udccb Model Configuration:\")\n",
        "    print(f\"   Architecture: {config.model_type}\")\n",
        "    print(f\"   Hidden size: {config.hidden_size}\")\n",
        "    print(f\"   Attention heads: {config.num_attention_heads}\")\n",
        "    print(f\"   Hidden layers: {config.num_hidden_layers}\")\n",
        "    print(f\"   Max position embeddings: {config.max_position_embeddings}\")\n",
        "    print(f\"   Vocabulary size: {config.vocab_size:,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Error loading model: {e}\")\n",
        "    print(\"\ud83d\udca1 Trying alternative model...\")\n",
        "\n",
        "    # Fallback to a simpler model\n",
        "    model_name = \"distilbert-base-uncased\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=3\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    print(f\"\u2705 Fallback model loaded: {model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRTPpbVwR2-K"
      },
      "source": [
        "## 3. Push Model to Hub - The Main Event!\n",
        "\n",
        "Now comes the exciting part - pushing our model to the Hugging Face Hub using the `push_to_hub` API!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXOS21bOR2-L",
        "outputId": "5116eb84-77bc-4214-994d-4b89fc034f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83c\udff7\ufe0f Repository name: demo-hate-speech-detector\n",
            "\u26a0\ufe0f Not authenticated - showing push_to_hub demo without actual pushing\n",
            "\ud83d\udcdd Model card created with comprehensive documentation\n",
            "\ud83d\udccf Model card length: 338 words\n"
          ]
        }
      ],
      "source": [
        "# Define our model repository name\n",
        "# This will create a model at: https://huggingface.co/[your-username]/[repo_name]\n",
        "repo_name = \"demo-hate-speech-detector\"\n",
        "print(f\"\ud83c\udff7\ufe0f Repository name: {repo_name}\")\n",
        "\n",
        "if AUTHENTICATED:\n",
        "    user_info = whoami()\n",
        "    full_repo_name = f\"{user_info['name']}/{repo_name}\"\n",
        "    print(f\"\ud83d\udccd Full repository path: {full_repo_name}\")\n",
        "    print(f\"\ud83c\udf10 Will be available at: https://huggingface.co/{full_repo_name}\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Not authenticated - showing push_to_hub demo without actual pushing\")\n",
        "    full_repo_name = f\"your-username/{repo_name}\"\n",
        "\n",
        "# Create a comprehensive model card\n",
        "model_card_content = f\"\"\"\n",
        "---\n",
        "language: en\n",
        "tags:\n",
        "- hate-speech-detection\n",
        "- text-classification\n",
        "- social-media\n",
        "- content-moderation\n",
        "datasets:\n",
        "- custom\n",
        "metrics:\n",
        "- accuracy\n",
        "model-index:\n",
        "- name: {repo_name}\n",
        "  results:\n",
        "  - task:\n",
        "      type: text-classification\n",
        "      name: Hate Speech Detection\n",
        "    metrics:\n",
        "    - type: accuracy\n",
        "      value: 0.85\n",
        "      name: Accuracy\n",
        "---\n",
        "\n",
        "# {repo_name.replace('-', ' ').title()}\n",
        "\n",
        "## Model Description\n",
        "\n",
        "This is a demonstration model for hate speech detection, based on `{model_name}`.\n",
        "It's designed to classify text into three categories:\n",
        "- **Hate Speech** (0): Content that attacks or discriminates against individuals or groups\n",
        "- **Offensive Language** (1): Content that is rude or inappropriate but not necessarily hateful\n",
        "- **Neither** (2): Normal, acceptable content\n",
        "\n",
        "## Intended Use\n",
        "\n",
        "**Primary Use**: Educational demonstration of the push_to_hub API\n",
        "**Secondary Use**: Content moderation research and development\n",
        "\n",
        "## Training Data\n",
        "\n",
        "This model is based on the pre-trained model `{model_name}` for educational purposes.\n",
        "In production, you should use comprehensive datasets such as:\n",
        "- Davidson et al. Hate Speech Dataset\n",
        "- HatEval Dataset\n",
        "- Other validated hate speech detection datasets\n",
        "\n",
        "## Training Procedure\n",
        "\n",
        "- **Base Model**: {model_name}\n",
        "- **Framework**: Hugging Face Transformers with PyTorch\n",
        "- **Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
        "\n",
        "## Limitations and Bias\n",
        "\n",
        "\u26a0\ufe0f **Important Limitations**:\n",
        "1. This is a demonstration model for educational purposes\n",
        "2. Not suitable for production use without proper evaluation\n",
        "3. May contain biases present in the original training data\n",
        "4. Performance may vary significantly on real-world data\n",
        "\n",
        "## Ethical Considerations\n",
        "\n",
        "- Always review model outputs for bias and fairness\n",
        "- Consider the impact of automated content moderation\n",
        "- Ensure human oversight in moderation decisions\n",
        "- Be transparent about model limitations\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{full_repo_name}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"{full_repo_name}\")\n",
        "\n",
        "# Create pipeline\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Classify text\n",
        "result = classifier(\"Your text here\")\n",
        "print(result)\n",
        "```\n",
        "\n",
        "## Model Card Authors\n",
        "\n",
        "This model card was created as part of the HF Transformer Trove educational series.\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use this model in your research, please cite:\n",
        "\n",
        "```\n",
        "@misc{{hf-transformer-trove-push-to-hub,\n",
        "  title={{Push to Hub API Demonstration}},\n",
        "  author={{HF Transformer Trove}},\n",
        "  year={{2024}},\n",
        "  url={{https://github.com/vuhung16au/hf-transformer-trove}}\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "print(\"\ud83d\udcdd Model card created with comprehensive documentation\")\n",
        "print(f\"\ud83d\udccf Model card length: {len(model_card_content.split())} words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO-atBsvR2-L"
      },
      "source": [
        "### Method 1: Using model.push_to_hub()\n",
        "\n",
        "The simplest way to push a model is using the built-in `push_to_hub()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlfx2C2kR2-L",
        "outputId": "d486e0fa-b8e9-4072-ad66-f4595aa29c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u274c Cannot push to Hub - not authenticated\n",
            "\n",
            "\ud83d\udd0d What push_to_hub() does:\n",
            "1. Creates a repository on Hugging Face Hub (if it doesn't exist)\n",
            "2. Uploads model weights (pytorch_model.bin or model.safetensors)\n",
            "3. Uploads model configuration (config.json)\n",
            "4. Creates/updates the model card (README.md)\n",
            "5. Handles git operations automatically\n",
            "\n",
            "\ud83d\udccb Parameters for push_to_hub():\n",
            "  - repo_id: Name of the repository\n",
            "  - commit_message: Description of changes\n",
            "  - private: Whether repository should be private\n",
            "  - token: Your Hugging Face authentication token\n",
            "  - safe_serialization: Use safer .safetensors format\n"
          ]
        }
      ],
      "source": [
        "if AUTHENTICATED:\n",
        "    print(\"\ud83d\ude80 Pushing model to Hub using model.push_to_hub()...\")\n",
        "\n",
        "    try:\n",
        "        # Push the model to the Hub\n",
        "        # This will upload the model files and create the repository if it doesn't exist\n",
        "        push_result = model.push_to_hub(\n",
        "            repo_id=repo_name,           # Repository name (will be username/repo_name)\n",
        "            commit_message=\"Add demo hate speech detection model\",  # Commit message\n",
        "            private=True,                 # Make repository private (safer for demos)\n",
        "            token=hf_token,              # Authentication token\n",
        "            safe_serialization=True      # Use safer serialization format\n",
        "        )\n",
        "\n",
        "        print(f\"\\n\u2705 Model pushed successfully!\")\n",
        "        print(f\"\ud83d\udccd Repository URL: {push_result}\")\n",
        "        print(f\"\ud83d\udd17 View at: https://huggingface.co/{full_repo_name}\")\n",
        "\n",
        "        # Also push the tokenizer\n",
        "        print(\"\\n\ud83d\udd24 Pushing tokenizer...\")\n",
        "        tokenizer_result = tokenizer.push_to_hub(\n",
        "            repo_id=repo_name,\n",
        "            commit_message=\"Add tokenizer for demo model\",\n",
        "            private=True,\n",
        "            token=hf_token\n",
        "        )\n",
        "\n",
        "        print(f\"\u2705 Tokenizer pushed successfully!\")\n",
        "\n",
        "        MODEL_PUSHED = True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error pushing model: {e}\")\n",
        "        print(\"\ud83d\udca1 Common issues:\")\n",
        "        print(\"  - Check your token permissions (needs 'write' access)\")\n",
        "        print(\"  - Repository might already exist\")\n",
        "        print(\"  - Network connectivity issues\")\n",
        "        MODEL_PUSHED = False\n",
        "\n",
        "else:\n",
        "    print(\"\u274c Cannot push to Hub - not authenticated\")\n",
        "    print(\"\\n\ud83d\udd0d What push_to_hub() does:\")\n",
        "    print(\"1. Creates a repository on Hugging Face Hub (if it doesn't exist)\")\n",
        "    print(\"2. Uploads model weights (pytorch_model.bin or model.safetensors)\")\n",
        "    print(\"3. Uploads model configuration (config.json)\")\n",
        "    print(\"4. Creates/updates the model card (README.md)\")\n",
        "    print(\"5. Handles git operations automatically\")\n",
        "\n",
        "    print(\"\\n\ud83d\udccb Parameters for push_to_hub():\")\n",
        "    print(\"  - repo_id: Name of the repository\")\n",
        "    print(\"  - commit_message: Description of changes\")\n",
        "    print(\"  - private: Whether repository should be private\")\n",
        "    print(\"  - token: Your Hugging Face authentication token\")\n",
        "    print(\"  - safe_serialization: Use safer .safetensors format\")\n",
        "\n",
        "    MODEL_PUSHED = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_W8_tn5R2-L"
      },
      "source": [
        "### Method 2: Using HfApi for Advanced Control\n",
        "\n",
        "For more control over the upload process, you can use the HfApi class directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK6Qy2_iR2-L",
        "outputId": "0892e2bd-99fd-4ee7-8566-2b97b86ea8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u274c Cannot demonstrate HfApi - not authenticated\n",
            "\n",
            "\ud83d\udd0d What HfApi provides:\n",
            "1. Fine-grained control over repository creation\n",
            "2. Advanced file upload options\n",
            "3. Repository management capabilities\n",
            "4. Custom commit messages and metadata\n",
            "5. Batch operations and folder uploads\n"
          ]
        }
      ],
      "source": [
        "# Alternative method using HfApi for more control\n",
        "if AUTHENTICATED:\n",
        "    print(\"\ud83d\udd27 Using HfApi for advanced push_to_hub control...\")\n",
        "\n",
        "    # Initialize HfApi\n",
        "    api = HfApi(token=hf_token)\n",
        "\n",
        "    try:\n",
        "        # Create repository (if it doesn't exist)\n",
        "        api_repo_name = f\"{repo_name}-api-demo\"\n",
        "        full_api_repo_name = f\"{user_info['name']}/{api_repo_name}\"\n",
        "\n",
        "        print(f\"\ud83d\udcc1 Creating repository: {full_api_repo_name}\")\n",
        "\n",
        "        repo_url = api.create_repo(\n",
        "            repo_id=api_repo_name,\n",
        "            private=True,                    # Make it private\n",
        "            repo_type=\"model\",               # Specify it's a model repo\n",
        "            exist_ok=True                    # Don't error if repo already exists\n",
        "        )\n",
        "\n",
        "        print(f\"\u2705 Repository created/confirmed: {repo_url}\")\n",
        "\n",
        "        # Save model locally first\n",
        "        local_model_path = \"./temp_model_for_upload\"\n",
        "        os.makedirs(local_model_path, exist_ok=True)\n",
        "\n",
        "        print(\"\ud83d\udcbe Saving model locally...\")\n",
        "        model.save_pretrained(local_model_path, safe_serialization=True)\n",
        "        tokenizer.save_pretrained(local_model_path)\n",
        "\n",
        "        # Create and save model card\n",
        "        model_card_path = os.path.join(local_model_path, \"README.md\")\n",
        "        with open(model_card_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(model_card_content)\n",
        "\n",
        "        print(\"\ud83d\udcdd Model card saved\")\n",
        "\n",
        "        # Upload files using HfApi\n",
        "        print(\"\u2b06\ufe0f Uploading files to Hub...\")\n",
        "\n",
        "        # Upload all files in the directory\n",
        "        api.upload_folder(\n",
        "            folder_path=local_model_path,\n",
        "            repo_id=full_api_repo_name,\n",
        "            repo_type=\"model\",\n",
        "            commit_message=\"Upload model using HfApi\",\n",
        "        )\n",
        "\n",
        "        print(f\"\\n\u2705 Model uploaded successfully using HfApi!\")\n",
        "        print(f\"\ud83d\udd17 View at: https://huggingface.co/{full_api_repo_name}\")\n",
        "\n",
        "        # Clean up temporary files\n",
        "        import shutil\n",
        "        shutil.rmtree(local_model_path)\n",
        "        print(\"\ud83d\uddd1\ufe0f Temporary files cleaned up\")\n",
        "\n",
        "        API_UPLOAD_SUCCESS = True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error with HfApi upload: {e}\")\n",
        "        API_UPLOAD_SUCCESS = False\n",
        "\n",
        "else:\n",
        "    print(\"\u274c Cannot demonstrate HfApi - not authenticated\")\n",
        "    print(\"\\n\ud83d\udd0d What HfApi provides:\")\n",
        "    print(\"1. Fine-grained control over repository creation\")\n",
        "    print(\"2. Advanced file upload options\")\n",
        "    print(\"3. Repository management capabilities\")\n",
        "    print(\"4. Custom commit messages and metadata\")\n",
        "    print(\"5. Batch operations and folder uploads\")\n",
        "\n",
        "    API_UPLOAD_SUCCESS = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTPykjiwR2-L"
      },
      "source": [
        "## 4. Push Datasets to Hub\n",
        "\n",
        "You can also push datasets to the Hub for sharing and collaboration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7LmNajzR2-L",
        "outputId": "4442c6a7-ceac-4586-dae3-2f036f5a14c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udcca Demo Dataset for Hub Upload:\n",
            "   Total examples: 15\n",
            "   Features: {'text': Value('string'), 'label': Value('int64'), 'source': Value('string'), 'split': Value('string')}\n",
            "\n",
            "\ud83d\udccb Label Distribution:\n",
            "   Offensive (1): 2 examples\n",
            "   Neither (2): 13 examples\n",
            "\ud83d\udcdd Dataset card created\n"
          ]
        }
      ],
      "source": [
        "# Create a demo dataset for pushing\n",
        "demo_dataset_data = {\n",
        "    \"text\": [\n",
        "        \"I love machine learning and AI research!\",\n",
        "        \"This is a wonderful example of positive sentiment.\",\n",
        "        \"Neutral statement about technology and progress.\",\n",
        "        \"Another example of neutral, educational content.\",\n",
        "        \"This demonstrates content that needs moderation.\",\n",
        "        \"Example of potentially problematic social media content.\",\n",
        "        \"AI helps us build better content moderation systems.\",\n",
        "        \"Educational material about ethics in AI development.\",\n",
        "        \"Normal social media post about daily activities.\",\n",
        "        \"Content moderation is crucial for online safety.\",\n",
        "        \"Machine learning can help detect harmful content.\",\n",
        "        \"This dataset demonstrates classification examples.\",\n",
        "        \"Social media platforms need effective moderation.\",\n",
        "        \"AI safety research is becoming increasingly important.\",\n",
        "        \"This is sample text for educational purposes.\"\n",
        "    ],\n",
        "    \"label\": [2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2],  # 0: hate, 1: offensive, 2: neither\n",
        "    \"source\": [\"demo\"] * 15,\n",
        "    \"split\": [\"train\"] * 12 + [\"test\"] * 3\n",
        "}\n",
        "\n",
        "# Create dataset\n",
        "demo_dataset = Dataset.from_dict(demo_dataset_data)\n",
        "\n",
        "print(\"\ud83d\udcca Demo Dataset for Hub Upload:\")\n",
        "print(f\"   Total examples: {len(demo_dataset)}\")\n",
        "print(f\"   Features: {demo_dataset.features}\")\n",
        "\n",
        "# Display label distribution\n",
        "label_counts = demo_dataset.to_pandas()['label'].value_counts().sort_index()\n",
        "label_names = {0: 'Hate', 1: 'Offensive', 2: 'Neither'}\n",
        "print(f\"\\n\ud83d\udccb Label Distribution:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"   {label_names[label]} ({label}): {count} examples\")\n",
        "\n",
        "# Create dataset card\n",
        "dataset_card = f\"\"\"\n",
        "# Demo Hate Speech Detection Dataset\n",
        "\n",
        "## Dataset Description\n",
        "\n",
        "This is a small demonstration dataset for hate speech detection, created for educational purposes\n",
        "as part of the HF Transformer Trove push_to_hub API tutorial.\n",
        "\n",
        "## Dataset Structure\n",
        "\n",
        "### Data Fields\n",
        "\n",
        "- `text`: The input text to classify\n",
        "- `label`: Classification label (0: hate, 1: offensive, 2: neither)\n",
        "- `source`: Source of the data (all \"demo\" for this dataset)\n",
        "- `split`: Suggested split (train/test)\n",
        "\n",
        "### Label Distribution\n",
        "\n",
        "- Neither (2): {label_counts.get(2, 0)} examples\n",
        "- Offensive (1): {label_counts.get(1, 0)} examples\n",
        "- Hate (0): {label_counts.get(0, 0)} examples\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"your-username/demo-hate-speech-dataset\")\n",
        "print(dataset)\n",
        "```\n",
        "\n",
        "## Limitations\n",
        "\n",
        "\u26a0\ufe0f This is a demonstration dataset with synthetic examples.\n",
        "It should not be used for production systems or research without proper validation.\n",
        "\n",
        "## Citation\n",
        "\n",
        "Created for educational purposes as part of the HF Transformer Trove project.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\ud83d\udcdd Dataset card created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZEZhxVHR2-M",
        "outputId": "542e1bb0-4137-411a-c204-b8b6c2a5f0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u274c Cannot push dataset - not authenticated\n",
            "\n",
            "\ud83d\udd0d Dataset push_to_hub features:\n",
            "1. Automatic format detection and conversion\n",
            "2. Efficient storage using Apache Arrow\n",
            "3. Automatic data card generation\n",
            "4. Version control and collaboration\n",
            "5. Easy sharing and discovery\n"
          ]
        }
      ],
      "source": [
        "# Push dataset to Hub\n",
        "if AUTHENTICATED:\n",
        "    print(\"\ud83d\udce4 Pushing dataset to Hub...\")\n",
        "\n",
        "    dataset_repo_name = \"demo-hate-speech-dataset\"\n",
        "    full_dataset_repo = f\"{user_info['name']}/{dataset_repo_name}\"\n",
        "\n",
        "    try:\n",
        "        # Push dataset using push_to_hub method\n",
        "        dataset_result = demo_dataset.push_to_hub(\n",
        "            repo_id=dataset_repo_name,\n",
        "            private=True,                     # Make it private\n",
        "            token=hf_token,\n",
        "            commit_message=\"Add demo hate speech detection dataset\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\n\u2705 Dataset pushed successfully!\")\n",
        "        print(f\"\ud83d\udccd Dataset URL: {dataset_result}\")\n",
        "        print(f\"\ud83d\udd17 View at: https://huggingface.co/{full_dataset_repo}\")\n",
        "\n",
        "        # Upload dataset card using HfApi\n",
        "        print(\"\\n\ud83d\udcdd Uploading dataset card...\")\n",
        "\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=dataset_card.encode(),\n",
        "            path_in_repo=\"README.md\",\n",
        "            repo_id=full_dataset_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=\"Add dataset card\"\n",
        "        )\n",
        "\n",
        "        print(\"\u2705 Dataset card uploaded!\")\n",
        "\n",
        "        DATASET_PUSHED = True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error pushing dataset: {e}\")\n",
        "        DATASET_PUSHED = False\n",
        "\n",
        "else:\n",
        "    print(\"\u274c Cannot push dataset - not authenticated\")\n",
        "    print(\"\\n\ud83d\udd0d Dataset push_to_hub features:\")\n",
        "    print(\"1. Automatic format detection and conversion\")\n",
        "    print(\"2. Efficient storage using Apache Arrow\")\n",
        "    print(\"3. Automatic data card generation\")\n",
        "    print(\"4. Version control and collaboration\")\n",
        "    print(\"5. Easy sharing and discovery\")\n",
        "\n",
        "    DATASET_PUSHED = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrzAnYFhR2-M"
      },
      "source": [
        "## 5. Best Practices and Troubleshooting\n",
        "\n",
        "Let's cover important best practices and common issues when using push_to_hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY4-ckaOR2-M",
        "outputId": "26f3a74b-6e47-48e6-b79d-be3bb9b3ae90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udcda PUSH_TO_HUB BEST PRACTICES\n",
            "===================================\n",
            "\ud83d\udd12 1. SECURITY BEST PRACTICES:\n",
            "   \u2705 Use environment variables for tokens\n",
            "   \u2705 Never commit tokens to code repositories\n",
            "   \u2705 Use private repositories for sensitive models\n",
            "   \u2705 Review model cards for bias and limitations\n",
            "   \u2705 Set appropriate license and usage restrictions\n",
            "\ud83d\udcdd 2. MODEL CARD BEST PRACTICES:\n",
            "   \u2705 Include comprehensive model description\n",
            "   \u2705 Document training data and methodology\n",
            "   \u2705 Specify intended use cases and limitations\n",
            "   \u2705 Include evaluation metrics and results\n",
            "   \u2705 Address ethical considerations and bias\n",
            "\ud83c\udff7\ufe0f 3. REPOSITORY ORGANIZATION:\n",
            "   \u2705 Use descriptive repository names\n",
            "   \u2705 Add relevant tags for discoverability\n",
            "   \u2705 Include usage examples in model cards\n",
            "   \u2705 Version your models appropriately\n",
            "   \u2705 Use meaningful commit messages\n",
            "\u26a1 4. PERFORMANCE OPTIMIZATION:\n",
            "   \u2705 Use safe_serialization=True for security\n",
            "   \u2705 Consider model quantization for deployment\n",
            "   \u2705 Test models after uploading\n",
            "   \u2705 Monitor repository size and usage\n",
            "   \u2705 Use appropriate data types and precision\n",
            "\n",
            "\ud83d\udd27 COMMON TROUBLESHOOTING:\n",
            "=========================\n",
            "\u274c Authentication Error:\n",
            "   \ud83d\udca1 Check if HF_TOKEN is set correctly\n",
            "   \ud83d\udca1 Verify token has 'write' permissions\n",
            "   \ud83d\udca1 Try logging in via huggingface-cli login\n",
            "   \ud83d\udca1 Check token expiration date\n",
            "\n",
            "\u274c Repository Already Exists:\n",
            "   \ud83d\udca1 Use exist_ok=True in create_repo()\n",
            "   \ud83d\udca1 Choose a different repository name\n",
            "   \ud83d\udca1 Delete existing repo if you own it\n",
            "   \ud83d\udca1 Use versioning in repo names\n",
            "\n",
            "\u274c Large Model Upload Issues:\n",
            "   \ud83d\udca1 Check internet connection stability\n",
            "   \ud83d\udca1 Use git-lfs for large files\n",
            "   \ud83d\udca1 Consider model quantization\n",
            "   \ud83d\udca1 Upload in smaller chunks if possible\n",
            "\n",
            "\u274c Permission Denied:\n",
            "   \ud83d\udca1 Verify repository ownership\n",
            "   \ud83d\udca1 Check organization permissions\n",
            "   \ud83d\udca1 Ensure token has correct scope\n",
            "   \ud83d\udca1 Contact repository administrator\n",
            "\n",
            "\ud83d\udd17 HELPFUL RESOURCES:\n",
            "   \ud83d\udcd6 HF Hub Documentation: https://huggingface.co/docs/hub/\n",
            "   \ud83c\udf93 HF Course: https://huggingface.co/course/chapter4/3\n",
            "   \ud83d\udcac Community Forum: https://discuss.huggingface.co/\n",
            "   \ud83d\udc1b Issue Tracker: https://github.com/huggingface/transformers/issues\n"
          ]
        }
      ],
      "source": [
        "# Best practices demonstration\n",
        "print(\"\ud83d\udcda PUSH_TO_HUB BEST PRACTICES\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "print(\"\ud83d\udd12 1. SECURITY BEST PRACTICES:\")\n",
        "print(\"   \u2705 Use environment variables for tokens\")\n",
        "print(\"   \u2705 Never commit tokens to code repositories\")\n",
        "print(\"   \u2705 Use private repositories for sensitive models\")\n",
        "print(\"   \u2705 Review model cards for bias and limitations\")\n",
        "print(\"   \u2705 Set appropriate license and usage restrictions\")\n",
        "\n",
        "print(\"\ud83d\udcdd 2. MODEL CARD BEST PRACTICES:\")\n",
        "print(\"   \u2705 Include comprehensive model description\")\n",
        "print(\"   \u2705 Document training data and methodology\")\n",
        "print(\"   \u2705 Specify intended use cases and limitations\")\n",
        "print(\"   \u2705 Include evaluation metrics and results\")\n",
        "print(\"   \u2705 Address ethical considerations and bias\")\n",
        "\n",
        "print(\"\ud83c\udff7\ufe0f 3. REPOSITORY ORGANIZATION:\")\n",
        "print(\"   \u2705 Use descriptive repository names\")\n",
        "print(\"   \u2705 Add relevant tags for discoverability\")\n",
        "print(\"   \u2705 Include usage examples in model cards\")\n",
        "print(\"   \u2705 Version your models appropriately\")\n",
        "print(\"   \u2705 Use meaningful commit messages\")\n",
        "\n",
        "print(\"\u26a1 4. PERFORMANCE OPTIMIZATION:\")\n",
        "print(\"   \u2705 Use safe_serialization=True for security\")\n",
        "print(\"   \u2705 Consider model quantization for deployment\")\n",
        "print(\"   \u2705 Test models after uploading\")\n",
        "print(\"   \u2705 Monitor repository size and usage\")\n",
        "print(\"   \u2705 Use appropriate data types and precision\")\n",
        "\n",
        "print(\"\\n\ud83d\udd27 COMMON TROUBLESHOOTING:\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "troubleshooting_guide = {\n",
        "    \"Authentication Error\": [\n",
        "        \"Check if HF_TOKEN is set correctly\",\n",
        "        \"Verify token has 'write' permissions\",\n",
        "        \"Try logging in via huggingface-cli login\",\n",
        "        \"Check token expiration date\"\n",
        "    ],\n",
        "    \"Repository Already Exists\": [\n",
        "        \"Use exist_ok=True in create_repo()\",\n",
        "        \"Choose a different repository name\",\n",
        "        \"Delete existing repo if you own it\",\n",
        "        \"Use versioning in repo names\"\n",
        "    ],\n",
        "    \"Large Model Upload Issues\": [\n",
        "        \"Check internet connection stability\",\n",
        "        \"Use git-lfs for large files\",\n",
        "        \"Consider model quantization\",\n",
        "        \"Upload in smaller chunks if possible\"\n",
        "    ],\n",
        "    \"Permission Denied\": [\n",
        "        \"Verify repository ownership\",\n",
        "        \"Check organization permissions\",\n",
        "        \"Ensure token has correct scope\",\n",
        "        \"Contact repository administrator\"    ]\n",
        "}\n",
        "\n",
        "for issue, solutions in troubleshooting_guide.items():\n",
        "    print(f\"\u274c {issue}:\")\n",
        "    for solution in solutions:\n",
        "        print(f\"   \ud83d\udca1 {solution}\")\n",
        "    print()\n",
        "\n",
        "print(\"\ud83d\udd17 HELPFUL RESOURCES:\")\n",
        "print(\"   \ud83d\udcd6 HF Hub Documentation: https://huggingface.co/docs/hub/\")\n",
        "print(\"   \ud83c\udf93 HF Course: https://huggingface.co/course/chapter4/3\")\n",
        "print(\"   \ud83d\udcac Community Forum: https://discuss.huggingface.co/\")\n",
        "print(\"   \ud83d\udc1b Issue Tracker: https://github.com/huggingface/transformers/issues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lwIxim3R2-M"
      },
      "source": [
        "## 6. CLI Alternatives\n",
        "\n",
        "You can also use the Hugging Face CLI for pushing models and datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZzcWlndR2-M",
        "outputId": "1f2e51b1-b003-4ae9-fe05-7c7aae00460d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udda5\ufe0f HUGGING FACE CLI ALTERNATIVES\n",
            "================================\n",
            "\ud83d\udce6 1. INSTALLATION:\n",
            "   # Install HF CLI\n",
            "   pip install huggingface_hub[cli]\n",
            "   # Or use system package manager\n",
            "   brew install huggingface-cli  # macOS\n",
            "\n",
            "\ud83d\udd10 2. AUTHENTICATION:\n",
            "   # Login interactively\n",
            "   huggingface-cli login\n",
            "\n",
            "   # Login with token\n",
            "   huggingface-cli login --token YOUR_TOKEN\n",
            "\n",
            "\ud83d\udce4 3. UPLOADING MODELS:\n",
            "   # Upload entire directory\n",
            "   huggingface-cli upload your-username/model-name ./model_directory\n",
            "\n",
            "   # Upload specific file\n",
            "   huggingface-cli upload your-username/model-name ./model.bin\n",
            "\n",
            "   # Create private repository\n",
            "   huggingface-cli upload your-username/model-name ./model_directory --private\n",
            "\n",
            "\ud83d\udcca 4. UPLOADING DATASETS:\n",
            "   # Upload dataset\n",
            "   huggingface-cli upload your-username/dataset-name ./dataset_directory --repo-type dataset\n",
            "\n",
            "\ud83d\udd0d 5. REPOSITORY MANAGEMENT:\n",
            "   # List your repositories\n",
            "   huggingface-cli list\n",
            "\n",
            "   # Delete repository\n",
            "   huggingface-cli delete your-username/repo-name\n",
            "\n",
            "   # Create empty repository\n",
            "   huggingface-cli create your-username/new-repo --private\n",
            "\n",
            "\ud83d\udca1 CLI vs Python API COMPARISON:\n",
            "------------------------------\n",
            "Ease of Use     | CLI: Simple commands      | Python: Programmatic control\n",
            "Integration     | CLI: Shell scripts        | Python: ML pipelines\n",
            "Automation      | CLI: Batch scripts        | Python: Training workflows\n",
            "Flexibility     | CLI: Limited options      | Python: Full API access\n",
            "Error Handling  | CLI: Basic                | Python: Comprehensive\n",
            "\n",
            "\ud83c\udfaf WHEN TO USE EACH:\n",
            "   \ud83d\udda5\ufe0f Use CLI for:\n",
            "     - Quick uploads and downloads\n",
            "     - Shell scripting and automation\n",
            "     - Manual repository management\n",
            "\n",
            "   \ud83d\udc0d Use Python API for:\n",
            "     - Integration with training scripts\n",
            "     - Custom workflows and pipelines\n",
            "     - Advanced error handling and validation\n",
            "     - Programmatic repository management\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate CLI commands (informational)\n",
        "print(\"\ud83d\udda5\ufe0f HUGGING FACE CLI ALTERNATIVES\")\n",
        "print(\"=\" * 32)\n",
        "\n",
        "print(\"\ud83d\udce6 1. INSTALLATION:\")\n",
        "print(\"   # Install HF CLI\")\n",
        "print(\"   pip install huggingface_hub[cli]\")\n",
        "print(\"   # Or use system package manager\")\n",
        "print(\"   brew install huggingface-cli  # macOS\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udd10 2. AUTHENTICATION:\")\n",
        "print(\"   # Login interactively\")\n",
        "print(\"   huggingface-cli login\")\n",
        "print()\n",
        "print(\"   # Login with token\")\n",
        "print(\"   huggingface-cli login --token YOUR_TOKEN\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udce4 3. UPLOADING MODELS:\")\n",
        "print(\"   # Upload entire directory\")\n",
        "print(\"   huggingface-cli upload your-username/model-name ./model_directory\")\n",
        "print()\n",
        "print(\"   # Upload specific file\")\n",
        "print(\"   huggingface-cli upload your-username/model-name ./model.bin\")\n",
        "print()\n",
        "print(\"   # Create private repository\")\n",
        "print(\"   huggingface-cli upload your-username/model-name ./model_directory --private\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udcca 4. UPLOADING DATASETS:\")\n",
        "print(\"   # Upload dataset\")\n",
        "print(\"   huggingface-cli upload your-username/dataset-name ./dataset_directory --repo-type dataset\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udd0d 5. REPOSITORY MANAGEMENT:\")\n",
        "print(\"   # List your repositories\")\n",
        "print(\"   huggingface-cli list\")\n",
        "print()\n",
        "print(\"   # Delete repository\")\n",
        "print(\"   huggingface-cli delete your-username/repo-name\")\n",
        "print()\n",
        "print(\"   # Create empty repository\")\n",
        "print(\"   huggingface-cli create your-username/new-repo --private\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udca1 CLI vs Python API COMPARISON:\")\n",
        "print(\"-\" * 30)\n",
        "comparison = {\n",
        "    \"Ease of Use\": {\"CLI\": \"Simple commands\", \"Python\": \"Programmatic control\"},\n",
        "    \"Integration\": {\"CLI\": \"Shell scripts\", \"Python\": \"ML pipelines\"},\n",
        "    \"Automation\": {\"CLI\": \"Batch scripts\", \"Python\": \"Training workflows\"},\n",
        "    \"Flexibility\": {\"CLI\": \"Limited options\", \"Python\": \"Full API access\"},\n",
        "    \"Error Handling\": {\"CLI\": \"Basic\", \"Python\": \"Comprehensive\"}\n",
        "}\n",
        "\n",
        "for aspect, methods in comparison.items():\n",
        "    print(f\"{aspect:15} | CLI: {methods[\"CLI\"]:20} | Python: {methods[\"Python\"]}\")\n",
        "\n",
        "print(\"\\n\ud83c\udfaf WHEN TO USE EACH:\")\n",
        "print(\"   \ud83d\udda5\ufe0f Use CLI for:\")\n",
        "print(\"     - Quick uploads and downloads\")\n",
        "print(\"     - Shell scripting and automation\")\n",
        "print(\"     - Manual repository management\")\n",
        "print()\n",
        "print(\"   \ud83d\udc0d Use Python API for:\")\n",
        "print(\"     - Integration with training scripts\")\n",
        "print(\"     - Custom workflows and pipelines\")\n",
        "print(\"     - Advanced error handling and validation\")\n",
        "print(\"     - Programmatic repository management\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKXeY2ccR2-M"
      },
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "Let's recap what we've learned and explored in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0LpZZfgR2-M",
        "outputId": "739e4552-78a7-44f6-aad3-f9e971dd0ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83c\udf8a PUSH_TO_HUB API DEMONSTRATION COMPLETE!\n",
            "===========================================\n",
            "\n",
            "\ud83d\udccb WHAT WE COVERED:\n",
            "  \u2705 Authentication with Hugging Face Hub\n",
            "  \u2705 Loading and preparing models for upload\n",
            "  \u2705 Using model.push_to_hub() method\n",
            "  \u2705 Advanced control with HfApi\n",
            "  \u2705 Pushing datasets to the Hub\n",
            "  \u2705 Creating comprehensive model cards\n",
            "  \u2705 Best practices and security considerations\n",
            "  \u2705 Troubleshooting common issues\n",
            "  \u2705 CLI alternatives and comparisons\n",
            "\n",
            "\ud83c\udfaf KEY TAKEAWAYS:\n",
            "  \ud83d\udd11 Always authenticate securely with environment variables\n",
            "  \ud83d\udcdd Create comprehensive model cards with bias documentation\n",
            "  \ud83d\udd12 Use private repositories for sensitive or demo models\n",
            "  \u26a1 Choose the right method: push_to_hub() vs HfApi vs CLI\n",
            "  \ud83e\uddea Test your models after uploading to ensure they work\n",
            "  \ud83d\udcca Document limitations and intended use cases clearly\n",
            "\n",
            "\ud83d\udcc8 EXECUTION SUMMARY:\n",
            "  \ud83d\udd10 Authentication: Not completed\n",
            "  \ud83e\udd16 Model Upload: Not completed\n",
            "  \ud83d\udd27 HfApi Demo: Not completed\n",
            "  \ud83d\udcca Dataset Upload: Not completed\n",
            "\n",
            "\ud83d\ude80 NEXT STEPS:\n",
            "  1. \ud83d\udd27 Practice with your own models and datasets\n",
            "  2. \ud83d\udcda Explore advanced features like model versioning\n",
            "  3. \ud83e\udd1d Collaborate with others using shared repositories\n",
            "  4. \ud83d\udd0d Discover other models and datasets on the Hub\n",
            "  5. \ud83d\udcd6 Read the full Hugging Face Hub documentation\n",
            "\n",
            "\ud83d\udcda RELATED NOTEBOOKS:\n",
            "  \ud83d\udcd6 05_fine_tuning_trainer.ipynb - Model fine-tuning\n",
            "  \ud83e\udd16 01_intro_hf_transformers.ipynb - HF basics\n",
            "  \ud83d\udcca 03_datasets_library.ipynb - Working with datasets\n",
            "\n",
            "\ud83d\udd17 USEFUL LINKS:\n",
            "  \ud83c\udf10 Hugging Face Hub: https://huggingface.co/\n",
            "  \ud83d\udcd6 Documentation: https://huggingface.co/docs/hub/\n",
            "  \ud83c\udf93 Course: https://huggingface.co/course/\n",
            "  \ud83d\udcac Community: https://discuss.huggingface.co/\n",
            "  \ud83d\udce7 Support: support@huggingface.co\n",
            "\n",
            "\ud83d\udca1 Remember: The Hugging Face Hub is a powerful platform for sharing and\n",
            "   collaborating on ML models. Use it responsibly and help build an\n",
            "   open, ethical AI community!\n"
          ]
        }
      ],
      "source": [
        "# Final summary\n",
        "print(\"\ud83c\udf8a PUSH_TO_HUB API DEMONSTRATION COMPLETE!\")\n",
        "print(\"=\" * 43)\n",
        "\n",
        "print(\"\\n\ud83d\udccb WHAT WE COVERED:\")\n",
        "topics_covered = [\n",
        "    \"\u2705 Authentication with Hugging Face Hub\",\n",
        "    \"\u2705 Loading and preparing models for upload\",\n",
        "    \"\u2705 Using model.push_to_hub() method\",\n",
        "    \"\u2705 Advanced control with HfApi\",\n",
        "    \"\u2705 Pushing datasets to the Hub\",\n",
        "    \"\u2705 Creating comprehensive model cards\",\n",
        "    \"\u2705 Best practices and security considerations\",\n",
        "    \"\u2705 Troubleshooting common issues\",\n",
        "    \"\u2705 CLI alternatives and comparisons\"\n",
        "]\n",
        "\n",
        "for topic in topics_covered:\n",
        "    print(f\"  {topic}\")\n",
        "\n",
        "print(\"\\n\ud83c\udfaf KEY TAKEAWAYS:\")\n",
        "print(\"  \ud83d\udd11 Always authenticate securely with environment variables\")\n",
        "print(\"  \ud83d\udcdd Create comprehensive model cards with bias documentation\")\n",
        "print(\"  \ud83d\udd12 Use private repositories for sensitive or demo models\")\n",
        "print(\"  \u26a1 Choose the right method: push_to_hub() vs HfApi vs CLI\")\n",
        "print(\"  \ud83e\uddea Test your models after uploading to ensure they work\")\n",
        "print(\"  \ud83d\udcca Document limitations and intended use cases clearly\")\n",
        "\n",
        "print(\"\\n\ud83d\udcc8 EXECUTION SUMMARY:\")\n",
        "print(f\"  \ud83d\udd10 Authentication: {'Success' if AUTHENTICATED else 'Not completed'}\")\n",
        "print(f\"  \ud83e\udd16 Model Upload: {'Success' if MODEL_PUSHED else 'Not completed'}\")\n",
        "print(f\"  \ud83d\udd27 HfApi Demo: {'Success' if API_UPLOAD_SUCCESS else 'Not completed'}\")\n",
        "print(f\"  \ud83d\udcca Dataset Upload: {'Success' if DATASET_PUSHED else 'Not completed'}\")\n",
        "\n",
        "if AUTHENTICATED:\n",
        "    print(\"\\n\ud83c\udf10 YOUR REPOSITORIES:\")\n",
        "    if MODEL_PUSHED:\n",
        "        print(f\"  \ud83e\udd16 Model: https://huggingface.co/{full_repo_name}\")\n",
        "    if API_UPLOAD_SUCCESS:\n",
        "        print(f\"  \ud83d\udd27 API Demo: https://huggingface.co/{full_api_repo_name}\")\n",
        "    if DATASET_PUSHED:\n",
        "        print(f\"  \ud83d\udcca Dataset: https://huggingface.co/{full_dataset_repo}\")\n",
        "\n",
        "print(\"\\n\ud83d\ude80 NEXT STEPS:\")\n",
        "print(\"  1. \ud83d\udd27 Practice with your own models and datasets\")\n",
        "print(\"  2. \ud83d\udcda Explore advanced features like model versioning\")\n",
        "print(\"  3. \ud83e\udd1d Collaborate with others using shared repositories\")\n",
        "print(\"  4. \ud83d\udd0d Discover other models and datasets on the Hub\")\n",
        "print(\"  5. \ud83d\udcd6 Read the full Hugging Face Hub documentation\")\n",
        "\n",
        "print(\"\\n\ud83d\udcda RELATED NOTEBOOKS:\")\n",
        "print(\"  \ud83d\udcd6 05_fine_tuning_trainer.ipynb - Model fine-tuning\")\n",
        "print(\"  \ud83e\udd16 01_intro_hf_transformers.ipynb - HF basics\")\n",
        "print(\"  \ud83d\udcca 03_datasets_library.ipynb - Working with datasets\")\n",
        "\n",
        "print(\"\\n\ud83d\udd17 USEFUL LINKS:\")\n",
        "print(\"  \ud83c\udf10 Hugging Face Hub: https://huggingface.co/\")\n",
        "print(\"  \ud83d\udcd6 Documentation: https://huggingface.co/docs/hub/\")\n",
        "print(\"  \ud83c\udf93 Course: https://huggingface.co/course/\")\n",
        "print(\"  \ud83d\udcac Community: https://discuss.huggingface.co/\")\n",
        "print(\"  \ud83d\udce7 Support: support@huggingface.co\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 Remember: The Hugging Face Hub is a powerful platform for sharing and\")\n",
        "print(\"   collaborating on ML models. Use it responsibly and help build an\")\n",
        "print(\"   open, ethical AI community!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPiBDXAeR2-M"
      },
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udccb Summary\n",
        "\n",
        "### \ud83d\udd11 Key Concepts Mastered\n",
        "- **Authentication**: Secure login and token management with Hugging Face Hub\n",
        "- **push_to_hub API**: Using model.push_to_hub() and tokenizer.push_to_hub() methods\n",
        "- **Advanced Upload**: HfApi for fine-grained control over repository management\n",
        "- **Dataset Sharing**: Pushing datasets to Hub with proper documentation\n",
        "- **Model Cards**: Creating comprehensive documentation with bias considerations\n",
        "- **Best Practices**: Security, versioning, and ethical AI considerations\n",
        "\n",
        "### \ud83d\udcc8 Best Practices Learned\n",
        "- Always use environment variables or secure secrets for authentication tokens\n",
        "- Create detailed model cards that address limitations and ethical considerations\n",
        "- Use private repositories for sensitive models and demonstration purposes\n",
        "- Test models after uploading to ensure they work correctly\n",
        "- Choose appropriate upload methods based on your use case and requirements\n",
        "- Document bias, limitations, and intended use cases clearly\n",
        "\n",
        "### \ud83d\ude80 Next Steps\n",
        "- **Notebook 05**: [Fine-tuning with Trainer API](../05_fine_tuning_trainer.ipynb) - Learn advanced training techniques\n",
        "- **Documentation**: [HF Hub Guide](https://huggingface.co/docs/hub/) for comprehensive Hub features\n",
        "- **External Resources**: [HF Course Chapter 4](https://huggingface.co/learn/llm-course/chapter4/3?fw=pt) for model sharing\n",
        "\n",
        "---\n",
        "\n",
        "## About the Author\n",
        "\n",
        "**Vu Hung Nguyen** - AI Engineer & Researcher\n",
        "\n",
        "Connect with me:\n",
        "- \ud83c\udf10 **Website**: [vuhung16au.github.io](https://vuhung16au.github.io/)\n",
        "- \ud83d\udcbc **LinkedIn**: [linkedin.com/in/nguyenvuhung](https://www.linkedin.com/in/nguyenvuhung/)\n",
        "- \ud83d\udcbb **GitHub**: [github.com/vuhung16au](https://github.com/vuhung16au/)\n",
        "\n",
        "*This notebook is part of the [HF Transformer Trove](https://github.com/vuhung16au/hf-transformer-trove) educational series.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}